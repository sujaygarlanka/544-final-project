BigData & Cloud Solutions Engineer BigData &amp; Cloud Solutions Engineer Data, Cloud Solutions Engineer - Big San Jose, CA shailesh.pilare@gmail.com  (309)-531-8354  • Over 19+ years of experience in IT industry in developing and deploying mission critical  San Jose, CA 95129  applications using various tools and technologies.  • Hands on in implementation large Data Extraction and Transformation pipeline for massive  Batch and Real time data processing using Flume, SQOOP, OOZIE, Kafka for Batch-  Processing using Hadoop/Hive and Real Time processing using Spark Streaming. Education  • Strong programming experience using Java/J2EE and Scala languages and developed  various services and transformation modules using the same. B.TECH: Chemical Technology  • Strong experience in Architecture and Deploying Geographically Distributed applications  1996-2000  and Databases i.e. Cassandra  Nagpur University  • Experience in implementing durable ETL pipelines for Hadoop Infrastructure.  Nagpur, India  • Strong experience in Micro Services Architecture using Kubernetes and Hands-on writing  HELM Charts and containerizing the applications using Docker.  • Hands-on implementing Security Compliance for Public Cloud environment (AWS). Programming    Java s  Tools & Technologies Scala  JavaScript  • Big-Data Technology Stack: Hadoop, Cassandra, Spark, Kafka, ZooKeeper, Flume,  Bash Scripting  SQOOP, Hive, Oozie, MapReduce  Python Scripting  • NoSQL, Memory and Relation databases:- Cassandra, Reddis, MySQL.  • Programming languages/ Scripts: Java, Scala, Python, Bash & JavaScript.  • DevOps and Micro Service Architecture: - Docker, Kubernetes, AWS, KOPS, Technical Skills  GIT, Jenkin, HELM, Prometheus, Heapster, Grafana.  Big Data s  • Cloud Commuting: - AWS, GKE, OpenStack  Streaming  • Configuration Management:- SALT, AWS System Manager  Cloud  • AWS Services:- AWS IAM, VPC, EC2, ECS, EBS, RDS, S3, Lambda, ELB, Auto  Micro Services  Scaling, Route 53, Cloud Front, Cloud Watch, Cloud Trail, SQS etc..  NoSQL  • Proxy & web Servers:- NGINX, Netty, Tomcat, WebSphere  RDBMS  • Cloud Security & Compliance: Dome-9, AWS GuardDuty, AWS Inspector,  BI & Reports  SumoLogic, Splunk Advanced Shield and WAF Work Experience BigData & Cloud Solutions Engineer Symantec - Mountain View, CA July 2015 to Present Mountain View, CA - July 2015 - Current ) Symantec  • https://www.symantec.com/products/websecurity -service BigData & Cloud Solutions Engineer  (WSS) is indispensable line of defense against modern day cyber  threats. This is Cloud Proxy service for Enterprise customers and Environment & Tools  handles massive amount of data from customer end. Programming: - Java, Scala  • Design and Development various Scala modules for Scripting: -Python  Transformations and Actions for cleansing the input data for Spark Databases: - Cassandra, Redis  Streaming applications. Messaging: - Kafka, Flume  • Designed and developed large ETL pipelines using Flume, SQOOP Storage: - HDFS, S3  and HADOOP Streaming: -Spark  • Successfully designed and deployed very large Geographically Batch Jobs: - Hive (On Tez.)  distributed clusters for doing Batch and Real-time analytics using Monitoring: - Grafana  various Big DataTechnology stocks like Hadoop, Cassandra, Kafka, Build:- Jenkins, BitBucket, Artifactory  Hive, Spark streaming . Security:- AWS Inspector, Amazon  • As a Cloud Solution & DevOps Engineer, I was Responsible for GuardDuty, Dome-9, AWS Cloudwatch.  building scalable distributed data solutions using Hadoop Infrastructure: - AWS, Kubernetes,  • Design, Development and Implementation of Micro -Services Docker.  architecture using Docker, Kubernetes, KOPS Big-Data Consultant MicroExcel Inc August 2011 to July 2015 MicroExcel ( Secaucus, NJ - Aug 2011 - July 2015 ) MicroExcel  • This was a consulting role, where I have worked with very reputed BigData Consultant  clients such as "NY State Department of Health", "Seagate",  "Macys". Environment & Tools:  • As a BigData Consultant, I was responsible Capacity & Infrastructure Infrastructure: - Bare Metal.  planning for Hadoop cluster. Programming: - Java,  • Design and Implementation of data Extraction & Transformation Databases: - Hive, Oracle  pipelines using SQOOP and Flume . Messaging: - SQOOP  • Setting up Data Warehousing and query optimization using Hive . Storage: - HDFS (Cloudera,  • Automation job scheduling using OOZIE. Hortonworks) Sr. Java & Back- end Programmer Mphasis an HP Company - New York, NY January 2004 to July 2011 New York, NY - Jan 2004-July 2011) Mphasis an HP Company  • Application system design over Java/J2EE technologies with security, Sr. Java & Back- end Programmer  robustness, transaction management as prime goal.  • Created detail design documents for use cases of the system  • Provide estimate for new modules and do impact analysis for engineering change requests.  • Integrated front end technologies like JSP and AJAX, java web  frameworks Hibernate and Spring, and an Oracle database.  • Created shell scripts and PL/SQL scripts that were executed daily to refresh data feeds from multiple systems. Java & Front- end developer ILT India - Nagpur, Maharashtra May 2000 to December 2003 • Wrote SQL queries to retrieve data from the database using JDBC  • Utilized frameworks such as Hibernate and Spring for persistence and  • application layers  • Design UI using HTML/CSS and JSP Education Bachelor's Skills AWS, Hadoop, Devops, Jenkins