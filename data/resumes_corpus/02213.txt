Job Seeker • Over 4 years of experience in configuring, installing and maintenance Apache Hadoop cluster Hortonworks distribution and having good knowledge and experience on Hadoop and BigData Technologies.  • Expertise in setting up fully distributed multi node Hadoop clusters, with Hortonworks Ambari.  • Good knowledge in installing, configuring and using ecosystem components like Oozie, Hive, Spark, Sqoop, Yarn, Zookeeper, Zeppelin and Namenode High Availability.  • Extensive experience on performing administration, configuration management, monitoring, debugging in Hadoop Clusters.  • Expertise in adding hadoop components using Ambari  • Good knowledge in Import/Export structured, un-structured data from various data sources such as RDBMS, Event logs, Message queues into HDFS, using a variety of tools such as Sqoop.  • Daily ticket analysis of open and critical operations issues.  • Experience in managing Hadoop infrastructure like commissioning and decommissioning of nodes.  • Excellent Interpersonal Skills, Communication skills, documentation skills, problem solving ability, Quality consious and multi-tasked environment.  • Having hands on experience in installation, configuration, supporting and managing Hadoop Clusters using Hortonworks Distribution.  • Having hand on experience on upgradation of Ambari from 2.4 to 2.5.  • Having hand on experience on upgradation of HDP from 2.5 to 2.6.  • Having hands on experience in analyzing Log files for Hadoop and eco system services and finding root cause.  • Hadoop Cluster capacity planning, cluster Monitoring, Troubleshooting.  • Strong knowledge in configuring Namenode High Availability.  • Having experience on creating read only users to access ambari server WEB UI..  • Having hands on experience in installing kerberos, create principals and keytabs for services and users level manually.  • Having experience on generating users and services kerberos tickets for access Hadoop Cluster  • Having experience on Commissioning, Decommissioning, and Managing Nodes and tuning server for performance of the cluster.  • Having experience in HDFS data storage and support for running PIG, YARN, Spark, Hive and Oozie jobs.  • Good knowledge on administrating Pivotal HAWQ and Hadoop echo system components.  • Having experience on data migration from Hawq to GPDB.  • Generating keytabs for Gpadmin users.  • Preparing the list of activities for Restrospective meetings. Work Experience Wissen Infotech April 2016 to Present Environment Hadoop    GE Aviation is a world-leading provider of commercial, military and business. GE Aviation is a world-leading provider of commercial, military and business. GE Aviation is becoming a digital industrial business with its ability to harness large streams of data that are providing incredible insights and in turn, real operational value for customers.    Roles and Responsibilities:    • Involved in raising and closing tickets in service now and adding the assignment group.  • Creating templates regarding outages and sending Notification Email to the users and also to the particular DL's.  • Creating User Stories in Rally Kanban Dash Board and updating the tasks and also the Iteration status.  • Involved in creating the databases and adding the NSGs in Ranger.  • Monitored multiple hadoop clusters environments using Ambari. Monitored workload, CPU utilization, YARN memory and RM.  • Involved in Table creation and Data Migrations from one environment to another.  • Worked on Upgradations of Ambari and HDP  • Reclaimed the disk usage spaces  • Hands on experience in Installing and configuring Kerberos for the authentication of users and hadoop services.  • Involved in restarting the zeppelin service  • Preparing Retrospective meeting documents and list out the major activities and In progress.  • Involved in web-ex sessions with Hortonworks team.  • Involved in Daily stand up call regarding updates  • Involved in Cluster configuration change in order to add new NSG's/changing the parameters based on the recommendations Database Administrator Wissen Infotech August 2015 to April 2016 Duration Aug 2015 - Apr 2016  Environment Hadoop    GE Healthcare is a subsidiary of General Electric Co., that focuses on new developments in health information technology (HIT) such as more advanced medical imaging technology and patient monitoring systems.    Roles and Responsibilities:  • Involved in start to end process of hadoop cluster setup where in installation, configuration and monitoring the Hadoop Cluster.  • Responsible for Cluster maintenance, commissioning and decommissioning Data nodes, Cluster Monitoring, Troubleshooting, Manage and review data backups, Manage & review Hadoop log files.  • Installation of various Hadoop Ecosystems and Hadoop Daemons.  • Experience in create users, databases and grant permissions as per requirement.  • Managed and reviewed Hadoop Log files as a part of administration for troubleshooting purposes. Communicate and escalate issues appropriately.  • Experience in Analyzing system failures, identifying root causes, and recommended course of actions. Documented the systems processes and procedures for future references.  • Involved in Package Installations.  • Bringing back the Disk Mount mismatch  • Created cronjobs for kerberos ticket generation for services accessing without interruption.  • Worked on Implementation of Druid for creation of the table in Hive.    PROJECT #3:  Project Name GEA  Role Database Administrator  Organization Wissen Infotech  Client GE Aviation Education GE Aviation Wissen Infotech September 2014 to July 2015 Skills DATABASES (3 years), MYSQL, HADOOP (3 years), Hadoop (3 years), Hive (Less than 1 year) Additional Information SKILLSET    Big Data Ecosystems: Hadoop, HDFS, Hive, Sqoop, Oozie, Spark and YARN  Databases: Hawq, Greenplum, Postgres and MySQL  Datawarehouse: Hive  Operating Systems: Windows XP/07, Linux.  Tools: Pivotal Hadoop  Monitoring Tools: PCC    PROJECT #1: