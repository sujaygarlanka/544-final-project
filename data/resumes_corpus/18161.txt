Senior Python Developer Senior <span class="hl">Python</span> <span class="hl">Developer</span> Senior Python Developer Redwood City, CA Over 7+ years of experience in developing web-based applications, software development and design using Python 3.3/2.7, Django 1.9/1.8, XML, CSS, HTML, DHTML, JavaScript, JQuery & Angular Js.   • 3+ years of QA experience working in environment with different types of Software Development Life Cycle and Software Testing Methodology.   • Good experience in Shell Scripting's Server, Unix and Linux, Open stock and Expertise python scripting with focus on Devops tools, CI/CD and AWS Cloud Architecture.   • Experienced in writing SQL Queries, Stored procedures, functions, packages, tables, views, triggers.   • Knowledge of the Software Development Life Cycle (SDLC), Agile and Waterfall Methodologies and Familiar with concepts and devices such routers, switches and TCP/IP protocols and OSI layer.   • Worked on AJAX framework to transform Datasets and Data tables into HTTP-serializable JSON strings.   • Experienced in developing service oriented architecture (SOA) and web Services using SOAP, JAX-WS, WSDL and UDDI.   • Built the web application by using Python, Django, AWS, J2EE, PostgreSQL, MySQL, Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins.   • Well versed with design and development of presentation layer for web applications using technologies like HTML, CSS, and JavaScript, Bootstrap.   • Expertise in writing cloud computing applications using ruby.   • Had knowledge on continuous integration and deployment using Jenkins, Docker.   • Experience working with network protocols SNMP, NetConf.   • Experience in developing applications using amazon web services like EC2, Cloud Search, Elastic Load balancer ELB, S3, Cloud Front.   • Used R Language among statisticians and data miners for developing statistical software and data analysis.   • Expertise in operating Symantec Altiris Remote Agent to remotely fix problems.   • Excellent understanding and knowledge of Hadoop Distributed file system data modelling, architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming.   • Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Pyspark.   • Good working experience in processing large datasets with Spark using Scala and Pyspark and Familiar with JSON based REST Web services   • Experienced in understanding Service Virtualization needs/ Requirements & creating VSI's using WSDL, WADL, Recording, Request & Response pairs.   • Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template.   • Built the web application by using Python, Django, AWS, J2EE, PostgreSQL, MySQL, Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins.   • Strong hands-on on AWS cloud services like EC2, S3, RDS, ELB, and EBS for installing, configuring   • Experienced in understanding Service Virtualization needs/ Requirements & creating VSI's using Authorized to work in the US for any employer Work Experience Senior Python Developer Phillips 66, Houston - Houston, TX March 2017 to Present ?     Over 7+ years of experience as a Web/Application Developer and coding with analytical   ?     Programming using Python, Django, Java.   ?     Involved in software development in Python (libraries used: Beautiful Soup, NumPy, SciPy, matplotlib, Pandas data frame, network, urllib2, MySQL dB for database connectivity) and IDEs - sublime text, Spyder, PyCharm.  ?     Good knowledge of web services with protocols SOAP, REST and knowledge of server Apache Tomcat, WebLogic.   ?     Hands on experience in SVN, Git, JIRA and Bugzilla worked in SQL databases MS SQL, Apache Cassandra, Oracle and MongoDB.   ?     Used AWS lambda to run code virtually.  ?     Developed API for using AWS Lambda to manage the servers and run the code in AWS.  ?     SQL and PL/SQL programming, developing complex code units, database triggers and using the latest features to optimize performance (Bulk Binds, Materialized views, Inline views, Global Temporary Tables).   ?     Good experience in Shell Scripting Server, Unix and Linux, Open stock and Expertise python scripting with focus on DevOps tools, CI/CD and AWS Cloud Architecture.   ?     Working with container-based deployments using Docker, working with Docker images, Docker Hub and Docker registries and Kubernetes.   ?     Modifying data using SAS/BASE, SAS/ MACROS.   ?     Open Source template-based Qt reporting solution.  ?     Big data processing using Spark, AWS, and Redshift   ?     Extracting data from the database using SAS/Access, SAS SQL procedures and create SAS data sets.   ?     Writing SQL Queries, Stored procedures, functions, packages, tables, views, triggers.   ?     Knowledge of the Software Development Life Cycle (SDLC), Agile and Waterfall Methodologies and Familiar with concepts and devices such routers, switches and TCP/IP protocols and OSI layer.   ?     Worked on AJAX framework to transform Datasets and Data tables into HTTP-serializable JSON strings.   ?     Used Groovy and Grails with spring, Java, J2EE for user interface.  ?     Built the web application by using Python, Django, AWS, J2EE, PostgreSQL, MySQL, Oracle 10g and MongoDB and Knowledgeable with continuous deployment using Heroku and Jenkins.   ?     Extensive working experience in free marker, Struts framework, Spring framework and O/R Mapping Hibernate framework.   ?     Used different PySpark APIs to perform necessary transformations and actions on the data which gets from Kafka in real time.   ?     Experience in using object-relational mapper (ORM) library to automate the transfer of data stored in relational databases tables into objects.   ?     Performed various Parsing technique's using PySpark API'S to cleanse the data from Kafka.   ?     Had knowledge on continuous integration and deployment using Jenkins, Docker.   ?     Implemented Restful web service to interact with Redis Cache framework.   ?     Worked on developing Restful endpoints to cache application specific data in in-memory data clusters like REDIS and exposed them with Restful endpoints.   ?     Experience in developing applications using amazon web services like EC2, Cloud Search, Elastic Load balancer ELB, S3, CloudFront.  ?     Used SQL Alchemy as Object Relational Mapper (ORM) for writing ORM queries.  ?     Worked with Spring Batch Used Spring ORM module to integrate with Hibernate.  ?     Developed custom consumers and producers for Apache Kafka in Go (Golang) for cars monitoring system.   ?     Designed the real-time analytics and ingestion platform using Storm and Kafka. Wrote Storm topology to accept the events from Kafka producer and emit into Cassandra DB.   ?     Manage the configurations of multiple servers using Ansible.  ?     Implemented real-time log analytics pipeline using Confluent Kafka, storm, elastic search,  Logstash Kibana, and Greenplum.  ?     Worked with Kibana log monitoring system and fixed a critical issue easily by capturing the context.   ?     Maintaining the Elasticsearch cluster and Logstash nodes to process around 5TB of Data Daily from various sources like Kafka, kubernetes, etc.  ?     Design, build and manage the ELK (Elasticsearch, Logstash, graphite, Kibana) cluster for centralized logging and search functionalities for the App.  ?     Golang, Infrastructure Teams and Engineering Productivity utilizing Kubernetes, Docker, influx dB Ansible, Spinnaker.  ?     Deployed mircoservices2, including provisioning AWS environments using Ansible Playbooks.   ?     Provisioned load balancer, auto-scaling group and launch configuration for microservice using Ansible.   ?     Used Ansible playbooks to setup Continuous Delivery pipeline. This primarily consists of a Jenkins and Sonar server, the infrastructure to run these packages and various supporting software components such as Maven, etc.   ?     Experience in writing playbooks for Ansible and deploying applications using Ansible.   ?     Automated various infrastructure activities like Continuous Deployment, Application Server setup, Stack Monitoring using Ansible playbooks and has integrated Ansible with Run deck and Jenkins.   ?     Provisioned and patched servers regularly using Ansible.   ?     Created real-time dashboard for Executives, utilizing Logstash, graphite, Elastic Search, Kibana & Redis.  ?     Implemented Ansible to manage all existing servers and automate the build/configuration of new servers.   ?     Developed an Ansible role for Zabbix-agent which will be integrated into the to the CICD pipeline.   ?     Used Ansible to document all infrastructures into version control.   ?     Used Ansible to document application dependencies into version control.   ?     Responsible for on boarding Application teams to build and deploy their code using GitHub Jenkins, Nexus and Ansible  ?     Written transformations and actions on data frames, used Spark SQL on data frames to access hive tables into spark for faster processing of data.   ?     Involved in converting Hive/SQL queries into Spark transformations using Spark RDDs, Python and Scala.   ?     Used Hive to do transformations, joins, filter and some pre-aggregations after storing the data to HDFS.   ?     Used Spark-Streaming APIs to perform necessary transformations and actions on the fly for building the common learner data model which gets the data from Kafka in near real time and Persists into Cassandra.   ?     Automated RabbitMQ cluster installations and configuration using Python/Bash.   ?     Excellent understanding and knowledge of Hadoop Distributed file system data modelling, architecture and design principles and Developed Python Mapper and Reducer scripts and implemented them using Hadoop streaming.   ?     Experienced in developing Web Services with Python programming language and Good working experience in processing large datasets with Spark using Scala and Spark.   ?     Good working experience in processing large datasets with Spark using Scala and Spark and Familiar with JSON based REST Web services   ?     Experienced in understanding Service Virtualization needs/ Requirements & creating VSI's using WSDL, WADL, Recording, Request & Response pairs.   ?     Expertise in creating Restful API in NodeJS and communicate with Clojure server via protocol and use Backbone to generate template.   ?     Used Kubernetes to deploy scale, load balance, scale and manage Docker containers with multiple name spaced versions.  ?     Different grid operations using panda, flask and SQL Alchemy combination  ?     Involved in multi-tiered J2EE design utilizing MVC architecture Spring, Struts, Hibernate and EJB deployed on WebSphere Application Server connecting to an Oracle database.   ?     Developed and configured the Java beans using Struts MVC and Hibernate  ?     Use AWS cloud management console, spinnaker to work with AWS. Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack.   ?     Developed CI/CD system with Jenkins on Google's Kubernetes container environment, utilizing Kubernetes and Docker for the runtime environment for the CI/CD system to build and test and deploy.   ?     Strong hands-on on AWS cloud services like EC2, S3, RDS, ELB, and EBS for installing, configuring   ?     Analyzed queries and database behavior using Percona tools, DB Tuna.  ?     Developed backup and recovery engine for VM backup/recovery using VMware vSphere APIs, Golang programming language and RabbitMQ Message bus (communication interface).   ?     Monitoring Cassandra cluster for resource utilization.  ?     Managing Cassandra clusters using Datastax OpsCenter  ?     Knowledge of Cassandra systems backup and recovery  ?     Knowledge of Cassandra security  ?     Knowledge of Cassandra maintenance and tuning - both database and server  ?     Created Terraform modules for two tier Architecture which includes AWS resources VPC, Subnets, Security groups, Ec2, Load Balancers, Auto scaling group, CloudWatch Alarms, ECS clusters, S3 buckets for logs.   ?     Built Jenkins jobs to create AWS infrastructure from GitHub repos containing Terraform code to deploy different Applications infrastructure for Dev, QA and Pre-prod based on the requirement from different teams.   ?     Built servers in AWS, importing Volumes, launching EC2, creating Security groups, Auto scaling, Load balancers (ELBs) and Installed required packages on servers.   ?     Crypto Blockchain (Bitcoin, Monaro, Bitcoin Cash) E-commerce platform built utilizing Python with Flask back-end and Jinja/JavaScript front-end.   ?     Currently building RESTful service API to allow users to see Blockchain transactions, orders, and info.   ?     Deployed on AWS and with services EC2, S3, CloudFront. Configured AWS CLI and performed necessary actions on the AWS services using shell scripting.   ?     Created Modules utilizing Requests JSON to interact RPC Wallet servers and Blockchain.  ?     Created scripts that monitored a device using Prometheus and Grafana via ODL, sash, GRPC, NC Client and model driven telemetry and checked for memory leaks and health of the router.  Senior Python developer Kroger - Ohio November 2015 to February 2017 ?     Extensively used Python / Django Framework for developing backend applications.   ?     Strong Expertise in working with server-side technologies including databases, Restful API and MVC design patterns.   ?     Actively involved in Initial software development life cycle (SDLC) of requirement gathering and in suggesting system configuration specifications during client interaction.  ?     Was leading an effort to build a real time click stream analytics platform for processing the beacons from web and mobile devices using Spark, Kafka, elastic and building dashboard using Kibana and Grafana  ?     Experience in the Hadoop ecosystem components like HDFS, Spark with Scala and python Zookeeper, Yarn, MapReduce, Pig, Sqoop, HBase, Hive, Flume, Cassandra, MongoDB, Oozie, Kafka, Flume, and TEZ.  ?     Hands on experience in developing SPARK applications using Spark API's like Spark core, Spark Streaming, Spark MLlib and Spark SQL and worked with different file formats such as Text, Sequence files, Avro, ORC, JSON and Parquette.   ?     Used object-relational mapper (ORM) to automate the transfer of data stored in relational databases tables into objects.   ?     Experience in using Design Patterns such as MVC, Singleton and frameworks such as DJANGO, Ability in handling Django ORM (Object-Relational Mapper) and SQL Alchemy.   ?     Implementing customer data collection with PySpark/Hadoop analytics.   ?     Managed and reviewed Hadoop log file and also worked in analyzing SQL scripts and designed the solution for the process using PySpark.   ?     Develop custom SAS code for performance monitoring reports.   ?     Import excel files into SAS for data manipulation and extraction.   ?     Developed SAS code for data analysis and report generation using Macro Processing, Proc Report to generate Excel spreadsheets.   ?     Pyspark we implemented Caching, Accumulators and UDF's   ?     We have implemented pyspark for Transformation and Actions in Spark   ?     Hands on experience with Spark Core, Spark SQL and Data Frames/Data Sets/RDD API.   ?     Changed map-reduce jobs and Hive scripts with Spark Data-Frame transformation and action.   ?     Excellent knowledge on Spark Architecture and Hadoop Architecture and its ecosystems such as HDFS, Job Tracker, Task Tracker, Name Node, Data Node and Map Reduce programming paradigm.   ?     Develop python code to automate the ingestion of common formats such as JSON, CSV by using Logstash from elastic search to Kibana dashboard to be viewed by clients.   ?     Responsible for designing and deploying new ELK clusters (Elasticsearch, Logstash, Graphite Kibana, beats, Kafka, zookeeper etc.  ?     Experience on Key AWS services: EC2, S3, DynamoDB (NoSQL) and Lambda.  ?     Responsible for the Automation of the deployment of the Conductor application on AWS lambda using high-end AWS architectural components  ?     Developed AWS lambda scripts to build on demand EC2 instance formation.  ?     Automated RabbitMQ cluster installations and configuration using Python/Bash.  ?     Fixed issues related to OpenStack components such as Nova, Glance, Neutron, Key-stone, MySQL/Percona DB, RabbitMQ, Cech, Repose, HAP Roxy and Horizon.   ?     Experienced in developing API services Python/Tornado while leveraging AMQP and RabbitMQ for distributed architectures.   ?     Designed and developed web crawler in python using Scrappy framework and using RabbitMQ as a messaging server between the micro services.   ?     Experience with Kibana to check logs and other time-stamped data sets stored in Elastic Search.  ?     Written and Maintained Automated Salt scripts for Elasticsearch, Logstash, Kibana, and Beats.   ?     Worked on several python packages like NumPy, Beautiful Soup, SQL Alchemy, Py Tables etc.  ?     Developed full stack Python web framework with an emphasis on simplicity, flexibility, and extensibility. It is built atop excellent components and reinvents zero wheels. WSGI, routing, templating, forms, data, plugins, config, events, SQL Alchemy, Storm, CouchDB, OpenID, App Engine, jQuery, etc.   ?     Enabled continuous delivery via Gitlab, Spinnaker, Docker, Jenkins, Terraform, and AWS  Designed and developed load tests using Scala (Gatling)  ?     Migrated 10 TB of data from Oracle to Cassandra datacenter 12 nodes that have 4TB drives each using Stable Loader.  ?     Worked on performance tuning of cluster using Cassandra Configuration file and JVM Parameters.  ?     Configured internode communication between Cassandra nodes and client using SSL encryption.  ?     Evaluated, benchmarked and tuned data model by running endurance tests using JMeter, Cassandra Stress Tool and OpsCenter.  ?     Analysis of logs data and filter required columns by Logstash configuration and send it to Elasticsearch.   ?     Validated BI Support events, transformed and batched events which are sent to HNM and Kafka by triggering these events using Kafka, Mesos.   ?     Used micro service architecture, with Spring Boot-based services interacting of REST and Kafka.   ?     Developed Kafka producer and consumers, HBase clients, Spark, shark, Streams and Hadoop MapReduce jobs along with components on HDFS, Hive.  ?     Creating restful web services for Catalog and Pricing with Django MVT, Jersey, MySQL, and MongoDB.   ?     Worked with JSON based REST Web services and Amazon Web Services (AWS).  ?     Use AWS cloud management console, spinnaker to work with AWS. Wrote python scripts using boto3 library to manage ec2 instances and CloudFormation stack.  ?     Created real-time dashboard for Executives, utilizing Logstash, graphite, Elastic Search, Kibana & Redis.   ?     Experience in configuring and working with Flume and Kafka to load the data from multiple web sources directly into HDFS.   ?     Used Redis cache for storing commonly used info and propagate the changes using RabbitMQ  ?     Worked on Angular JS framework to develop interactive websites based on client needs.  ?     Used Cassandra for database and Redis for cache, for storing and fetching the data.   ?     Used Redis Cache for high performance, which creates space for new data by removing old data.   ?     Developed Ruby on Rails web applications using MongoDB and back-ground processes using Risqué and Redis.   ?     Utilized Python in the handling of all hits on Django, Redis, and other application  ?     Successfully migrated the website's main database from MySQL to PostgreSQL.   ?     Helped the big data analytics team with implementation of python scripts for Sqoop, spark and Hadoop batch data streaming.   ?     Developed frontends using HTML5, CSS3, JavaScript and jQuery.   ?     Designed and created the database tables and wrote SQL queries to access PostgreSQL  ?     Used Kubernetes to deploy scale, load balance, and worked on Docker Engine, Docker HUB, Docker Images, Docker Compose for handling images for installations and domain configurations.   ?     Implemented in Jenkins for Continuous Integration and for automating all builds and deployments and Build Jenkins jobs to create AWS infrastructure from GitHub repos containing terraform code and Installed and Administered Jenkins CI for Maven Builds.   ?     Developed Python based API (RESTful Web Service) to track the events and perform analysis using Flask.   ?     Ingested large CSV XML JSON data from computers around the world utilizing Python with pandas, csv, xml and NumPy. Formatted the raw data and built dynamic statistic pages for engineers.   ?     Migrated data from a mongo dB and python2 environment to an Elasticsearch python 3 workflow.   ?     Developed Micro services for the HP team using Spring Boot and Java 8.   ?     Integrated Hibernate ORM with Spring-Hibernate framework to facilitate DML and DQL queries and represent object-database mapping.   ?     Kubernetes is being used to orchestrate the deployment, scaling and management of Docker Containers.   ?     Used Jenkins pipelines to drive all micro services builds out to the Docker registry and then deployed to Kubernetes, Created Pods and managed using Kubernetes   ?     Managed local deployments in Kubernetes, creating local cluster and deploying application containers.   ?     Wrote AJAX calls to populate tables, tab menu and other components with JSON data in AngularJS.   ?     Extensively used HTML5, AngularJS, JSON, AJAX and DOM scripting for form validations.   ?     Worked on the MySQL migration project to make the system completely independent of the database being used. Used Spring to implement this.   ?     Involved in multi-tiered J2EE design utilizing MVC architecture Spring, Struts, Hibernate and EJB deployed on WebSphere Application Server connecting to an Oracle database  ?     Implemented a continuous Delivery Pipeline with Jenkins and GitHub to build a new Docker container automatically.  ?     Used Docker to implement a high-level API to provide lightweight containers that run processes isolation and worked on creation of customized Docker container images, tagged and pushed the images to the Docker repository.    ?     Participated in development of a well responsive single page application using AngularJS framework, Java Script, and jQuery in conjunction with HTML5, CSS3 standards, with front-end UI team.  ?     Extensively used HTML5, AngularJS, JSON, AJAX and DOM scripting for form validations.   ?     Automated various infrastructure activities like Continuous Deployment, Application Server setup, Stack monitoring using Ansible playbooks and has Integrated Ansible with Run deck and Jenkins.   ?     Wrote Ansible Playbooks with Python SSH as the Wrapper to Manage Configurations of AWS nodes and Tested Playbooks on AWS instances using Python. Run Ansible Scripts to Provide Dev Servers.   ?     Experience in using GIT Repository Managers for Maven builds.  ?     Used Celery as task queue and RabbitMQ, Redis as messaging broker to execute asynchronous tasks.  Python Developer UPS - Atlanta, GA August 2013 to October 2015 ?     Developed Wrapper in Python for instantiating multi-threaded application and Deploy and monitor scalable infrastructure on Amazon web services (AWS).   ?     Used Test driven approach(TDD) for developing services required for the application.   ?     Managed datasets using Panda data frames and MySQL, queries MYSQL database queries from python using Python-MySQL connector and MySQL dB package to retrieve.   ?     Datacenter migration to Amazon Web Services (AWS) infrastructure and provided initial support to Applications and Database teams.  ?     Familiarity and experience with some ORM (Object Relational Mapper) libraries.  ?     Developed requirements and enterprise architecture for EIA metadata, Eguide and EBI under SASVB.   ?     Developed and implemented Legacy system programs by using COBOL, DB2, CICS, JCL, JAVA and VSAM.   ?     Responsible SAS reports, analysis using SAS macros in UNIX operating system.  ?     Worked on Big Data infrastructure for batch processing and real-time processing using Apache Spark. Built scalable distributed Hadoop cluster running Hortonworks Data Platform   ?     Responsible for design and development of Spark SQL Scripts based on Functional Specifications.  ?     Worked on the large-scale Hadoop YARN cluster for distributed data processing and analysis using Spark, Hive.   ?     Develop python code to automate the ingestion of common formats such as JSON, CSV by using Logstash from elastic search to Kibana dashboard to be viewed by clients.   ?     Responsible for designing and deploying new ELK clusters (Elasticsearch, Logstash, Graphite Kibana, beats, Kafka, zookeeper etc.  ?     Parsed the unstructured data into semi-structured format by writing complex algorithms in pyspark   ?     Extensive working experience in free marker, Struts framework, Spring framework and O/R Mapping Hibernate framework.   ?     Designed and coded Hibernate, struts for mapping, configurations and HQL for enhancement and new module development of Transport Optimization, Planning and Scheduling Web app.   ?     Automated RabbitMQ cluster installations and configuration using Python/Bash.  ?     Managed, developed, and designed a dashboard control panel for customers and Administrators using Django, Oracle DB, PostgreSQL, and VMWare API calls.  ?     Developed micro services using spring boot exposed as REST API and integrated with AngularJS based web applications.   ?     Integrated AD with Cassandra Authorization.  ?     Designed, Automated the process of installation and configuration of secure DataStax Enterprise Cassandra cluster using puppet.  ?     Monitored the cluster with Zabbix.  ?     Configured internode communication between Cassandra nodes and client using SSL encryption.  ?     Developed shell scripts along with setting up of CRON jobs for monitoring and automated data backup on Cassandra cluster.  ?     Created data frames schema from raw data stored at Amazon S3, lambda using PySpark.  ?     Created azure templates to automate server creation and DSE deployments.  ?     Installed and configured Cassandra cluster and CQL on the cluster.  ?     Experience in upgrading the existing Cassandra cluster to latest releases.  ?     Implemented application level persistence using Hibernate and spring.   ?     Configured Struts, Hibernate framework with Spring MVC.  ?     Docker container deploying micro services, and scaling the deployment using Kubernetes.   ?     Developed Chat Ops interfaces with slack and Kubernetes on GKE.  ?     Experience with Streaming platforms like Apache Kafka   ?     Used Apache Kafka (Message Queues) for reliable and asynchronous exchange of important information between multiple business applications  ?     Extensively used python modules such as requests urllib2 for web crawling.   ?     Working on Spinnaker platform for Multi-Cloud Continuous Delivery (Bake, Test, & Deploy/Container Pipelines) using Packer, Terraform, Kubernetes, AWS, GCP.  ?     Setup Docker on Linux and configured Jenkins to run under Docker host.   ?     Wrote and executed various MYSQL database queries from python using Python-MySQL connector and MySQL dB package.   ?     Managed local deployments in Kubernetes, creating local cluster and deploying application containers.   ?     Experienced in developing API services Python/Tornado while leveraging AMQP and RabbitMQ for distributed architectures.   ?     Added support for Amazon AWS S3 and RDS to host static/media files and the database into Amazon Cloud   ?     Designed and managed API system deployment using fast http server and Amazon AWS architecture.   ?     Design and implementation of CI/CD pipelines using Jenkins and automated CI/CD pipelines by invoking Ansible playbooks   ?     Automated the Oracle 12c installation using ansible scripts  ?     Automated email notification using celery and RabbitMQ for status of jobs and pending task list manager to users and admin.    ?     Profound knowledge and experience on underlying mechanism of docker containers and automated the docker containers using Ansible  ?     Expertise in Implementing a Production ready, Highly Available, Fault Tolerant Kubernetes infrastructure. Working on Scheduling, deploying and managing container replicas on a node cluster using Kubernetes.   ?     Setting up the CI/CD pipeline using GitHub, Jenkins, Maven, Chef, Terraform and AWS.   ?     DevOps experience with GitHub, Maven, Nagios, Docker, Jenkins, Puppet, Chef, Ansible.  ?     Virtualized the servers using the Docker for the test environments and dev-environments needs, and configuration automation using Docker Containers  ?     Integrated Kafka with Spark streaming for high speed data processing.  ?     Built Web pages that are more user-interactive using, Jasmine, Karma, HTML, CSS, LESS, RESTFUL API Services, JavaScript, Bootstrap, GIT, and JSON.   ?     Used Celery as task queue and RabbitMQ, Redis as messaging broker to execute asynchronous tasks.   ?     Built Web pages that are more user-interactive using, Jasmine, Karma, HTML, CSS, LESS, RESTFUL A Having good experience in Struts, Spring IOC, Spring MVC, Spring Data, Spring Boot, Spring Security and other spring frameworks implementation and integration.   ?     Followed Agile SCRUM methodology and used Test Driven Development (TDD) and Used BDD pattern for code quality and good readability standards   ?     Worked on Redux making to do list reduces, reducers functions and implementing store method PI Services, JavaScript, Bootstrap, GIT, and JSON.   ?     Implemented application level persistence using Hibernate and spring.   ?     Configured Struts, Hibernate framework with Spring MVC.   ?     Written the Grok pattern in Logstash.  ?     Configured Logstash: input, filter, output plugins – database log file sources and elastic search as output Python developer Aetna - Hartford, CT August 2011 to July 2013 ? Designed, Installed and Implemented Ansible configuration management system.   ? Used Ansible to manage Web applications, Environments configuration Files, Users, Mount points and Packages.  ? Involved in database Administration activities like taking backup, checking log messages, looking for database optimization.   ? Executed asynchronous tasks with help of Celery and RabbitMQ.   ? Developed Kafka consumers to consume data from Kafka topics.  ? Responsible for Configuring Kafka Consumer and Producer metrics to visualize the Kafka System performance and monitoring   ? Experience with Kibana to check logs and other time-stamped data sets stored in Elastic Search.  ? Written and Maintained Automated Salt scripts for Elasticsearch, Logstash, Kibana, and Beats.  ? Used Amazon Web Services (AWS) for improved efficiency of storage and fast access.   ? Vast experience with Core Java and J2EE using most of the advanced features of Java including JDBC, Spring, Struts, EJB, Servlets, Hibernate.   ? Added support for Amazon AWS S3 and RDS to host static/media files and the database into Amazon Cloud.  ? Developed Merge jobs in Python to extract and load data into MySQL database and used Test driven approach for developing applications.  ? Cloud platform engineering Kubernetes, Spinnaker, Docker, Terraform, Consul, drone Jenkins, Chef, Kitchen.  ? Scheduled, deployed and managed container replicas onto a node cluster using Kubernetes.  ? Developed views and templates with Python and Django view controller and templating language to create a user-friendly interface using MVC architecture.   ? Worked on resulting reports of the application and Tableau reports and involved in modifying data using SAS/BASE, SAS/ MACROS  ? Extracting data from the database using SAS/Access, SAS SQL procedures and create SAS data sets.   ? Involved in installing software using pip command for python libraries like Beautiful Soup, NumPy, SciPy, python-twitter, RabbitMQ, Celery, matplotlib, Pandas data-frame and used the PEP8 coding convention.   ? Migration of API code written for Sybase to Oracle and was involved in Overlook the migration activity of PL/SQL programs.   ? Managed local deployments in Kubernetes, creating local cluster and deploying application containers.   ? Build back-end application with Python / Django, Worked on Dockers, RabbitMQ, Celery, and Jenkins.   ? Experienced in implementing Model View Control (MVC) architecture using server-side applications like Django and Flask for developing web applications.   ? Involved in the migration of the data contained in the earlier ASPL Database from Sybase to Oracle.   ? Expertise in working with server-side technologies including Databases, Restful API and MVC design patterns.   ? Wrote and executed various MySQL database queries from Python-MySQL connector and MySQL db package.   ? Used the Python modules NumPy, matplotlib, etc. for generating complex graphical data, creation of histograms etc.   ? Involved in migrating the Libraries written using Sybase API's to Oracle OCCI API.  ? Automate Build and Release tasks using ANT, Shell, and Perl for efficiency and repeatability  ? Communication with team members for both Ansible Core and Ansible Tower teams to clarify requirements and overcome obstacles  ? Automated various service and application deployments with ANSIBLE on CentOS and RHEL in AWS.   ? Wrote ANSIBLE Playbooks with Python, SSH as the Wrapper to Manage Configurations of AWS  ? Nodes and Test Playbooks on AWS instances using Python. Run Ansible Scripts to provision Dev servers.    ? Used Python Libraries Pandas and NumPy, SQL and Tableau to procure, clean and aggregate data from Relational database to generate status reports and dashboards. Education Bachelor's Skills DJANGO (5 years), PYTHON (7 years), jQuery (5 years), AJAX (5 years), Flask (5 years), Restful (5 years), AWS (5 years), rabbitMQ (3 years), Ajax (4 years), Agile (4 years), azure (3 years) Additional Information SKILLS  Python 3.3/2.7, Django 1.4/1.3, Flask, Java, C++, Shell Script, SQL, Java/J2EE,  AJAX, JavaScript, HTML, DHTML, XHTML, XML, React, JSON, Jquery, Angularjs.