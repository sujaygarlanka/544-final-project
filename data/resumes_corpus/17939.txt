Python Developer <span class="hl">Python</span> <span class="hl">Developer</span> Python Developer - Infosys/Apple iTunes Sunnyvale, CA • Engineering professional with 8 years of experience in Software development.  • Mastering/Leading in the development of applications/tools using Python for 6 years.  • Experience with Web Development, Web Services, Python and the Django/flask framework • Proficient in Front end development experience using HTML, XML, CSS, JQuery and JavaScript, AngularJS.  • Mastering Web Application Development using html, JavaScript.  • Expertise in Object-Oriented design and coding. Good knowledge of various Design Patterns and UML.  • Experience in developing web-based applications using Python 2.X, Django 1.X/Flask.  • Experienced in using flask components like needs, permission, Principal for providing user permissions at granular level.  • Proficient in SQL databases MS SQL, MySQL, Oracle and No-SQL databases like MongoDB, Pymongo.  • SQL and PL/SQL programming, developing complex code units, database triggers and using the latest features to optimize performance (Bulk Binds, Materialized views, Inline views, Global Temporary Tables).  • Experience in building frameworks and automating complex workflows using Python for Test Automation.  • Experienced in writing SQL Queries, Stored procedures, functions, packages, tables, views, triggers.  • Experience in working with Python ORM Libraries including Django ORM, SQL Alchemy.  • Good experience in working with Web services like Amazon EC2, AWS and Amazon s3.  • Hands-on experience in UNIX and LINUX Kernels.  • Hands on experience in SVN, Git, JIRA, and Bugzilla.  • Good knowledge of web services with protocols SOAP, REST.  • Good knowledge of server Apache Tomcat, Web logic.  • Experienced in various types of testing such as Unit testing, Integration testing, User acceptance testing, Functional testing.  • Experience in writing test plans, test cases, test specifications and test coverage.  • Good Experience in error and exceptional handling.  • Proven ability to implement Continuous Integration and Continuous Deployment processes.  • Having experienced in Agile Methodologies, Scrum stories and sprints experience in a Python based environment, along with data analytics, data wrangling and Excel data extracts.  • Performed numerous server migrations on both Linux and Windows servers. Migrations include moving all clients and their data, configuration settings, testing and verifying.  • Extensive knowledge on automated batch programs by UNIX shell Scripts (file validations, file downloads, workflow executions).  • Can handle, writing technical and functional documents defined by the business requirements.  • Outstanding communication, analysis, and out-of-the-box/creative problem solving.  • Experience in working with different operating systems Windows, UNIX, Linux, and OS X.  • Have flexibility and ability to learn and use new technologies and also to work in team environment as wells as independently to get things done. Authorized to work in the US for any employer Work Experience Python Developer Infosys/Apple iTunes - Sunnyvale, CA January 2017 to Present Intelligent Data Analytics and Alerts(iDAA):    Project Description: • The ETL Framework was used to do extensive auditing of data based on statistical analysis. Auditing is done on data and gives a graphical and tabular view for the data. The tabular structure is send to the user through email. The various features for the tool is to provide Data Check Variance Check (difference between data on the same period), Recon Check(difference between data between two clusters). Various Quality scores are assigned daily and the dashboard loads the latest scores for the latest runs with the trend of last 14 days (2 weeks). The various quality measures we track are: (Completeness, Consistency, Uniqueness, Validity, Accuracy, Timeliness).    Responsibilities: • Responsible for gathering requirements, system analysis, design, development, testing and deployment.  • Developed and enhanced ETL framework which checks DQMs on different databases and gets the counts, validates the data between multiple environments(Clusters).  • Designed and developed alerting system to framework users when ever the DQM runs, the email alert contains DQM details and if it fails an incident is raised and ticket is created for the application teams.  • Framework has multiple modules like Load/Edit, DQM Executer, Export/Import data from Oracle/Hive/Teradata/Vertica/Druid.  ? Load/Edit is a command line API exposed to application teams for on boarding (Excel template)the DQMs into the Oracle DB.  ? Used Anaconda Python (numpy, pandas) for reading the data from the input template (Excel) and loading the data into Oracle DB.  ? Executer module is an command line API which is envoked through Autosys with necessary params and this module uses the params for pulling the DQM metadata from Oracle.  ? Wrote Success Criteria logic for DQMs with 0 dimensions and Multiple Measures and also for Multiple dimensions and multiple measure.  • Wrote custom python scripts for migrating the data from Hive to Oracle and vice versa which is envoked through a shell script using Autosys job scheduler and is schedule to run every day.  • Wrote a python alerting custom code which works as a package and sends an alerting email with the DQM deails and for PASS, FAIL, NOT_EVAL and EXCEPTION_RAISED cases.    Environment: Anaconda Python, numpy, pandas, Oracle, cx_oracle, Hadoop, Teradata, Vertica, vertica_ python,Druid, Pycharm, GIT, Jenkins. Python Developer Wipro/Apple - Sunnyvale, CA August 2017 to December 2017 Project Description:  Particles (formerly known as ProtoDB) is an effort to track data population and coverage at a granular (Protopath) level across multiple releases and plan for future releases. It is also an attempt to document at a granular level which specific subsets of existing data are consumed by services. Historical and future Protopath data population statistics can be leveraged for a variety of use cases.    Responsibilities: • Responsible for gathering requirements, system analysis, design, development, testing and deployment • Wrote Python scripts which periodically ingests data into Postgres and serves as the back-end to a web server.  • Worked on Jenkins creating jobs, executing jobs in different environment, creating triggers and configuring jobs.  • Load and transform large data sets of structured, semi structured and unstructured data using Hadoop/Big Data concepts.  • Developed spark jobs using pyspark in test environment for faster data processing.  • Working on Swagger-enabled REST API to serve as entry-point for web UI and integrate with other applications.  • Worked on Nodejs (Protopath parser project) to come up with all possible combinations of Protopath by analyzing the input for predicting the combination of incorrect inputs.  • Working on designing and implementing a web application using Python/Django for displaying the Maps data for every release and also providing a scope for generating a diff between the data for every release.  • Working on Gradle utility to automate the build and deployment process.    Environment: Python 2.7, Django, Postgres, Hadoop, Pycharm, Docker, GIT, Jenkins, Gradle. Python Developer WalmartLabs - Bentonville, AR April 2016 to July 2017 Responsibilities: • Worked on multiple projects like Taxonomy, Feed Gate Way which deals with the product classification and providing a platform for sellers, suppliers and MP sellers for updating the product and inventory in .com • Understand the business process variants and created the process flow for automating the adhoc request.  • Developed and supported Taxonomy API (RestAPI) using Python and (Flask, Cerberus, MongoDB).  • Wrote python wrapper for Flask and EVE frame work for generating desired results of Taxonomy API.  • Created client and server actions and added permissions for admins and non-admin users by restricting individuals for a particular data set by using flask principal, permissions and needs.  • Developed an API that asynchronously distributes task using RabbitMQ and Celery • Porting of data import jobs from cron jobs to distributed tasks, leading to a speedup.  • Efficiently performed all backend tasks from OPS up to the REST API interface/Portal frontend single handedly.  • Deployed async jobs monitoring system using celery flower.  • Wrote unittests and did code reviews.  • Worked with search business and search team to implement dynamic rule updates to search using elasticsearch.  • Created mapreduce job using python for creating sync between PTC configs and PTCs to remove unwanted attributes for products in .com.  • Used basic Hive queries for processing large sets of data used for analyzing the 1P, 2P and 3P products and also for analyzing data from MP Sellers, Sellers and Suppliers.  • Developed Spark code using python for faster processing of data given by market place sellers for generating best specification and description of products • Worked closely with the search team (Machine learning) for the title optimization of products by processing the product information given by the sellers. (Title, Specifications, Description etc.) • Wrote Python normalizations scripts to find duplicate data in different environments.  • Good Knowledge on MongoDB Workspaces, Snapshots and patching documents in Snapshots.  • Wrote scripts to integrate API's with 3rd party applications.  • Wrote scripts to Import and Export data to CSV, EXCEL formats from different environments using Python and made a Celery action using REST API call.  • Performed Did data validation and data cleaning process and data manipulation with pandas and numpy used for data visualization by reporting teams to genereate ranking for content provided by sellers.  • Did data analysis, miss value imputation with statistical methodologies using pandas, numpy.  • Worked under Agile/Scrum environment and handled production rollouts and issues.  • Developed new and enhanced search features such as SYNONYM, CANONICAL and ABBREVIATION for optimizing search results and relevancy. (JSON-elasticsearch-Kibana) • Extensively used XLSX reader and writer modules to read, write and analyze data and project the results as per the client request.  • Used GIT and JENKINS for continuous integration and deployment.  • Was a part of Holiday readiness support team starting from Thanksgiving to Christmas.    Environment: Python 2.7, Flask, Eve, Celery, Mongodb, Hive, Hadoop, Event, Postman, Pycharm, JIRA, JSON, Docker, GIT, Jenkins, Linux Python Developer CVS Caremark - Phoenix, AZ June 2015 to March 2016 Responsibilities: • Design, develop, test, deploy and maintain the website.  • Developed entire front-end and backend modules using Python on Django Web Framework.  • Designed and developed the UI of the website using HTML, AJAX, CSS and JavaScript.  • Implemented SQL Alchemy, which is a python library for complete access over SQL.  • Designed and developed data management system using MySQL and wrote several queries to extract/store data.  • Rewrite existing Java application in Python module to deliver certain format of data.  • Wrote Python scripts to parse XML documents and load the data in database.  • Generated property list for every application dynamically using Python.  • Wrote Automation test cases using Selenium WebDriver using Python API.  • Responsible for search engine optimization to improve the visibility of the website.  • Used Apache. htaccess to provide authentication system for Django/MySQL sites • Handled all the client side validation using JavaScript.  • Performed testing using Django's Test Module.  • Added support for Amazon AWS S3 and RDS to host static/media files and the database into Amazon Cloud.  • Developed MapReduce jobs in python data cleaning and data processing.  • Involved in AJAX driven application by invoking web services/API and parsing the JSON response.  • Involved in writing application level code to interact with APIs, Web Services using JSON.  • Deployed the project into Heroku using Django and GIT version control system.  • Designed and Developed Restful web-services for both consumer and producer using Django, Swagger, Gunicorn.  • Creating unit test/regression test framework for working/new code.  • Using version control tool to coordinate team-development.  • Responsible for debugging and troubleshooting the web application.    Environment: Python 2.7, Django 1.8, Swagger, Hadoop, MySQL, XML, HTML, XHTML, CSS, AJAX, JSON, JavaScript, Apache Web Server, MYSQL and Linux. Python Developer ABC Insurance - Bloomington, IL January 2014 to May 2015 Responsibilities: • Responsible for gathering requirements, system analysis, design, development, testing and deployment.  • Worked on Front-end UI using HTML5, CSS3, JavaScript, Bootstrap and Jquery for event handling, pop-up dialogs, menus and skinning.  • Developed tools using Python, Shell scripting, XML to automate some of the menial tasks.  • Involved in building database Model, APIs and Views utilizing Python/Django, in order to build an interactive web based solution.  • Used Python to place data into JSON for Django Webapp.  • Used Python scripts to update content in the database and manipulate files.  • Used Beautiful Soup for selecting particular DOM elements when parsing HTML.  • Used Apache, MongoDB (NoSQL) in AWS Linux instance to store and analyze data.  • Restructuring data for faster distributed queries to aid caching.  • Made Django web based apps for Insurance premium calculations.  • Implemented jobs in Python to extract and load data into MySQL database.  • Created server-monitoring daemon with Psutil, supported by Django app for analytics, which I created. Also researched big data solutions with MongoDB database.  • Deployed the project into Heroku using GIT version control system.  • Involved in writing application level code to interact with Rest APIs, Web Services using JSON.  • Wrote validation scripts in SQL to validate data loading.  • Identified several hidden bugs caused by complicated multithreading issues such as race conditions caused by asynchronous events and resolved them.  • Interfacing with supervisors, artists, systems administrators and production to ensure production deadlines are met.    Environment: Python 2.7, Django, JSON, REST, HTML, XHTML, CSS, AJAX, JavaScript, Apache Web Server, Heroku, SOAP, Git, MongoDB, UNIX. Python Developer US Cellular - Chicago, IL November 2013 to November 2014 Responsibilities • Involved in understanding the current business process, defining scope of the project along with position statement.  • Re-engineered various modules for implementing changes and creating efficient system.  • Developed dynamic web pages using python Django Frameworks.  • Used Python and Django creating for XML processing, data exchange and business logic implementation.  • Used python scripts to update content in the database and manipulate files.  • Resolved issues and improvised the process to ensure a stable and accurate solution.  • Generated Python Django Forms to record data of online users • Python OO Design code for manufacturing quality, monitoring, logging, and debugging code optimization.  • Writing Unit, Functional, and Integration test cases for Cloud Computing applications on AWS using Python with boto library.  • Held meetings with client and worked all alone for entire internal project with limited help from the client.  • Worked on writing and as well as read data from csv and excel file formats.  • Provided technical and business knowledge to clients.  • Connected Flex from Backend Controller using different API services.  • Working with the architect, developers on business and technical issues, helping in designing the system; and testers to ensure all requirements are correctly translated.  • Managed requirements and tasks using JIRA.  • Data mapping, logical data modeling, created class diagrams and ER diagrams and used SQL queries to filter data within the Oracle database.    Environment: Python, Django, Java, MySQL, XML, HTML, XHTML, CSS, AJAX, JSON, JavaScript, Apache Web Server, MYSQL, and Linux. JAVA/ Python Developer HILTI - Hyderabad, Telangana May 2010 to September 2013 India    Responsibilities: • Developed Python based API (RESTful Web Service) to track sales and perform sales analysis using Flask, SQLAlchemy and PostgreSQL.  • Developed and designed an API (RESTful Web Service) for the company's website.  • Developed and designed e-mail marketing campaigns using HTML and CSS.  • Maintained customers relationship management databases (MySQL / PostgreSQL) • Developed server based web traffic statistical analysis tool using Flask, Pandas.  • Implemented and tested many features for dashboard using Flask, CSS and JavaScript.  • Managed companies virtual servers at Amazon EC2, S3 • Designed and developed Use-Case Diagrams, Class Diagrams, and Object Diagrams using UML Rational Rose for OOA/OOD techniques.  • Designed and developed components using Java/J2EE.  • Created UI using HTML CSS and JavaScript's.  • Created Servlets and Beans to implement Business Logic.  • Used SAX/DOM Parser for parsing the data to Oracle Database.  • Designed and created backend data access modules using PL/SQL stored procedures and Oracle 9i.  • Created database access layer using JDBC and PL/SQL stored procedures.  • Designed object model, data model, tables, constraints, necessary stored procedures, functions, triggers, and packages for Oracle Database.  • Worked on Socket communication layers and multithreading on Linux.  • Worked on SNMP interfaces.  Environment: Python, Flask, SQLAlchemy, PostgreSQL, SQL, J2EE, HTML, CSS, JDBC, Servlets, SNMP, JavaScript, Oracle, Apache Web Server and Linux. Education Master's Skills Apache. (6 years), database. (6 years), HTML (6 years), Linux (7 years), Python (8 years), C, Flask, Java, Javascript, Django Additional Information Technical Skills    Languages Python, Java, C, SQL, Shell Scripting.  Web Technologies HTML/DHTML, JavaScript, AngularJS, XML.  Development Tools (IDEs) Pycharm, Eclipse, Sublimetext, Atom, Komodo.  Web/Application Servers Nginx, Apache, WebSphere, WebLogic, Gunicorn.  Python Framework Django, Flask, Web2py, Bottle.  Database SQL SERVER, MySQL, Oracle, Sqlite3, MongoDB  Cloud Computing Amazon EC2/S3, Heroku, Google App Engine.  Bug Tracking Tools Jira, Bugzilla.  Platforms Windows, UNIX, LINUX,Mac.  Version Control SVN, GIT, CVS, TFS.    Methodologies Agile Methodology, Scum.