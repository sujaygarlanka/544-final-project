Cloud Engineer Cloud Engineer Cloud Engineer - ALTA / GDIT Brandywine, MD • Over 4+ years experience planning, designing, implementing and maintaining system applications in AWS Cloud in Linux and Windows environments and overall 15+ years IT related experience.  • Experience working in Agile Scrum Software Development Life Cycle with respect to delivering Operations, Functional and Technical Specifications, Resource Planning, Development, Testing and Maintenance.  • Experience in migrating and implementation of multiple applications from on premise to cloud using AWS services like SMS (Server Migration Service), DMS ( Database Migration Service), SCT (Schema Conversion Tool), CloudFormation, Cloudwatch, Cloudtrail, S3, Route53, Glacier, EC2, RDS, SQS, SNS and VPC.  • Build and configure a virtual data center in the Amazon Web Services cloud to support Enterprise Data Warehouse hosting including Virtual Private Cloud (VPC), Public and Private Subnets, Security Groups, Route Tables, Elastic Load Balancer.  • Experience with Amazon Kinesis to Stream, Analyze and Process real-time Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket.  • Experience with Amazon Athena to Analyze Web Data Stored in S3 Bucket.  • Experience in Big Data Processing with Apache Hadoop, Apache Spark, and Amazon Elastic MapReduce (EMR) using HDFS and EMRFS to directly access files stored in S3 Bucket with Cluster Nodes.  • Configured EMR Transient and Persistent Clusters depending on the workload and scenario of the application.  • Experience with Apache Hadoop frame works like Hive, Presto, Hue, Pig and Ganglia to Process and Analyze datasets from various data sources and applications.  • Migrated on premise Data Warehouse Application into Amazon Redshift and implemented the Leader Node and Compute Nodes for processing the information.  • Implemented Amazon QuickSight and TIBCO Spotfire Analytics to generate various reports.  • Configuration of Continuous Integration (CI), Continuous Delivery and Deployment (CD) using Github / Jenkins for automation.  • Experience in deployment of Java/J2EE applications on WebLogic and WebSphere application servers.  • Good experience in creating and editing Shell, Bash, Python Scripts for automation.  • Excellent communication, analytical and problem solving skills with ability to work within a team environment and independently.    Cloud Computing  AWS - EC2, EBS, RDS, S3, Glacier, Apache Hadoop, Apache Spark, EMR, Hive, Presto, Pig, Hue, Ganglia, Apache Spark, Redshift SQS, SNS, SES, CloudFormation, VPC, IAM, Route53, DynamoDB, Lambda, CloudWatch, Cloudtrail, CI/CD (CodeDeploy and CodePipeline), Ansible, Jenkins, Docker, Github, AWS Glue, AWS Athena    RDBMS Oracle 12c/11g/10g/9i, SQL, PL/SQL, MySQL5.6/5.7, MS SQL Server 2014 / 2012 / 2008, MS (SSIS, SSAS, SSRS), SAP ECC, SAP HANA. Authorized to work in the US for any employer Work Experience Cloud Engineer ALTA / GDIT - Herndon, VA November 2018 to Present • Managing Cloud Infrastructure and Shared Services for various customers' applications running on Amazon EC2 Instances for Linux / Windows environments.  • Responsible for launching Amazon EC2 Cloud Instances and Configuring Instances with respect to specific Applications in various Availability Zones using CloudFormation.  • Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments.  • Installed applications on AWS EC2 instances and configured storage on S3 buckets with security options for access and the IAM role based polices.  • Build VPCs (Virtual Private Cloud) and launching EC2 instances with Security Groups, Auto-Scaling, Load Balancers and other like S3, Glacier, RDS, SQS, SNS, and SES in defined public and private connections.  • Implemented Big Data Processing with Apache Hadoop, Apache Spark, and Amazon Elastic MapReduce (EMR) using HDFS and EMFS to directly access files stored in S3 Bucket for Cluster Nodes.  • Configured Transient and Persistent Clusters depending on the workload and scenario of the application.  • Implemented Apache Hadoop frame works like Hive, Hue, Pig and Ganglia to Process and Analyze datasets from various data sources and applications.  • Implemented Amazon Kinesis to Stream, Analyze and Process real-time Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket.  • Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket.  • Responsible for creating monitors, alarms and notifications for EC2 hosts using Cloud Watch.  • Migrating on promise application into AWS cloud and also configured a Hybrid environment for certain applications.  • Involved in 24X7-support rotation for all the Production, Im pl, Test, and Development environments.  Environment  AWS - EC2, S3, Glacier, SMS, RDS, SQS, SNS, CloudFormation, VPC, Apache Hadoop, Apache Spark, Java, Scala, EMR- Hive, Presto, Pig, Hue, Ganglia, CloudWatch, Kinesis, Lambda, QuickSight, Athena, Redshift, DynamoDB, Oracle 12c, Linux/Windows, Python, RDMS, MySQL, MS SQL Server 2012 AWS Cloud / Systems Engineer Glocoms Inc - Chicago, IL November 2014 to October 2018 • Responsible for launching Amazon EC2 Cloud Instances using Amazon Web Services and Configuring Instances with respect to specific Applications, Availability Zones and Regions.  • Worked with project team members in the development of approval criteria and request for designing change management process of various applications running in hybrid environments.  • Installed applications on AWS EC2 instances and configured the storage on S3 buckets.  • Responsible for S3 buckets creation, policies and the IAM role based polices.  • Build servers using AWS, importing volumes, launching EC2, RDS, creating security groups, auto-scaling, load balancers (ELBs) in the defined virtual private connection, AWS Glue for ETL and Data Analytics.  • Responsible for creating monitors, alarms and notifications for EC2 hosts using Cloud Watch.  • Involved in the migration and implementation of multiple applications from on premise to cloud using AWS services like SMS, DBMS, CloudFormation, S3, Route53 Glacier, EC2, RDS, SQS, SNS, Redshift, Lambda, CloudFormation, Cloudwatch, Cloudtrail and VPC.  • Build servers using AWS and launching EC2, RDS, creating security groups, auto-scaling, load balancers (ELBs) in the defined virtual private connection.  • Implemented Big Data Processing with Apache Hadoop, Apache Spark, and Amazon Elastic MapReduce (EMR) using HDFS and EMRFS to directly access files stored in S3 Bucket for Cluster Nodes.  • Configured Transient and Persistent Clusters depending on the workload and scenario of the application.  • Implemented Apache Hadoop frame works like Hive, Hue, Pig and Ganglia to Process and Analyze datasets from various data sources and applications.  • Implemented Amazon Kinesis to Stream, Analyze and Process real-time Logs from Apache application server and Amazon Kinesis Firehose to store the Processed Log Files in Amazon S3 Bucket.  • Implemented Amazon Athena to Analyze Web Data Stored in S3 Bucket by Elastic Load Balancer.  • Configuration of Continuous Integration (CI) and Continuous Delivery (CD) using CodePipeline and CodeDeploy for automation.  • Involved in 24X7-support rotation for all the Production, Test, and Development environments.  • Responsible for the Installation, Configuration and Maintenance of Oracle 12c/11g/10g Single Instances and RAC databases for High Availability and Disaster Recovery.  • Performed patching, upgrade and migration of multiple development, test and production databases from 10g/11g to 12c and migration to different platforms.  • Performed backup and recovery strategy using Recovery Manager (RMAN) - physical backup - and Data Pump (Import/Export) - logical backup, respectively.  • Created User accounts, Roles and granting required access Permissions and Privileges to the users.  • Implemented SQL, PL/SQL and T-SQL queries, packages, functions, stored procedures, triggers, tables, views, materialized views, indexes.  • Involved in 24X7-support rotation for all the Production, Test, and Development databases.  • Performed Performance Tuning using SQLTRACE, EXPLAIN PLAN, TKPROF, STATSPACK, AWR and ADDM.  • Developed various Bash, Shell Scripts for automation.  Environment  AWS - EC2, S3, Glacier, SMS, RDS, SQS, SNS, SES, CloudFormation, VPC, Apache Spark, Apache Hadoop, EMR- Hive, Pig, Hue, Ganglia, CloudWatch, Kinesis, Lambda, QuickSight, Athena, Redshift, DynamoDB, Oracle 12c, Linux/Windows, Java, Scala, Python, MySQL, MS SQL Server 2012 Database Administrator Glocoms Inc - Chicago, IL August 2011 to October 2014 • Responsible for Installation, Configuration and Maintenance of Oracle 12c/11g Single Instances, RAC and Standby databases (DataGuard) for High Availability and Disaster Recovery.  • Planned, designed and implemented a robust backup and recovery strategy using Recovery Manager (RMAN), physical backup and Data Pump (Import/Export) - logical backup, respectively. I periodically used production backups to refresh/clone the lower environments.  • Created User accounts, Roles and granting required access Permissions and Privileges to the users.  • Implemented SQL, PL/SQL and T-SQL queries, packages, functions, stored procedures, triggers, tables, views, materialized views, indexes.  • Performed SQL, PL/SQL Performance Tuning using various tools like EXPLAIN PLAN, SQL*TRACE, TKPROF and AUTOTRACE.  • Heavily utilized Oracle Enterprise Manager (OEM) for monitoring, job scheduling, performance tuning, and other routine DBA activities.  • Provided 24X7 supports for all the Production, Quality, Test, Development databases.  • Performed the Installation, Configuration and Migration of various Schema Objects, Patches and Database Upgrade from 10g to 11g and 11g to 12c.  • Developed various UNIX / Power Shell Scripts for automation.  • Installed, configured, and maintained MySQL both cluster and non-clustered configurations  • Experienced in configuring, troubleshooting, managing and maintaining MySQL Servers with third party tools like percona toolkit (pt-query digest, pt-online schema change etc).  • Maintained Optimized, tuned MySQL Error log, Log maintenance and troubleshooting queries.  • Experienced in handling MySQL Security, establishing MySQL Replication and MySQL Clustering between two or more MySQL Database servers.  • Performed MySQL full, incremental Backups (logical and physical) and recovery strategies making use of master binary log.  • Implemented database backups - for both MyISAM and InnoDB storage engines in production.  • Recovered database using crash, version and roll-forward recovery methods.  • Maintained database security by Granting/Revoking users/role (v. 5.5 & 5.6) authorizations and privileges.  • Implemented MySQL Enterprise Monitor, MySQL Replication Monitor and MySQL Query Analyzer for improving query performance and capacity planning.  • Installation and Administration of MS SQL Server 2008/2012/2014 databases in high availability environments including Clustering, AlwaysOn, Mirroring, Log Shipping and Replication.  • Implemented the Extract, Transform and Load (ETL) process for developing high performance Business Intelligence Reports using OBIEE, MS SSIS, and SSRS tools from various Data Sources.  • Strong knowledge of BI solution with Star Schema, Snow Flake Schema, Dimension and Fact table.  • Configure OBIEE and SQL Reporting Services (SSRS) for Developing Drill Tabular Reports, Matrix Reports and Drill Down Reports.  • Developed user guide documentation and training materials for various database environments and SOX compliance.  Environment  Oracle 12c, 11g RAC, OBIEE, MySQL 5.5/5.6, MS SSIS, SSAS, SSRS, HP-UX, REDHAT LINUX, Windows, ASM, OEM (Grid Control/Cloud), RMAN, SQL*Loader. Database Administrator Oracle (SAP) Partner K2 AG - Zurich, CH March 2010 to February 2011 • Provided Production support for database on 11g, 10g and 9i versions with standalone and RAC environment.  • Developed various UNIX / Power Shell Scripts for automation.  • Performed full & incremental backup using RMAN and implemented recovery strategies.  • Performed Database performance tuning using Tuning Advisor, AWR, ADDM, SQL ANALYZER, and Explain Plan, also using command line in generating reports needed.  • Heavily utilized TOAD, DBArtisan, and OEM for various administrations, reporting, job scheduling and performance optimization tasks.  • Implementing Switchovers in Data Guard environments for schedule and Rolling Upgrades  • Used Data Pump for logical backups and schema migrations.  • Scheduled and used RMAN backups for refreshes using DPITR.  • Interfaced regularly with developers to help optimize their queries and database support. Performed capacity planning, Extracting, Transforming and Loading (ETL) data using SQL*Loader and External Tables.  • Migrated databases from Sun Solaris, HP-UX to IBM AIX, and Windows to Linux.  • Performing core database administrative tasks like user creation, password resets, unlocking accounts, creating profiles, roles, migrating objects and backups etc.    Environment Oracle 11g, 10g, 9i, HP-UX, SUN SOLARIS, IBM AIX, OEM (Grid Control), RMAN, SQL*Loader, ASM, Data Guard SAP Basis Administrator Ecolab GmbH - Düsseldorf, DE August 2007 to August 2008 • Responsible for SAP Client Administration - User Authorization concept, Client copy, Transport Management, System performance tuning.  • Database maintenance includes Online Backup, Archive Log Backup, Upgrade and SAP DBA BR*Tools.    Environment SAP R/3 Enterprise 4.7, Oracle 9i and 10g, windows 2000, Solaris SAP Consultant Accenture GmbH - Frankfurt, DE July 2005 to May 2007 Performed a broad range of SAP-related consulting services for the following client companies: Givaudan Schweiz AG October 2006 to April 2007 Bombardier Transportation - UK June 2006 to September 2006 Messer Group - DE November 2005 to May 2006 T-Mobile GmbH August 2005 to October 2005 Education Master of Science in Data Analytics in Data Analytics University of Maryland University College 2020 Master of Science in Technical Management in Technical Management University of Applied Sciences Emden 2001 Skills DATA MODEL, PL/SQL, SQL, AIX, LINUX, SHELL SCRIPTING, SUN, UX, POWER BI, C/C++, C++, JAVASCRIPT, JSON, PERL, PHP, PYTHON, SCRIPTING, XML, BASH, SCALA, Docker, Devops