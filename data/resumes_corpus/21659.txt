Sr. ML Developer Sr. ML <span class="hl">Developer</span> Sr. ML Developer - IBM Dallas, TX Over 9+ years of experience in IT Industry with proficiency in Design & Development of various software projects. Sun Certified Java programmer with over 8 years of experience developing enterprise applications using Java/J2EE and Machine learning (ML), Artificial Intelligence (AI) technologies in Banking, Insurance and Telecom.    ? Hands on design and implementation of AI, machine learning algorithms using Python and R.  ? Expertise in distributed application architecture, object oriented design, and web based applications.  ? Expertise in Application Design & Architecture using Core Java, J2EE, EJB, Hibernate, Swing, Struts, JSP Servlets, Filters, JMS, JDBC, JNDI, MDB, Java Beans, Web Services, AJAX, Java Script, HTML, DHTML, XML, XSLT, ANT, Maven, log4j.  ? Excellent Project implementation skills using Core Java, Java Beans, J2EE (JSP, Servlets), EJB, JMS, JSF, Struts, spring, spring batch, Hibernate, JDBC, XML, Web Services and Design Patterns.  ? Expertise in J2EE Architecture, Java and J2EE Core Design Patterns, Object Oriented Analysis and Design/Development Methodologies (OOAD), Object Modeling with Use Cases, Sequence & Class.  ? Diagrams using UML with Rational Rose and Microsoft Visio.  ? Expert knowledge over J2EE Design Patterns like MVC Architecture, Front Controller, Session Facade, Business Delegate and Data Access Object for building J2EE Applications.  ? Expertise UI development using HTML, Javascript, EXT-JS, Ajax, JQuery and CSS Work Experience Sr. ML Developer IBM - Seattle, WA 2015 to Present Consumer portal used by sprint customer to setup plans and make payments using various device through phone, computer etc. User can also select Bolton addOn service once account is setup.    Responsibilities:  • Developed and Implemented WebServices and used Spring Framework.  • Used R for prototype on a sample data exploration to identify the best algorithimic approach and then wrote scala scripts using spark machine learning module.  • IInvolved in building data pipelines that extract, classify, merge and deliver new insights on the data.  • Managed and reviewed Hadoop log files.  • Worked with time series data, and perform various statistical and (AI) artificial intelligence, (ML) machine learning algorithm such as LMS, regression, filtering, correlation, neural network.  • Designed the (AI) artificial intelligence, (ML) Machine learning data pipeline for regular monitoring and performance evaluation of the deployed ML models.  • Built codebase for a natural language processing and (AI) artificial intelligence, (ML) machinelearning framework.  • Tested raw data and executed performance scripts.  • Shared responsibility for administration of Hadoop, Hive and Pig.  • Developed Map Reduce programs to parse the raw data, populate staging tables and store the refined data in partitioned tables in the EDW.  • Created Hive queries that helped market analysts spot emerging trends by comparing fresh data with EDW reference tables and historical metrics.  • Developed Web Services to communicate to other modules using XML based SOAP and WSDL protocols.  • Followed an Agile, Software Development methodology. Used NetBeans IDE  • Configuration and deployment of application on to Jboss application server  • Create and maintain Amazon EC2 instance that supports the companies Redmine project management site and Mercurial CM.  • Developed web presentation layer using jQuery, HTML and CSS according to internal standards and guidelines.  • Implemented Ajax with JQuery to refresh results from Ajax page.  • Used JavaScript for developing UI Components like Editable drop down, data-driven menu customizations.  • Developed internal application using Angular.js and Node.js connecting to Oracle on the backend.  • Created web application prototype using jQuery and Angular.JS  • Implemented MVVM in all interactive views using jQuery & Knockout.js and layouts in Bootstrap.  • Developed frontend widgets in Backbone.js and Handlebars.js  • Wrote stored procedures in Oracle PL/SQL for data entry and retrieval  • Used JPA with Entity Beans for interacting with Persistence Layer for CRUD operations.  • Worked in RDBMS implementation using SOAP, SQL, PL/SQL, MySQL on Oracle database.  • Implemented the Connectivity to the Data Base Server Using JDBC.  • Developed Dash-Board to monitor and report Cache Coherence Servers.  • Created distributed Oracle coherence domains, configuration and system design based on oracle coherence. Designed and implemented interface elements using Google Web Toolkit.  • Contributed to organization of testing and quality improvement process (JIRA, Confluence).  • Designed Interactive GUIs using Java Applets and Swing.  • Involved in Installation & Configuration of Cognos in distributed environments on Solaris.  • Configured glassfish server; Design shipping rate template upload UI using Adobe Flex and Developed Jasper report.  • Installed and configured a multi-server, clustered ILOG environment. Documented architecture and trained client administrators.  • Designed various design Workflow Modules using BPM (Business Process Modeler) to implement Business Logic and Business rules using Ilog, Jrules.  • Layout and design the overall architecture and migration approaches using Oracle ADF.  • Developed Rest architecture based webservices to facilitate communication between client and servers.  • Developed Servlets and Worked extensively on Sql  • Developed Dash-Board to monitor and report Cache Coherence Servers.    Environments:  Java, Machine Learning, GraphLab, Hadoop, Hive, Pig, AWS, R, Spark, Python, scikit-learn, J2EE, Spring, Hibernate, Struts, Jquery, Ajax, Sencha Extjs, Javascript, Node.Js, Angular.Js, Bootstrap, Backbone.js, Oracle,, Linux, Unix, Ruby, wordpress, drupal, Sr. ML Developer TIAA/CREF Insurance - New York, NY 2013 to 2015 TIAA, formerly TIAA - CREF (Teachers Insurance and Annuity Association - College Retirement Equities Fund), is a Fortune 100financial services organization that is the leading retirement provider of financial services for the academic, research, medical, cultural and governmental industries.    Responsibilities:  • Researched and implemented various (AI), artificial intelligence, Machine Learning Algorithms using R language.  • Devised a machine learning algorithm using Python for facial recognition.  • Worked on various methods including data fusion and machine learning and improved the accuracy of distinguished right rules from potential rules.  • Tested with various Machine Learning algorithms as Support Vector Machine, Random Forest, Trees with XGBoost concluded Decision Trees as champion model.  • Configured Spark streaming to get ongoing information from the Kafka and store the stream information to HDFS.  • Experienced in decommissioning the legacy systems.  • Written multiple Map Reduce programs to extract data for extraction, transformation and aggregation from different sources having multiple file formats including XML, JSON, CSV &other compressed file formats.  • Assisted with data capacity planning and node forecasting.  • Used python to read the AVRO file.  • Developed shell scripts to perform the incremental loads.  • Used HIVE join queries to join multiple tables of a source system and load them into Elastic Search Tables.  • Experienced in moving data from MULTIMEMBER'S to Hadoop.  • Architect, Designed and implemented key services within the project.  • Developed the spring AOP programming to configure logging for the application  • Designing Architecture, developing and implementing components of day-to-day for user Web Interface.  • Used Hibernate as the ORM tool to communicate with the database  • Application was developed in J2EE using MVC architecture.  • Implemented MVC architecture using Jakarta Struts framework,  • Designed and implemented Service Oriented Architecture, enterprise service bus, web applications, databases, data warehouses, business rules.  • Used Java/J2EE, MVC, DAO and Value Object Design Pattern for component architecture.  • Architected the design for reading XML files using Groovy.  • Architected mainframe modernization solutions using SOA/web services, middleware integration technologies and ESB based on JAVA/J2EE.  • Deployed the application under WebSphere application server and involved in resolving deployment issues.  • Design and implementation of web applications in Java and HTML5/Javascript using Eclipse, Swing, GWT, JPA frameworks; and GIT maven source code environments.  • Used Github repository for version control.  • Developed test cases and performed unit test using JUnit Framework.  • Agile and scrum process is used for tracking and developing the application.  • Design and development of components, such as Class, and Sequence diagram in UML  • Developed user interface using JSP, AJAX, JSP Tag libraries to simplify the complexities of the application.    Environments:  Machine Learning, Hadoop, Hive, AWS, R, Spark, Python, scikit-learn, Java, Spring, Hibernate, Struts, JSF, Node.Js, Angular.Js, Bootstrap, Backbone.Js, Sencha Extjs, Javascript, CSS, Ajax, Html5, DB2, Crud, PL/SQL, JDBC, Apache CXF, Soap, Mongo DB, Webservices, Eclipse, Websphere Portal, Git, Github, Junit, Scrum, UML, JSP, JSTL, Servlet, Maven Sr. Software Developer Wells Fargo - Fermont, CA 2012 to 2013 Wells Fargo & Company, a diversified financial services company, provides retail, commercial, and corporate banking services to individuals, businesses, and institutions. Its Community Banking segment offers checking, savings, market rate, and individual retirement accounts, as well as time deposits and remittances.    Responsibilities:  • Experience in gathering business requirements from customers, analyze them and point out the impacts.  • Created sessions, tasks and workflows using Alteryx.  • Used Alteryx to perform end to end ETL process which included developing mappings, extracting data from sources (Flat files & Oracle Database 11g), cleansing and transforming the data to specific business requirements/rules, and loading the data into the target.  • Worked on big data such as Streamline analytics for building predictive models inside Machine Learning using Scala, Python, and R.  • Created Technical Documentation for all the developed mappings.  • Used Apache Kafka for handling real-time user data feeds.  • Used Kafka Direct Stream API to connect Kafka with Spark Streaming.  • Developed Spark Streaming application in Java that connects to Kafka and fetches data in real-time.  • Used Kafka to load data streaming into HDFS.  • Experience working with spark machine learning and SPSS.  • Worked on Sequence files, RC files, Map side joins, bucketing, partitioning for Hive performance enhancement and storage improvement.  • Involving in Analysis, Design, Implementation and Bug Fixing Activities. Handling structured and unstructured data and applying ETL processes. Responsible for building scalable distributed data pipelines using Hadoop.  • Worked on developing ETL processes to load data from Oracle data source to HDFS Sqoop, perform structurally  • Worked on requirement gathering, analysis and translated them into technical design.  • Used Jenkins scheduler to schedule the ETL workflows.    Environments:  HDFS, Spark, ETL, Sqoop, Jenkins, Collabra, Oracle Database, Cloud era Distribution for Hadoop3(cdh3u5), Linux, Kafka, Maven Software Developer Cisco - Chicago, IL 2010 to 2012 The online dashboard of Early Warning reports enhance the productivity of its users by significantly reducing their data collection time and allows them to focus on scoping the initiatives. It will also provide a more holistic consolidated view for the comparison of data from multiple data sources.    Responsibilities:  • Developed eye catching MXML view components using Flex Builder.  • Used Cairngorm MVC Architecture to handle the events and to retrieve the data from the server.  • Responsible for design and development of user interface using Flex Layout and Navigation, Data grid menus, and skinning components.  • Used Cisco Cues charts for creating Bar charts, Line charts and Pie Charts to show the project specific performance metrics  • Integrated Flex with BlazeDS to communicate Server side Objects which was build using Spring Framework and Hibernate.  • Extensively used RemoteObjects to retrieve data from the remote server and perform required business functionalities from the front end.  • Used spring framework modules like Core container module, Application context module, Spring AOP module, Spring ORM and Spring MVC module.  • Configured Spring Application-Context.xml used by spring container to inject dependencies to java classes to optimize memory resources.  • Implemented Spring IoC (Dependency Injection) and Spring Aspect Oriented Programming (AOP) for the Business as well as Lookup Service Layer development.  • Developed / modified the model components to incorporate new business level validations.  • Responsible for the oracle schema design, generating various POJO objects and generating their corresponding Hibernate mappings (.hbm) files.    Environments:  Java , J2ee, Spring , Hibernate , Flex , Action Script, MXM, XML, XSD, Java script, Blaze DS , Cairngorm MVC Framework, IBM RAD, ClearCase, Oracle Software Developer United Parcel Service- GE 2008 to 2010 United Parcel Service (UPS) is the world's largest package delivery company and a provider of supply chain management solution.    Responsibilities:  • Involved in multi-tiered J2EE design utilizing MVC architecture Struts Framework, Hibernate and EJB deployed on Websphere Application Server connecting to an Oracle database.  • Worked on the Spring framework like Spring IOC and Spring DAO.  • Architectured, develop, deployment of front-end and presentation layer logic of sites using JSP, HTML/DHTML, CSS, and JavaScript.  • Develop software in JAVA/J2EE, EJB, Struts, XML, Oracle and Enterprise Architecture.  • Used iBATIS framework with Spring framework for data persistence and transaction management  • Expertise in MVC Architecture using JSF and Struts framework and implementing custom tag libraries.  • Used Spring framework for dependency injection and integrated with Hibernate and JSF.  • Developed the application under J2EE Architecture using Spring, Hibernate, Servlets and JSP  • Developed application infrastructure using GWT/GXT as the front-end architecture using AJAX.  • Used EJB, JMS, Java Script in enhancement of the product  • Used JQuery JavaScript libraries for providing richer user interface and facilitates asynchronous request invocations using AJAX.  • Create and maintain Amazon EC2 instance that supports the company's project management site and Mercurial as version control.  • Build and maintained a Selenium Regression test suite.  • Designed Use Cases using UML and managed the entire functional requirements life cycle using water fall model.  • Wrote Java programs, performed builds, monitored DB2 data and ran SQL.  • Responsible for development and support of Service Activation System (SAS) written in JSP, Servlets, Spring, Hibernate and Web Services.    Environments:  Java, J2EE, Spring, Ibatis, Struts , JSF, EJB, Jquery, My Sql, Toad, Sql Server, DB2, Apache Axis2, WSDL, Netbeans, Jboss, Clearcase, Mercurial, Selenium, Waterfall Model, UML, JSP, Servlet, ANT, XML, EMC Documentum, JIRA, Swing, Cognos Education M.Sc. in Computer Science Stanford University 2005 to 2008 Skills JAVA (10+ years), XML (9 years), ORACLE (8 years), JAVASCRIPT (7 years), SQL (7 years) Additional Information Skills  Languages Python, Java, Flex, JavaScript, PL/SQL, T-SQL, HTML, XML  Java Technologies Java, Spring, Hibernate, Servlets, JSP, EJB, Angular.JS, Ext.JS, Node.JS, Backbone.JS, Bootstrap.JS, jQuery, Dojo, React.JS.  Frame Works Struts and Spring.  Development Tools WSAD, Eclipse, ANT , Log4j, Rapid Application Developer, Dreamweaver and FrontPage.  ORM Hibernate.  Design and Modeling UML and Rational Rose.  Web Services SOAP, WSDL, UDDI.  Databases Oracle, SQL Server,DB2, MS-Access  Scripting languages Java Script, Shell Script  XML technologies DTD,XSD,XML, XSL, XSLT, SAX, DOM, JAXP  Version Control CVS, Clear case, SVN  Environments UNIX, Red Hat Linux, Windows 2000/ server 2008/2007, Windows NT, Windows XP.