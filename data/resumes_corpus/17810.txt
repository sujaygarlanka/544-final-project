Python Developer <span class="hl">Python</span> <span class="hl">Developer</span> Python Developer - IBM (Remote) Heidelberg, PA • Software Developer around 7 years of experience in software development with a deep understanding of technology trends with expertise in the core of complex technologies.  • Skillful involvement in Python by developing software's utilizing new tools, libraries utilized: Beautiful Soup, NumPy, SciPy, PySide, Pandas, Requests, xmltodict, Matplotlib, Pickle, Pandas data frame, urllib3, MySQL DB to improve software development process.  • Experience in developing Web Services (SOAP, Restful API's) in Python using XML and JAVA.  • Experience in working with various version control systems like GIT, CVS and SVN.  • Hands on experience in developing business processes and system solutions utilizing prototype development, system development, and deployment.  • Experience in using editors like Eclipse, sublime text, NetBeans, PyCharm, PyScripter, Spyder, PyStudio and PyDev.  • Used Django evolution and manual SQL modifications to retain all the data, while the site is in production.  • Experience in Linux Bash Scripting and PEP guidelines in python.  • Expertise in developing web-based open stack applications for large dataset analysis using Python and Django.  • Used Python Unit test framework for developing and implementing the unit tests using Test driven approach.  • Analyzed instrument pricing and modeling methodologies and documented how instrument prices move as a change in the market data source.  • Good Hands on experience in establishing connections for Java and Python by configuring packages like MySQL- Python, JDBC.  • Hands on experience in monitoring, developing and transforming data using SQL Server Integration Service(SSIS) and SQL Service Analysis Service(SSAS).  • Experienced in writing custom queries through database connectors.  • Hands on experience with databases using ORMs/DOMs for integrating with Oracle, MySQL, PostgreSQL.  • Good knowledge in working with Web/application server- Apache Tomcat (6.0, 7.0, 8.0), Tornado, CherryPy.  • Experienced with Object Oriented design methodology and Agile Methodology in software development.  • Used Pandas API to put the data as time series and tabular form for east timestamp data retrieval and manipulation and for statistical analysis. Authorized to work in the US for any employer Work Experience Python Developer IBM (Remote) January 2018 to Present Description:  The International Business Machines Corporation is an American multinational technology company headquartered in Armonk, New York, United States, with operations in over 170 countries. IBM manufactures and markets computer hardware, middleware and software, and provides hosting and consulting services in areas ranging from mainframe computers to nanotechnology.    Responsibilities:  • Developed Speech to text conversion using Google API  • Developed a script which can convert JSON to CSV  • Used pandas to convert a Python list of sentences to a series object using to-list method.  • Extracting data using regex and validations.  • Worked with Latin characters using uni-decode and simplejson libraries as a json decoder which can handles Unicode characters libraries.  • Used Unidcode to decode the Unicode string  • Worked on xml parser file.  • Developed codes which can fetch the data from two different REST API's and update the list of contact information in the desired API.  • Developed a different class which can perform add/delete members functionalities.  • Used requests library to access the information from API's using get request method  • Authorizing the API's using HTTP BasicAuth library  • Passing the arguments from command line to pull out the data based on modified date.  • Using my script as a base and inheriting the client file to access the API's URL's and client credentials from property file.  • Creating a new IBM Blue Pages group where user can store all his personal information.  • Accessing that created groups and giving access that group API to invoke to other users and use the information on demand.  • Involved in mapping the data from CSV and updating the list of data in API using REST services.  • Setting up the IBM Data Science Experience in local machines.  • Created Jupyter notebook under DSX and executed the scripts by splitting the code as per the requirement.  • Involved in the execution of CSV files in Data Science Experience.  • Major part is like being a part of the project, importing the converted CSV file to IBM internal API which is InfoSphere Information Governance Catalog  • Experienced with GIT version control and deployed the project to DSX.  • Knowledgeable with GIT version control.  • Written a wrapper class that will allow any group to update list of usernames based on demand using property file with CSV.  • Updating the information in JIRA with required details and uploading necessary information to finish that particular story.  • Supporting my team members in performance testing using JMeter and running the scripts in parallel.    Environment: Python 3.7, JavaScript, CSV, JSON, JIRA, DSX, Jupyter, HTTPBasicAuth, Pandas, GitHub, Requests, xmltodict, HTTP BasicAuth. Python Engineer Nike, OR May 2017 to December 2017 Description:  Nike is an American multinational corporation that is engaged in the design, development, manufacturing, and worldwide marketing and sales of footwear, apparel, equipment, accessories, and services. It is the world's largest supplier of athletic shoes and apparel and a major manufacturer of sports equipment.  Responsibilities:  • Converted data from PDF to XML using python script in two ways i.e. from raw xml to processed xml and from processed xml to .CSV files.  • Developing a generic script for the regulatory documents.  • Used python Element Tree (ET) to parse through the XML which is derived from PDF files.  • Data which is stored in sqlite3 data file (.db) were accessed using the python and extracted the metadata, tables and data from tables and converted the tables to respective CSV tables.  • Used the XML tags and attributes to isolate headings, side-headings and subheadings to each row in CSV file.  • Converted data from HTML to XML for couple of PDF regulatory documents.  • Used Beautiful Soup for web scraping (Parsing the data)  • Developed the code to capture the description which comes under headings of index section to the description column of CSV row.  • Used some other python libraries like PDFMiner, PyPDF2, PDF Query and Sqlite3.  • Converted the Unicode to nearest possible string (ASCII value) using Uni-decode module.  • Adding a column to each CSV row which gives the parent Index number of the given row.  • Examined framework determined specifications and had client interaction with requirements specifications.  • Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval.  • Experience on Jenkins continuous integration (CI) tool for deployment of the project.  • Used MySQL database for simple queries and writing Stored Procedures for normalization and de-normalization.  • Involved in development of Web Services using SOAP for sending and getting data from the external interface in the XML format.  • Experience in using collections in Python for manipulating and looping through different user-defined objects.  • Knowledge of Test Driven Development (TDD), Pair Programming with PyUnit, Junit and PythonUnit-test.  • Used Pandas API to put the data as time series and tabular format for east timestamp data manipulation and retrieval.  • Executed MYSQL database queries from python using Python-MySQL connector and MySQL dB package to retrieve information.  • Generated Python Django Forms to record data of online users  • Used Python and Django creating graphics, XML processing, data exchange and business logic implementation  • Designed and developed communication between client and server using Secured Web services such as Django-rest-framework.  • Documented the design solutions and created stories for client requirements.  • Utilized Python libraries like NumPy and Matplotlib for generating graphical reports.  • Build SQL queries for performing various CRUD operations like create, update, read and delete.  • Experience in working with a team of developers on python applications for RISK management.  • Improved code reuse and performance by making effective use of various design patterns.    Environment: Python2.7, 3.5, HTML5, CSS, JavaScript, AJAX, JSON, JIRA, Django, REST API, jQuery, MS Access, MS SQL Server, GitHub, Shell Scripting. Python Developer AMEX, NY - New York, NY September 2016 to April 2017 Description:  The American Express Company, also known as Amex, is an American multinational financial services corporation headquartered in Three World Financial Center in New York City. Project developed was a Business Tool focused to expand the customer base. It's a web based application which send emails to all the registered users on the deals and new products which are placed on the web and also predicting the values upon the matriculations.    Responsibilities:  • Wrote Python routines to log into the websites and fetch data for selected options. Used Python modules such as requests, urllib, urllib2 for web crawling.  • Used other packages such as Beautiful Soup for data parsing.  • Worked on writing and as well as read data from csv and excel file formats.  • Web-services backend development using Python (CherryPy, Django, SQLAlchemy).  • Worked on resulting reports of the application and Tableau reports.  • Worked on HTML5, CSS3, JavaScript, Git, REST API, Mongo DB, IntelliJIdea.  • Design and Setting up of the environment of Mongo dB with shards and replica sets. (Dev/Test and Production).  • Private VPN using Ubuntu, Python, Django, Postgres, Redis, Bootstrap, jQuery, Mongo, Git, Tenjin, Selenium.  • Performed QA testing on the application.  • Developed approaches for improving NLP pipeline.  • Create custom VB scripts for repackaging applications as needed. NLP File Prep Settlement-Prepare files for review for Settlement.  • Held meetings with client and worked all alone for the entire project with limited help from the client.  • Managed and reviewed Hadoop log file and worked in analyzing SQL scripts and designed the solution for the process using PySpark.  • Actively involved in developing the methods for Create, Read, Update and Delete (CRUD) in Active Record.  • Designing mobile search application system requirements and coded back-end and front-end in Python.  • Developed rich user interface using CSS, HTML, JavaScript, and jQuery. Created a Python-based GUI application For Freight Tracking and processing.  • Used Django framework for application development. Excellent knowledge of distributed storages (HDFS) and distributed processing (MapReduce, Yarn).  • Developed and maintained various automated web tools for reducing manual effort and increasing efficiency of the Global Shipping Team.  • Developed an automated testing framework for command-line based tests on Linux using Objected Oriented Perl and for selenium-based tests using Python.  • Created database using MySQL, wrote several queries to extract data from the database.  • Setup automated Cron jobs to upload data into the database, generate graphs, bar charts, upload these charts to the wiki, and backup the database.  • Wrote scripts in Python for extracting data from HTML file.    Environment: MySQL, HTML, Python, Django, HTML5, CSS, XML, MySQL, MS SQL Server, JavaScript, AWS, Linux, Shell Scripting, AJAX, urllib, urllib2, Json, CherryPy, Unix, Redis, Bootstrap, Mongo dB, SQLAlchemy, jQuery. Python Developer NBC Universal December 2015 to August 2016 Description: NBC Universal Media, LLC, a media and entertainment company, develops, produces, and distributes entertainment, news and information, sports, and other content for audiences worldwide. The company operates in four segments: Cable Networks, Broadcast Television, Filmed Entertainment, and Theme Parks. The Cable Networks segment offers a portfolio of cable television networks, including national cable entertainment networks, such as USA Network, Syfy, E!, Bravo, Oxygen, Sprout, Esquire Network, Chiller, Universal HD, and Cloo; national cable news and information networks comprising MSNBC, CNBC, and CNBC World.  Responsibilities:  • Django Framework that was used in developing web applications to implement the model view controller architecture.  • Exposure to Multi-Threading factory to distribute learning process back-testing and the into various worker processes.  • Performed efficient delivery of code based on principles of Test Driven Development (TDD) and continuous integration to keep in line with Agile Software Methodology principles  • Different testing methodologies like unit testing, Integration testing, web application testing  • Python/Django based web application, PostgreSQL DB, and integrations with 3rd party emailmessaging storage services.  • Developed a fully automated continuous integration system using Git, Gerrit, Jenkins, MySQL and custom tools developed in Python and Bash  • Design and implement custom scripts.  • Extensive use of version controller Team Foundation Server (TFS).  • Delivered automated solutions for science models  • Managed, developed and designed a dashboard control panel for customers and Administrators using Django, Oracle DB, and PostgreSQL.  • Implemented configuration changes for data models.  • Maintained and updated existing automated solutions.  • Handled potential points of failure through error handling and communication of failure.  • Troubleshoot the process execution and worked with other team members to correct them.  • Actively worked as a part of a team with managers and other staff to meet the goals of the project in the stipulated time.  • Performed troubleshooting, fixed and deployed many Python bug fixes of the two main applications that were the main source of data for both customers and internal customer service team  • Used Pandas library for statistics Analysis.  • Managed large datasets using Panda data frames and MySQL.  • Used advanced packages in AON PATHWISE for performing the unit test and deploying data models.  • Extensively used Python modules such as requests, urllib, urllib2 for web crawling.  • Developed GUI using webapp2 for dynamically displaying the test block documentation and other features of Python code using a web browser.  • Developed the required XML Schema documents and implemented the framework for parsing XML documents.  • Different testing methodologies like unit testing, Integration testing, web application testing, selenium testing was performed. Used Django framework for application development.  • Developed user interface using, CSS, HTML, JavaScript and jQuery& Ruby on rails.  • Assisted in the reduction of cost and optimization of supplier selection for the CRM Applications.  • Debug of custom software running on Windows and Linux operating systems.  • Professional minded with the ambition to advance both the product as well as themselves.  • Responsible for user validations on client side as well as server side.  • Automated the existing scripts for performance calculations using NumPy and SQLAlchemy.  • Interacted with QA to develop test plans for high-level design documentation.  Environment: Python 2.7, Django 1.4, HTML5, CSS, XML, MySQL, JavaScript, Angular JS, Backbone JS, jQuery, CSS Bootstrap, Mongo DB, T-SQL, JavaScript, Eclipse, Git, GitHub, AWS, Linux, Shell Scripting. Data Analyst/Data Modeler Accenture - Bengaluru, Karnataka May 2012 to July 2015 Description: Accenture PLC is a global management consulting and professional services company that provides strategy, consulting, digital, technology and operations.  Responsibilities:  • Developed end to end enterprise Applications using Spring MVC, REST and JDBC Template Modules.  • Written well designed testable, efficient java code.  • Understanding and analyzing complex issues and addressing challenges arising during the software development process, both conceptually and technically.  • Implemented best practices of Automated Build, Test and Deployment.  • Developed design patterns, data structures and algorithms based on project need.  • Worked on multiple tools such as Toad, Eclipse, SVN, Apache and Tomcat.  • Deployed models via APIs into applications or workflows  • Worked on User Interface technologies like HTML5, CSS/SCSS.  • Wrote Stored procedure and SQL queries based on project need.  • Deployed built jar into application server.  • Created Automated Unit Tests using Flexible/Open Source Frameworks  • Developed Multi-threaded and Transaction Handling code (JMS, Database).    Environment: Java, Spring MVC, Hibernate, MS, HTML5, CSS/SCSS, Junit, Eclipse, Tomcat and Oracle. Education Bachelor's Skills HTML, JAVASCRIPT, BOOTSTRAP, NODE.JS, PYTHON, MATPLOTLIB, NUMPY, PANDAS, SCRIPTING, XML, DATABASE, DB2, MYSQL, ORACLE, PL/SQL, SQL, SQLITE, CSS, SOA, TOMCAT