AWS/ Python Developer AWS/<span class="hl">Python</span> <span class="hl">Developer</span> AWS/ Python Developer - Ditech Financials • Over 7 years of experience in IT industry and experience working in Designing & Architecting solutions on public Cloud on AWS platform.  • Experience in Linux Administration, Configuration Management, Continuous Integration, Continuous Deployment, Release Management and Cloud Implementations.  • Highly experienced in AWS Cloud platform and its features which includes EC2, VPC, EBS, AMI, SNS, RDS, EBS, Cloud Watch, Cloud Trail, Cloud Formation, AWS Config, Auto scaling, Cloud Front, IAM, S3, and R53.  • Experienced in setting up Amazon EC2 instances, virtual private cloud (VPCs), and security groups.  • Setting up databases in AWS using RDS, storage using S3 bucket and configuring instance backups to S3 bucket.  • Helped customers deploying their applications in AWS cloud using Opsworks, Codedeploy, Elastic beanstalk, troubleshooting customer's cloud formation stacks.  • Installed, configured and maintained DNS systems using BIND, Route53 (AWS), Powering.  • Experience on Virtualization technologies like VMware, Vagrant.  • Experienced in understanding principles and best practices of Software Configuration Management (SCM) processes, which include compiling, packaging, deploying and Application configurations.  • Expertise in Administration of Production, Development and Test environment's carrying Windows, Ubuntu, Red Hat Linux, SUSE Linux, Centos and Solaris servers.  • Experience in Python Scripting in various projects for automating tasks.  • Experienced in branching, tagging and maintaining the version across the environments using SCM tools like GIT, Subversion (SVN) and TFS on Linux and windows platforms.  • Extensively experienced in using Build Automation tools like ANT, Maven, Gradle and working knowledge on other build tools like make file.  • Expertise in UNIX performance monitoring and kernel tuning and Load balancing to ensure stable performance.  • Experience in writing Python functions for AWS Lambda using S3 triggers to automate workflow.  • Experience in performance tuning at WebLogic domain level and OS level, performance tuned WebLogic heap, threads, JDBC and JMS subsystems.  • Managing and Monitoring the JVM performance by WebLogic Heap Size, garbage collection, JDBC Pools and taking Thread dumps and analyzing to find the problems in application.  • Good understanding of mapping the requirements, custom designing solutions & troubleshooting for complex software & application problems.  • An effective communicator with exceptional relationship management & analytical skills and problem solving and organizational abilities.  • Ensuring that all the requests (E-mail/instant messaging and ticketing tool) are addressed within SLA. Work Experience AWS/ Python Developer Ditech Financials - Fort Washington, PA December 2018 to Present Responsibilities:  • Worked Enterprise Data Program (EDP) project, which involves creation of a Data Warehouse which stores SCD type 2 data from multiple application databases and the data to be used by various reporting tools.  • Developed ETL scripts using PySpark libraries to extract data from SQL Server Database.  • Developed ETL scripts using PySpark libraries to load data into Amazon RDS (PostgreSQL).  • Created AWS Glue jobs to run the ETL code using connections and drivers for DB's.  • Developed Python code to create multiple Glue jobs.  • Used AWS Glue Triggers to schedule daily jobs.  • Developed Python code (Framework) which is used to log the job statistics into PostgreSQL table.  • Developed code to check and load the historical data from the source databases into Data warehouse.  • Developed VBA code to convert csv (Excel) data into json files which are used as parameter files for Glue jobs.  • Widely used boto3 library to store data files, schema files and run stats files to S3 and use them for finding historical data for future job runs.  • Worked on enabling SES and SNS notification services to alert the user about faulty runs, delayed runs and extracted data details.  • Developed Monitoring and reporting frameworks to constantly check for the overall process and log individual job reports.  • Worked on AWS Cloudwatch events to trigger AWS Glue reporting jobs for job failures or network errors.  • Worked on SSMS to extract DDL's and involved in framing complex SQL queries.  • Worked on SQL stored procedures as part of data migration from SQL server to PostgreSQL.  • Developed python scripts to update the content in database and manipulate files. AWS/ Python Developer Pfizer - Groton, CT June 2017 to December 2018 Responsibilities:  • Developed AWS Lambda python functions using S3 triggers to automate workflows.  • Developed Python scripts to upload and download objects to and from AWS S3 buckets.  • Developed RESTFUL web services using JAX-RS framework to query on PostgreSQL from web application.  • Worked on Elastic Search to index data into Indices and retrieve using Elastic queries and python scripts.  • Used Confluence and JIRA to report bugs, track work flows, create user stories, communicate with team members and other teams in the project.  • Written python scripts to pre-process file data before loading into Elastic Search.  • Created Elastic search indices with mapping definition to accommodate file metadata.  • Configured Tomcat and Apache web servers for reverse proxy redirection to UI application.  • Developed java web services for S3 file download and zip file download.  • Worked on enabling Single Sign On (SSO) for Data Commons application.  • Used pipeline pilot to create workflows, pre-process json data, metadata extraction and Elastic search ingestion.  • Maintained Elastic Cluster, granting permissions, Access configurations.  • Experience in using Bit Bucket for code deployment using provided Ansible scripts.  • Used Hadoop in the cycle of retrieving data from the central data repositories using agent services.  • Assisted with deploying datalake on docker containers to ingest files to PostgreSQL database.  • Created Google Cloud POC using compute engine, storage and cloud functions.  • Used python scripts to update the content in database and manipulate files.  • Developed preview functionality using data grid by streaming S3 bucket objects asynchronously.  • Involved in web application deployment on Tomcat web server, Installation of SSL certificates, Configuring Tomcat and Apache with DNS.  • Developed python code to manipulate-parse Jason data, index mapping and index json files into elastic indexes.  • Worked on BitBucket and Tortoise SVN as code repositories and TeamForge for version control.  • Developed Sci-Bite Termite API's to integrate it with front end application.  • Used Swagger Hub and Swagger Inspector to document API's.  • Managed PostgreSQL database within Amazon RDS, developed schemas and table versioning.  • Resolved Elastic Search tickets with configuration changes, granting Elastic Search access from different applications.    Environment: EC2, RDS, S3, Elastic Search, Pipeline Pilot, AWS Lambda, Python, Python (boto3),Apache, Tomcat Linux, Hadoop, MapReduce, Spark, PostgreSQL, Confluence, Jira, GIT, Docker, Google Cloud Platform, Data Grid, Powershell, Swagger Hub, Swagger Inspector, BitBucket, Tortoise SVN, TeamForge. AWS/ Python Developer Monsanto - St. Louis, MO April 2016 to May 2017 Responsibilities:  • Implemented AWS solutions using EC2, S3, RDS, EBS, Elastic Load Balancer, Auto scaling groups.  • Used IAM to create and manage AWS users and groups, and use permissions to allow and deny their access to AWS resources.  • Created scripts in Python which integrated with Amazon API to control instance operations.  • Assisted in migrating the existing data center into the AWS environment.  • Architect and support AWS Private Cloud implementation.  • Support and configured all cloud services including AWS Direct Connect to On-Premise datacenter  • AWS Integration with internal DNS  • Configure AWS Virtual Private Cloud to support application development and production.  • Architect and design AWS Private Cloud Subnets, Security Groups, Network Access Controls, configure AWS Elastic Load Balancing for application high availability and performance  • Design EC2 instance architecture to meet high availability application architecture and security parameters.  • Involved in setting up Disaster Recovery instance environment for current application.  • Used Python based GUI components for the front-end functionality such as selection criteria.  • Setting up Auto scaling of the instance group using AWS command line tools and AWS cloud environment for Dev/QA environments.  • Automated the Applications and MySQL container deployment in Docker using Python and monitoring of these containers using Nagios  • Reduced build + deployment times by designing and implementing Docker workflow.  • Configured Docker container for branching purposes.  • Comfortable and flexible with installing, updating and configuring various flavors of UNIX and Windows  • Developed Cloud Formation templates and deployed AWS resources on different environments.  • Experienced in setting up SNS on top of EC2, S3, RDS, Lambda to notify admins about activities via email.  • Documented all build and release process related items. Level one support for all the build and deploy issues encounter during the build process  • Worked on the cloud-based diagramming software called Gliffy for creating different types of design documents required for the continuous integration process  • Implemented & maintained the branching and build/release strategies utilizing GIT  • Responsible for writing the Release Notes, documenting all the useful info about the release, software versions, changes implemented in current release, Defects fixed, Labels applied.  • Strong understanding of infrastructure automation tooling (AWS cloud formation, EBS)  • Experienced in deployment of applications on Apache Web server, Nginx and Application Servers such as Tomcat, Oracle web logic sever.  • Implemented Puppet modules to Install, configure and maintain web servers like Apache Web Server , Nginx.  • Involved in periodic archiving and storage of the source code for disaster recovery.  • Development of SPLUNK Queries to generate the Report.    Environment: EC2, RDS, S3, IAM, VPC, Cloud Watch, Cloud Trail, Cloud Formation, SNS, EBS, Route 53, ELB, Amazon Machine image, Elastic Bean Stack, Python (boto), Shell scripting, Linux, MySQL, Jira, GIT, Elastic Search, Dockers, Rack Space. AWS/Devops Engineer Unisys - Ashburn, VA March 2015 to March 2016 Responsibilities:  • Build and configure a virtual data center in the Amazon Web Services cloud to support Enterprise Data Warehouse hosting including Virtual Private Cloud (VPC), Public and Private Subnets, Security Groups, Route Tables, Elastic Load Balancer.    • Continuously managed and improved the build infrastructure for global software development engineering teams including implementation of build scripts, continuous integration infrastructure and deployment tools.    • Leveraged AWS cloud services such as EC2, auto-scaling and VPC to build secure, highly scalable and flexible systems that handled expected and unexpected load bursts.    • Manage amazon redshift clusters such as launching the cluster and specifying the node type as well.    • Used AWS Beanstalk for deploying and scaling web applications and services developed with Java, PHP, Node.js, Python, Ruby, and Docker on familiar servers such as Apache, and IIS.    • Designed AWS Cloud Formation templates to create custom sized VPC, subnets, NAT to ensure successful deployment of Web applications and database templates.    • Implemented automated local user provisioning instances created in AWS cloud.    • Setup and build AWS infrastructure various resources, VPC EC2, S3, IAM, EBS, Security Group, Auto Scaling, and RDS in Cloud Formation JSON templates.    • Provide highly durable and available data by using S3 data store, versioning, lifecycle policies, and create AMIs for mission critical production servers for backup.    • Maintained the user accounts (IAM), RDS, Route 53, VPC, RDB, Dynamo DB, SES, SQS and SNS services in AWS cloud.    • Designed and implemented scalable, secure cloud architecture based on Amazon Web Services.    • Defined branching, labeling, and merge strategies for all applications in Git.    • Built Continuous Integration environment Jenkins and Continuous delivery environment.    • Utilized Configuration Management Tool Chef & created Chef Cookbooks using recipes to automate system operations.    • Build servers using AWS, importing volumes, launching EC2, RDS, creating security groups, auto-scaling, load balancers (ELBs) in the defined virtual private connection.    • Deployed applications on AWS by using Elastic Beanstalk.    • Used Ansible server and workstation to manage and configure nodes.    • Configured plugins for the integration tools to the version control tools.    • Manage source code, software builds, software versioning, & defect tracking on software maintenance tasks/projects    • Manage AWS EC2 instances utilizing Auto Scaling, Elastic Load Balancing and Glacier for our QA and UAT environments as well as infrastructure servers for GIT and Chef.    • Administered and Engineered Jenkins for managing weekly Build, Test and Deploy chain, SVN/GIT with Dev/Test/Prod Branching Model for weekly releases.    • Created monitors, alarms and notifications for EC2 hosts using Cloud Watch.    • Migrated applications to the AWS cloud.    • Involved in DevOps processes for build and deploy systems.    • Created Python scripts to totally automate AWS services which includes web servers, ELB, Cloud Front distribution, database, EC2 and database security groups, S3 bucket and application configuration, this script creates stacks, single servers, or joins web servers to stacks.    • Grasp the Technical aspects from High level to create Deployment plans, Contingency Plans and which direction to go if they hit a snag.    • Planned release schedules with agile methodology & coordinated releases with engineering & SQA for timely delivery.    • Troubleshoot the automation of Installing and configuring applications in the test environments.    Environment: AWS (EC2, VPC, ELB, S3, RDS, Cloud Trail and Route 53), VDI, Linux, Ansible, Git version Control, VPC, AWS EC2, S3, Route53, EBS, IAM, ELB, Cloud watch, Cloud Formation, AWS CLI, AWS Auto Scaling, Nagios, Subversion, Jenkins, Unix/Linux, Shell scripting. Linux Administrator ANZ - IN September 2012 to September 2014 Responsibilities:    • Installed, configured and Administrated of all UNIX/LINUX servers, includes the design and selection of relevant hardware to Support the installation/upgrades of Red Hat (5/6), CenOS 5/6, Ubuntu operating systems.  • Developed Cookbooks, Recipes, Resources and Run lists using chef and Ruby.  • Responsible for managing the Chef client nodes and upload the cookbooks to chef-server from Workstation.  • Used Agile/scrum Environment and used Jenkins, GitHub for Continuous Integration and Deployment.  • Used pearl, Python and Ruby as scripting language to automate the tasks.  • Used chef to configure/install web servers, database servers etc.  • Configured Red Hat Cluster Nodes for any legacy applications and verified the daily health check on the Cluster Nodes.  • Creating and modifying the manifest as per the requirement on puppet.  • Configured and Administered Apache, VSFTPD services, MYSQL and Tomcat.  • Participating in 24x7 production on-call support of Linux and provided technical support to users.  • Configured various alerts, captured support logs and configured resource pools utilizing Cisco UCS Manager.  • Implemented rapid provisioning and life cycle management for Redhat Linux using kickstart.  • Expertise in security hardening (iptables/selinux) major Production Servers, and compiling, building and installing web server based Linux tools.  • Experience in performing, uploading and upgrading new firmware on the Interconnects and Chassis.  • Implement and maintain internal systems key to DevOps operations such as database servers, continuous integration, and QA/Test servers.  • Expertise in creating VM Templates, cloning and managing Snapshots.  • Troubleshooting performance or configuration issues with MySQL and Oracle.  • Expertise in hardening, Linux Server and Compiling, Building and installing Apache Server from sources with minimum modules.  • Monitoring and troubleshoot backups and schedule Cron jobs.  • Experience in scripting using BASH & PERL, Mail Server, Samba Server, Apache Server.  • Worked on configuring NIS, NFS, DNS, DHCP, FTP, FSTP, Telnet and RAID levels.  • Experience in database replication using OCFS2 file system with oracle 10g and 11g database.  • Experience in deploying several sets of Linux guest builds from VMware templates using PowerCLIas well as Red Hat Satellite Server.  • Resolving assigned remedy tickets and remedy tools in Development/QA/Staging/Production.  • Patch management of servers and maintaining server's environment in Development/ QA staging/ Production.    Environment: RHEL 4.x/5/6, Solaris 9, 10&11, HPUX, Centos, SUSE 10, 11, VERITAS Volume Manager 3.x/ 4.x, VERITAS Storage Foundation 5, Redhat Cluster, VERITAS Cluster Server 4.1, Tripwire, NFS, DNS, SAN/NAS, Puppet, Chef, Splunk Jr. Linux Engineer Netcracker - IN October 2011 to August 2012 Responsibilities:    • Managed and administrated of all UNIX servers, includes Linux operating systems by applying relative patches and packages at regular maintenance periods using Red Hat Satellite server, YUM, RPM tools.  • Planned and performed the upgrades to Linux (RHEL 5x, 6x, SUSE 10, 11, CENTOS 5, 6, operating systems and hardware maintenance like changing memory modules, replacing disk drives.  • Handling NFS, Auto Mount, DNS, LDAP related issues.  • Monitoring CPU, memory, physical disk, Hardware and Software RAID, multipath, file systems, network using the tools NAGIOS 4.0 monitoring.  • Performing failover and integrity test on new servers before rolling out to production.  • Deployment and Configuration of application server Tomcat deploying Java and Web Application.  • Writing Shell scripts for automation of daily tasks, documenting the changes that happen in the environment and in each server, analyzing the error logs, analyzing the User logs, analyzing the /var/log/messages.  • Planned, scheduled and Implemented OS patches on Linux boxes as a part of proactive maintenance.  • Identify, troubleshoot, and resolve problems with the OS build failures.  • Used Chef for managing server application server such as Apache, MySQL, Tomcat.  • Installation, configuration, and customization of services Sendmail, Apache, FTP servers to meet the user needs and requirements.  • Performing kernel and database configuration optimization such that it limits I/O resource utilization on disks.    Environment: Red Hat Linux 5.x, 6.x, Autosys, CentOS, VMware vSphere 4.0, VMware ESX 3.5.0, GIT, Shell Scripting, MySQL, Tomcat, Nagios. Education Masters in Information Systems in Information Systems Stratford University - Fairfax, VA Bachelors in Information Technology in Information Technology Pondicherry University - Puducherry, Puducherry Skills Amazon web services, Git, Pvcs, Python, Reporting tools, Ruby, Scripting, Subversion, Apache, Linux, Unix, Tomcat, Web services, Weblogic, Mysql, Oracle, Postgresql, Change management, Nagios, Jboss Additional Information TECHNICAL SKILLS:  Operating Systems Windows, Linux, Unix, RHEL.  Databases Oracle, MySQL, MongoDB, PostgreSQL.  Scripting Languages Python, PowerShell, Shell, Ruby.  Cloud Platforms Amazon Web Services & Google Cloud Platform.  Version Controllers Perforce, Subversion, GIT.  Monitoring Tools Splunk, Nagios.  Change Management App dynamic, Service Now, PVCS Tracker.  Web/Application Servers Tomcat, Apache, Nginix, WebLogic, WebLogic, JBoss.  Bug Reporting Tools SDM-12, Bugzilla, JIRA and Rational Clear Quest.