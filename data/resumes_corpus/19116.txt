Sr. Python Software Engineer Sr. <span class="hl">Python</span> Software Engineer Sr. Python Software Engineer I desire to work with a creative and passionate team that are trying to solve hard problems. I can tackle  complicated algorithms, build complex distributed systems and setup deployment pipelines that are almost too  easy to manage. I love mastering the skills that I have and thrive on developing new ones. Work Experience Sr. Python Software Engineer DAQRI - Los Angeles, CA 2016 to 2017 DAQRI is developing cutting edge augmented and mixed reality hardware, software and content. This  includes active research on machine vision, machine learning, human computer interaction and holographics.  • I developed a streaming platform for collecting and analyzing EEG data from test subjects and later  expanded the platform for collecting IoT sensor data, logs and video data.  • Data was published to and from Kafka over MQTT. This required building custom Kafka connectors  (Java/Scala) and deploying a highly available linearly scalable Kafka cluster backed by Zookeeper.  • I Implemented several real-time analysis algorithms using Kafka Streams. I also connected Apache Spark  running as a cluster and consuming messages from Kafka to utilize the streaming SparkML functionality.  • I also set up a trial system streaming video data over ZeroMQ to a GPU based calculation engine running  on OpenCL  • All components, even the OpenCL engine which required direct GPU access, were containerized with Docker, built and unit tested within Jenkins for CI then published as images where they could be  deployed on demand to production with Rancher (itself setup using Terraform). This was all hosted with AWS, though it was designed to be portable to any hosting platform.  • Using Rancher any component in the system could be scaled up in seconds. VP Engineering GoodCall - San Francisco, CA 2015 to 2016 GoodCall automatically turns business email into a prioritized task list of the most important actions  needed to grow revenue and customers.  • As VP of Engineering at GoodCall I developed several natural language algorithms with NLTK to determine the intent within email, identify where an 'ask' was taking place, and extract the people  engaged in the email along with a rich data set describing their contact information.  • I Utilized the scikit-learn library to train models with data extracted from the NLP framework and classify years of email content.  • Consuming years of users emails required a solid work-horse, which I implemented with multi-threading  in Java using Spring and Hibernate. The Java agent fully utilized the Docker instance it ran on and could  be scaled out across multiple instances.  • I also developed an infinitely scalable platform, utilizing SQS queueing and S3 storage, high throughput  Java components, intelligent Python components utilizing the wealth of libraries available, a Node.js API  built for high performance asynchronous access and a data store comprised of DynamoDB, ElasticSearch and even a Graph Database (Neo4j) spanning multiple servers.  • I also developed all of the components using Docker and was able to create a simulation of the entire  production system on my laptop in less than a minute. Consultant iSentia - Sydney NSW 2013 to 2015 Australia)  • iSentia is the Asia-Pacific region's leading media intelligence company, providing over 5000 clients with media information, analysis and advice  • After BuzzNumbers (below) was acquired, I worked with iSentia to integrate the BuzzNumbers  collection and processing platform into the core of iSentia; collecting social media data for their flagship  MediaPortal product. As well as Singapore based Brandtology and other iSentia assets based in China.  • I proactively initiated the federated search project and worked with relevant stakeholders across the Asia- Pacific to complete the integration.  • I Led a team of five engineers to complete the project in just six months.  • Once the project was completed, I provided a federated social media collection system for all of iSentia's  assets. The company then executed a successful $500,000,000 IPO.  • The system developed at BuzzNumbers scaled seamlessly to the much larger demands of the iSentia  product group.  • Consulting continued in an advisory role and to provide training and support as the team was  transitioned in-house CTO BuzzNumbers - Sydney NSW 2010 to 2013 Australia)  • As CTO I was instrumental in the company's technical development, from the initial founding until the successful acquisition by iSentia.  • BuzzNumbers is a social media monitoring service that collects thousands of online mentions every  second. Each mention is then matched against hundreds of thousands of complex queries for a range of international clients. The platform provides real-time search and multi-dimensional reports across all  collected data.  • Responsibilities included designing the architectural blueprint for the platform, in addition to managing  and hiring the software development team, as well as project managing the agile development cycle.  • Further responsibility included a DevOps role to keep the system running 24/7 during times of exceptional growth.  • Success in this role required technical mastery of many skills including:  • Successfully leading a team of ten engineers and developers.  • Queuing platforms for stream processing the high quantity of collected data and dealing with traffic  bursts (RabbitMQ, PubNub, WebSockets)  • Custom development of cloud scaling platforms, including configuration, security and deployment  (Storm, Dome9)  • Realtime filtering of content according to non-trivial user submitted queries (Elastic Search)  • Natural language processing and analysis of collected content, including sentiment and topic discovery  ( Python)  • Developing patented algorithms to quickly determine the geographic origin of content based on their  meta data and text (C#)  • Utilizing scalable, searchable and distributed cloud storage for billions of records with real-time  indexation and multi-dimensional analysis capabilities. This included not only system design, but also monitoring, configuration, migration, and scaling operations across shards, partitions and clusters  (MongoDb, Solr, C#)  • Parallel processing theory for 100% utilization of all available resources (C#, Python, JavaScript) Lead Developer Mokoki - Newcastle NSW 2007 to 2009 Australia)  • Mokoki took an in-house Maps-to-Mobile application and extended it into a location-centric social  networking platform.  • Mokoki successfully partnered with 'MapMyIndia' to launch the Mokoki app on mobile phones across India with exclusive, relevant local map data.  • The Mokoki platform utilized an intermediary web server farm to optimize Google map tiles and deliver  them efficiently to a range of native mobile applications. This required utilizing Objective C for the iPhone, J2me for Java enabled phones, C++ for Symbian and Mono-touch to leverage the C# code base for  Android.  • Mokoki users needed the ability to quickly search for friends, events and places within geographic  regions. This required the development of a custom search engine and indexer for efficient retrieval of data based on both textual and spatial keys.  • A novel dynamic markup language similar to HTML was also developed, which could be deployed to the various mobile platforms and run using custom interpreters with rich and responsive native code.  • A leaner network layer that ran over UDP was also developed to improve on the standard interface  provided by the phones. This required a high performance massively parallel communication server which we developed. Software Developer Redback Solutions - Newcastle NSW 2005 to 2006 Australia) Lead Developer Ynot Technologies - Newcastle NSW 2003 to 2005 Australia) Director Cerebral Internet Solutions - Newcastle NSW 1999 to 2003 Australia) Education First Class Honours in breast cancer research State and national 2010 Bachelor of Computer Science (Hons) in Computer Science University of Newcastle 2000 to 2005