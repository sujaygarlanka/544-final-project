Jr. Hadoop Developer Jr. Hadoop <span class="hl">Developer</span> Jr. Hadoop Developer New Orleans, LA • 3+ years of professional experience in designing, development and deployment of big data projects.  • Hadoop written jobs to analyze data using HDFS, Map reduce, Hive, Impala, Spark, Hbase, Kafka, Flume and Oozie.  • Good Knowledge on 1.0 Architecture which include HDFS, Hadoop 2.0 Name Node, Data Node, Task Tracker, Job Tracker, Map Reduce, YARN.  • Experience in Data load management, importing & exporting data using SQOOP & FLUME.  • Experience in analyzing data using Hive, Pig and custom MR programs in Java.  • Experience in integrating Hive and Hbase for effective operations.  • Experience in scheduling and monitoring jobs using Oozie and Zookeeper.  • Experienced in writing Map Reduce programs & UDF's for both Pig & Hive in java.  • Experience in dealing with log files to extract data and to copy into HDFS using flume.  • Analyzed the SQL scripts and designed the solution to implement using Scala.  • Good Knowledge on Spark Architecture which include RDDs, API's of transformations and actions.  • Experience in writing Hive UDF's, queries.  • Experience in developing Applications in Python and Scala for Spark.  • Experience in writing Map reduce Applications using Java.  • Using Sqoop imported data from RDBMS to HDFS.  • Authorized to work in the US for any employer. Authorized to work in the US for any employer Work Experience Jr. Hadoop Developer Sixgen technology Hyderabad - Hyderabad, Telangana May 2014 to June 2015 Responsibilities  • Worked closely with team in converting Business requirements to Technical requirements.  • Imported required tables from RDBMS to HDFS using Sqoop.  • Transformed data using Spark based on requirement.  • Written spark applications using Python and Scala.  • Created H base tables to load large sets of structured data.  • Managed and reviewed Hadoop log files.  • Involved in providing inputs for estimate preparation for the new proposal.  • Worked extensively with HIVE DDLs and Hive Query language (HQLs).  • Developed UDF, UDAF, UDTF functions and implemented it in HIVE Queries.  Implemented SQOOP for large dataset transfer between Hadoop and RDBMs  • Used spark SQL for Analytics.  • Experience in Spark streaming.  • Scheduled automated jobs with the help of Oozie.  Environment: HDFS, Sqoop, Hadoop, Flume, Kafka, Map reduce, Hive, PIG, Oozie, HBase, Zookeeper, Cloudera, Oracle, NoSQL and Unix/Linu Jr. Hadoop Developer ISPACE - Hyderabad, Telangana April 2013 to May 2014 Responsibilities  • Imported required tables from RDBMS to HDFS using Sqoop.  • Transformed data using Map Reduce on requirement.  • Used Java for writing Map Reduce Jobs.  • Analyzed data using Hive and Impala.  • Worked with Hive Tables, Hive queries, Partitioning, Bucketing.  • Developed Data ingestion platform using Sqoop and Flume to ingest Twitter and Facebook data for Marketing & Offers platform.  • Developed and designed automate process using shell scripting for data movement and purging.  • Installation & Configuration Management of a small multi node Hadoop cluster.  • Installation and configuration of other open source software like Pig, Hive, Flume, Sqoop.  • Developed programs in JAVA, Scala-Spark for data reformation after extraction from HDFS for analysis.  • Written Hive jobs to parse the logs and structure them in tabular format to facilitate effective querying on the log data.  • Importing and exporting data into Impala, HDFS and Hive using Sqoop.  Environment: HDFS, Sqoop, Map Reduce, Hive, PIG, Oozie, Cloudera, CDH5, Oracle, NoSQL and Unix/Linux, Hadoop Python Developer Glance IT Solutions - Hyderabad, Telangana May 2012 to March 2013 Responsibilities:  • Designed views and templates with Django's view controller and templating language to create a web interface.  • Used on Django's API's to access database objects.  • Developed user interface using HTML, CSS, AJAX and JavaScript.  • Worked on API's deploying queries, status codes, requests to retrieve data in json format.  • Worked on data exchange from website using xml, java and web services.  • Performed on GUI programming using Tkinter.  • Worked onc scripts to parse XML documents and load the data in database.  • Coordinated with team members to improve quality assurance and mitigate risks.  • Wrote stored procedures in MySQL.  Environment: PyQT, Python 2.7 .NET, PyQuery, MVW, HTML5, Shell Scripting, JSON, Rest, Apache Web Server, SQL, UNIX, Windows, PostgreSQL, libraries such as Numpy, SQLAlchemy, Python etc. Education Masters Southern University at New Orleans 2017 Skills APACHE HADOOP SQOOP (2 years), Hadoop (2 years), HADOOP (2 years), Hive (2 years), Pig (2 years) Additional Information Skills  • APACHE HADOOP (3, YEARS), APACHE HADOOP SQOOP (3 Years), HADOOP(3+YEARS), Hive (3+ YEARS), PIG (3+ YEARS)