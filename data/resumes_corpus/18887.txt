partner data partner data partner data - Capital One • 5-6 years of experience as Python developer includes Python programming on Handling warnings,  Exception handling, Concrete exceptions, binary data services.  • Application designing skills using Python 2.x, Python 3.x.  • Application designing skills using Python, HTML.  • Hands on experience in developing web applications and implementing Model View Control (MVC)  architecture using server-side applications like Django, Flask.  • Complete Knowledge on SDLC models, Agile (scrum).  • Expert in writing SQL queries and optimizing the queries in Redshift and Teradata.  • Excellent knowledge in SQL and coding PL/SQL Packages, Procedures.  • Involved in designing, developing, testing, maintaining and supporting TABLEAU applications.  • Secured Tableau server on AWS to protect the Tableau environment using Amazon VPC, security  group, AWS IAM and AWS Direct Connect.  • Expertise in Normalization Techniques for Data Consistency and Flexible Database design.  • Accessing the files and directory, Data persistence, achieving and data compression.  • Handling file formats such as CSV, ZIP, HTML, JPEG and downloading files from web.  • Internet access through python, sending mail through python, opening web browser from python,  downloading documentation files, images through python.  • Internet protocols and support through python, Multimedia services.  • Architecture using Django, Flask python web application frameworks.  • Worked on different python IDE's: PyCharm, Sublime, Spyder and good knowledge on various  another IDE's.  • Hands experience of software development in Python (libraries used: libraries- Beautiful Soup,  numpy, scikit-learn, PyQt, scipy, matplotlib, python-twitter, Pandas data frame, network, urllib2,  MySQL db.  • Built various graphs for business decision-making using Python matplotlib library.  • Fetched twitter feeds for certain important keyword using python-twitter library.  • Setting up python REST API Frame work using Django.  • Good understanding of SAS programming, merging SAS datasets, preparing data, producing and  validating reports, SAS formats, and managing data.  • Hands on experience in data quality, data organization, metadata, and data profiling and large Data  set sizes.  • Ability to move data between production systems and work on cross/multiple platforms.  • Responsible for the design, development and administration of analytical data processes.  • Experience in analyzing the claims data, future trends and summarized results to generate  recommendations for management. Hands-on experience in building web and enterprise applications  in various domains like Health, Banking/Financial Services, Insurance, Public Sector, and Software  Service verticals. Work Experience partner data Capital One May 2017 to Present May 2017 to Present    Project: Description: The project is about moving data from existing Teradata, Whirl, SAMgw to Redshift. Some of the processes must be converted so that they are compatible to run on AWS Redshift.  Code porting is a part of the project. We are working for Capital One LOB, as part of it we have different  partner data, different clusters on redshift, assorted brands available on different VPC, branded card data,  NPI, NNPI etc.    Responsibilities:  • Responsible for the design, development and administration of analytical data processes.  • Included within those responsibilities are the areas of data access and delivery technologies.  • Includes expertise in data quality, data organization, metadata, and data profiling.  • Data set sizes are usually huge (more than hundreds of millions of records).  • Demonstrated ability to move from one sequential assignment to the next (work environment and priorities can change quickly depending on business needs).  • Demonstrated ability to move data between production systems and across multiple platforms.  • Working substantially with little supervision or oversight to deliver key milestones.  • Ability to deliver highly technical information to an analyst team to support their own system migration  responsibilities.  • Working on Agile Kanban.  • First line of project to be completed by October (Kohls Fusion Data). Data Analyst/ Python Boeing Toolbox - Allentown, WA November 2016 to April 2017 Responsibilities  • Working linux based environment.  • Redesigned web server architecture and implemented using python and flask frameworks.  • Creating web service layer using web frameworks like flask.  • Implemented rest services like rest post and get methods and integrate them with external  authentication services like radius.  • Written SQL queries in SQL Server, AWS's Redshift environment using SQL Management Studio.  • Created cloud analytics platform using Aws and Tableau server.  • Involved in connecting the Tableau to amazon redshift to increase speed, flexibility, and scalability.  • Advanced web development experience with Python  • SAS functions for almost any statistical operation / model building for python frameworks like Flask,  Pandas.  • Using huge array of statistical functions from SAS which good GUI.  • Using get and post API which exposes the primary part of the code.  • As a part of migration, we are performing migration of new sets of frameworks, apps and data to AWS.  • Focusing more on web based services like flask frameworks, which contains both post and get  methods.  • Some API's are already there in legacy system and migration of legacy systems to AWS.  • Worked extensively on Multithreading and Concurrency for implementing Batch  • Backend database as SQL for the development and test environment. Having data backups on MongoDB, Oracle and Teradata databases.  • Experience in creating Materialized Views, Views, Lookups for the Teradata warehouse.  • Provided architecture/development for initial load programs to migrate production databases from Oracle data marts to Teradata data warehouse.  • Worked on validating the code and developed SQL queries.  • Working with SQL database, creating, executing, modifying, and deleting stored procedures.  • Executing the stored procedures code in SQL files.  • Writing, handling stored procedures in complex tasks in single and multiple blocks.  • Implemented the presentation layer with HTML, CSS and JavaScript.  • Developing a web application written in python/flask in windows and deploying to a Linux servers.  • Used python scripts to update content in the database.  • Manipulate CVS files like looping through rows, extracting information, handling lists etc.  • Generated Python flask forms to record data of online users for application setup, setting up user  accounts, templates, static files etc.  • Testing (unit and integration), debugging and error handling.  Using version control systems like GIT (windows). Python Developer Experian - Irvine, CA October 2015 to October 2016 Responsibilities:  • Developed web applications in Django, Flask and Pandas Framework's model view control (MVC)  architecture.  • Extracted, transformed, and loaded data using SAS, PETL.  • Involved in analysis, development, testing, implementation, and provided technical support to business needs using SAS in Unix environment  • Tested and automated SAS jobs running on a daily, weekly and monthly basis using Unix Shell  Scripting  • Ensured the validity and accuracy of the analyzed data  • Created python scripts for file transfer and file manipulation  • Created stored procedures that would generate ad-hoc reports based on parameters passed  • Coordinated with the other teams to deliver the data to the clients on time  • Used SAS/ODS to produce RTF and HTML reports  • Submitted SAS/ queries in Unix shell to validate data  • Raised queries on the existing Oracle and SQL Server databases to provide ad-hoc reports using  SAS/SQL  • Working with SQL database, creating, executing, modifying, and deleting stored procedures.  • Executing the stored procedures code in SQL files.  • Hands on experience using SQL queries.  • Involved in the development of different datasets according to the user specifications for various  applications  • Analyzed the data for future trends and summarized results to generate meaningful recommendations  to management  • Written Macros to develop a concise and reusable code. Used Pandas library, R language and SAS  for statistics Analysis.  • Managed large datasets using Panda data frames and MySQL.  • Extensively used python modules such as requests, urllib, and urllib 2 for web crawling. Python Developer PayPal - San Jose, CA September 2014 to October 2015 Responsibilities:  • Worked on designing, coding and developing the application in Python using Django, Flask and Pandas MVC.  • Developed dashboard using Highcharts Python script library.  • Developed Django for dynamically displaying the test block documentation and other features of python code using a web browser.  • Used Django configuration to manage URLs and application parameters.  • Used Pandas ( Python library) with (SAS) Statistical Analysis.  • Experience in working with Python ORM Libraries including Django ORM, Sqlalchemy.  • Used standard Python Modules e.g. CVS, Robotparser, itertools, pickle, jinja2, lxml for development.  • Wrote and executed various MYSQL database queries from python using Python MySQL connector  and MySQL dB package.  • Written scripts in Python for extracting data from HTML file.  • Utilize PyUnit, the Python Unit test framework, for all Python applications.  • Created most important Business Rules which are useful for the scope of project and customer  needs.  • Used Collections in Python for manipulating and looping through different user defined objects.  • Improved code reuse and performance by making effective use of various design patterns.  • Creating database schema for MySQL Database and helped to draw ER-Diagrams using Microsoft  Visio.  • Performed troubleshooting, fixed and deployed many Python bug fixes of the two main applications  that were a main source of data for both customers and internal customer service team. Python Developer Williams Companies, Inc - Tulsa, OK August 2013 to August 2014 Responsibilities:  • Used petl package to extract, Transform and Load tables of data.  • Utilized Python libraries wxpython, numpy, Twisted and matplotlib.  • Implemented sqlalchemy which is a python library for complete access over SQL.  • Worked with data sets in the Terabyte size using SAS - Extensive experience in Base SAS including  PROC SQL.  • Worked on ElementTree XML API in python to parse XML documents and load the data in database.  • Developed views and templates with Python and Django's view controller and templating language to create a user-friendly website interface.  • Used Django configuration to manage URLs and application parameters.  • Accessed database objects using Django Database APIs.  • Created database using MySQL, wrote several queries to extract/store data.  • Identified several hidden bugs caused by complicated multithreading issues such as rare conditions  caused by asynchronous events and resolved them.  • Deployed the project into Heroku using GIT version control system.  • Responsible for debugging and troubleshooting the web application.  • Took part in the entire project's lifecycle which includes Design, Development and Deploying, Testing,  Implementation and support.  • Used Design patterns efficiently to improve the code reusability. Python developer Onward technologies ltd - Mumbai, Maharashtra January 2013 to March 2013 Responsibilities:  • Work with team of developers on python applications for RISK management.  • Design, develop, deploy and maintain the website.  • Written python scripts to parse XML documents and load the data in database.  • Responsible for debugging and troubleshooting the web application.  • Developed views and templates with python and Django's view controller and template language to create a user-friendly website interface.  • Python, Django1.3, MySQL,  • Responsible to manage data coming from various sources.  • Installed and configured Zookeeper for Hadoop cluster.  • Wrote Hive queries for data analysis to meet the business requirements.  • Created Hive tables and working on them using Hive QL. Education Master's in Computer Software Engineering in Computer Software Engineering Oklahoma Christian University Bachelor's in Information Technology in Information Technology GITAM University Skills Django (3 years), HTML (2 years), Python (3 years), SAS (3 years), Serial Attached SCSI (3 years) Additional Information TECHNICAL SKILLS  • Programming Languages: Python.  • Web Technologies: HTML, CSS, Java Script, XML.  • Frameworks: Django, Flask.  • Testing Tools: Selenium and JIRA.  • AWS: AWS (EC2/Redshift/S3/IAM)  • IDE's/ Development Tools: PyCharm, Ultra Edit.  • Analytic Tools: SAS.  • Databases: Redshift, Teradata and Snowflake.  • Version Control: GitHub.  • Operating Systems: Windows, Unix, RedHat Linux.  • Other: Shell, DATADOG, SAS, Shell