Data Science Analyst Data Science Analyst Data Science Analyst San Francisco, CA • 7 Plus years of IT industry experience encompassing a wide range of skill set.  • Over 4 plus years of experience with Statistics, Data Analysis, Machine Learning using Rlanguage and Python.  • Strong with ETL, Data warehousing, Data Store concepts and OLAP technologies.  • Worked in Amazon Web Services cloud computing environment.  • Experienced in SQL programming and creation of relational database models.  • Experienced in creating cutting edge data processing algorithms to meet project demands.  • Worked with applications like R, SPSS and Python to develop neural networkalgorithms, cluster analysis.  • Worked with packages like ggplot2 and shiny in R to understand data and developing applications.  • Worked on Tableau, QuickViewto create dashboards and visualizations.  • Automated recurring reports using SQL and Python and visualized them on BI platform like Tableau or QuickView.  • Strong experience working with SQL Server 2008, RStudio, MATLABOracle10i, Sybase.  • Worked on Statistical models to create new theories and products.  • Experience working with statistical and regression analysis, multi-objective optimization.  • Worked with python libraries like matPlotLib, wxPython and numPY  • Designed and implemented supervised and unsupervised machine learning.  • Identify problems and provide solutions to business problems using data processing, data visualization and graphical data analysis.  • Developed predictive models using Decision Tree, Random Forest and Naïve Bayes.  • Solid knowledge of mathematics and experience in applying it to technical and research fields.  • Identifying areas where optimization can be efficient.  • Worked with clients to identify analytical needs and documented them for further use.  • Developed predictive models using Python&R to predict customers churn and classification of customers.  • Used spring framework to design architecture of the application as per requirements.  • Query optimization, execution plan and Performance tuning of queries for better performance in SQL.  • Worked on Shiny and R application showcasing machine learning for improving the forecast of business.  • Used technologies like JQuery for java script manipulations and bootstrap for the front-end html layout.  • Worked on Designing and configuration of the database and back end applications and programs.  • Developed user interface using HTML/CSS, JavaScript and JQuery.  • Hands on experience with Dimensional tables and Operational Data Store.  • Excellent communication, analytical & troubleshooting skills. Work Experience Data Science Analyst Medtronic, North 2014 to October 2015 Description:Analyze data reports to identify and intercept trends or patterns. Communicate issues that affect productivity to Management and improving existing processes.  Responsibilities:  • Grouping customers & predicting churn rate for a car ride-share application.  • Developed a movie recommender based on users' movie ratings using matrix techniques.  • Created a fraud prediction model for a ticketing site using a boosted tree classifier.  • Development application UsingDjango framework and Flask framework.  • Developed user interface using CSS, HTML, JavaScript and JQuery.  • Worked on a reduction of cost and optimization of CRM Applications.  • Cleaned and processed data using python libraries.  • Worked with python libraries like matPlotLib, wxPythonand numPY.  • Built database mapping classes using Cassandra and Django models.  • Used Pandas API for analyzing time series.  • Designed and developed RDBMS using MySQL.  • Used Panda API for east timestamp data manipulation and retrieval.  • Creating regression test framework for new code.  • Used technologies like JQuery for java script manipulations and bootstrap for the front-end html layout.  • Took care of debugging and troubleshooting the web applications.  • Developed, tested and debugged tools utilized by clients and end-users.  • Worked with internal teams within the project to convert end user feedbacks into improved solutions.  • Coded programs and evaluated existing data processes.  • Worked on Designing and configuration ofthe database and back end applications and programs.  • Researched to identify and explore new technological platforms.  • Resolved Several problems and documented troubleshooting documents.  Environment: Python 2.7, scipy, Pandas, Bugzilla, Red hat Linux, Apache Spark, Cassandra, SVN, Linux, Eclipse, Shell Scripting, JQuery, MySQL, HTML5/CSS. SQL developer Owens Corning - Toledo, OH July 2013 to April 2014 Description: Authored database procedures and triggers for data processing, developed and modified applications.  Responsibilities:  • Worked on requirements gathering, analysis, design, change management and deployment.  • Developed and Designed forms using Visual Basic with ODBC.  • Automated the process of rebuilding indexes at regular interval for better performances.  • Generated reports that can handle both dynamic grouping and sorting.  • Generated reports using Crystal Reports.  • Developed E-R diagrams (logical and physical) using Erwin mapping the data into the database.  • Worked in dimensional modeling to design the data warehouse.  • Query optimization, execution plan and Performance tuning of queries for better performance.  • Worked with clients regarding system requirements and ensuring the development of customized products to user satisfaction.  • Created Tables, Indexes, Table Spaces and integrity constraints.  • Worked in UNIX Environment.  Environment: SQL Developer, SQL Navigator, Informatica Power Center 9.x., Oracle 11g/12c, SQL, PL/SQL, MySQL Workbench, Oracle Hints, UNIX Python Developer PIMCO - New York, NY November 2012 to June 2013 Description:  Designed and implemented predictive analytic models for monitoring the equipment using Python libraries like pandas, NumPy and SciPy.  Responsibilities:  • Programmed utilities in Python that uses packages like scipy, numpy, pandas.  • Used spring framework to design architecture of the application as per requirements.  • Estimation and Requirement Analysis of project timelines.  • Developed batch processors based on python to produce and consume various feeds.  • Generated Pdf reports daily and Monthly using Aspose PDF Kit.  • Written python scripts to parse XML documents and load the relating data into a database.  • Developed front end page using HTML, CSS, JavaScript and JQuery.  • Generating property list each and every application using python.  • Collecting the several functions and usage models from colleagues.  • Developing and maintaining a tool that abstracts information for the customer.  • Developing XMLs for components which maintain data for many registers.  • Developed and designed SQL procedures and Linux shell scripts for data export/import and for converting data.  • Developed internal web apps using Python Flask framework with the help of HTML /CSS framework.  • Used Test Driven Development (TDD) for the project.  • Written SQL Queries, Store Procedures, Triggers and functions for MySQL Databases.  • Involved in Creation of database access layer using JDBC and PL/SQL stored procedures.  • Coordinate architects and senior technical staff to identify client's needs and document assumptions.  • Build-out new requirements and move code through user acceptance testing.  Environment: Python, C++, HTML, CSS, TDD, SQL, MYSQL and Windows. Data Analyst 5.Cyient Ltd - Hyderabad, Andhra Pradesh January 2011 to October 2012 Worked on a project that classified images using a neural network. My job included evaluating, identifying and programming a utility to improve image classification performance. I identified duplicate images manually and then programmed the detection utility in R and Python. Identified the accuracy of detection across a range of input values.  Responsibilities:  • Developed business process models using MS Visio to create case diagrams and flow diagrams to show flow of steps that are required.  • Worked with other teams to analyze customers to analyze parameters of marketing.  • Used MS Excel, MS Access and SQL to write and run various queries.  • Used traceabilitymatrix to trace the requirements of the organization.  • Recommended structural changes and enhancements to systems and databases.  Environment: UNIX, SQL, Oracle 11g/12c, MS Office, MS Visio Data Stage Developer Birla Soft - Hyderabad, Andhra Pradesh 2009 to December 2010 Description: Participated in designing system and coordinate with business groups in order to define the requirements and develop plans and schedules.  Responsibilities:  • Developed ETL processes for data conversions and construction of data warehouse using IBM InfoSphere DataStage.  • Used Star Schema and designed Mappings between sources to operational staging targets.  • Provided On-call Support for the project and gave a knowledge transfer for the clients.  • Used Rational Application Developer (RAD) for version control.  • Developed transformations using jobs like Filter, Join, Lookup, Merge, Hashed file, Aggregator, Transformer and Dataset.  Environment: IBM Rational Clear Case & Clear Quest and IBM InfoSphere Metadata Workbench 8.7,IBM InfoSphere DataStage and Quality Stage 8.7/8.1/8.0.1/7.5.2, IBM InfoSphere CDC version 6.5.1, XML files. R Programmer / Data Scientist 1.Actelion Pharmaceuticals - San Francisco, CA Description:  Worked as a part of Analytical Group and worked on development and designing of statistical models for the client. Coordinated with end users on designing and implementing data solutions as per project requirements.  Responsibilities:  • Conducted research on development and designing of sample methodologies, and analyzed data for pricing of client'sproducts.  • Investigated market sizing, competitive analysis and positioning for product feasibility.  • Worked on Business forecasting, segmentation analysis and Data mining.  • Automated Diagnosis of Blood Loss during Emergencies.  • Developed Machine Learning algorithm to diagnose blood loss.  • Generated graphs and reports using ggplot package in RStudio for analytical models.  • Developed and implemented R and Shiny application which showcases machine learning for business forecasting.  • Developed predictive models using Decision Tree, Random Forest and Naïve Bayes.  • Performed time series analysis using Tableau.  • Collaborating with dev-ops teams for production deployment.  • Worked in Amazon Web Services cloud computing environment.  • Worked with Caffe Deep Learning Framework.  • Developed various workbooks in Tableau from multiple data sources.  • Created dashboards and visualizations using Tableau desktop.  • Created dashboards in QuickView to visualize data.  • Worked on R packages to interface with Caffe Deep Learning Framework.  • Performed analysis using JMP.  • Perform validation on machine learning output from R.  • Written connectors to extract data from databases.  Environment: R, Python, R Studio, Shiny Excel 2013, Amazon Web Services, Machine Learning, Tableau, QuickView, JMP, Segmentation analysis Education technology SRM University - Chennai, Tamil Nadu Skills databases. (2 years), Oracle (2 years), Python (4 years), SQL (3 years), UNIX (2 years) Additional Information TECHNICAL SKILLS:    Languages R, C#, VB.NET, VC++, Java, PL/SQL, Matlab  Scripting Python, Unix Shell Scripting, Perl  Development Tools RStudio, Visual Studio.NET 2015, Eclipse, Quest - SQL Navigator, Tableau, QuickView  Data Science/Big data Statistical Analysis, Machine Learning, Data Mining, Hadoop 2.x, HBase 1.2, HDFS, NoSql, HBase  Operating Systems Windows 10.0, UNIX with Sun Solaris 8.0, HP-Unix  Databases MS SQL Server 2005, Oracle 11g, Sybase  Web Technologies Silverlight, AJAX, ASP.NET, Java Script, (IIS) 7.0, AWS (Amazon Web Services)  Others .NET 4.5, WPF, WCF, XAML, LINQ, MS Team Foundation Server(TFS), SSRS, Infragistics/Telerik Toolkit