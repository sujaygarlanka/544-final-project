Python/Big Data Engineer <span class="hl">Python</span>/Big Data Engineer Python/Big Data Engineer Aldie, VA Authorized to work in the US for any employer Work Experience Python/Big Data Engineer Next Shift Health LLC - Bethlehem, PA October 2017 to May 2018 Worked on parsing of multiple log files, segregating the data based on certain attributes and uploading the data into DynamoDB  table on Amazon Web Services. Wrote regular expression to parse files of different formats.  • Managed Hive tables in an Big Data environment while facilitating transfer of data between HDFS to RDBMS and vice versa.  Processed and stored the files in Avro, Parquet, ORC and JSON formats as per the requirement for further processing.  • Created Hive Staging tables as a temporary directory for transfer of data between Hive Database and RDBMS. Worked with Big  Data distributions such as Cloudera and Hortonworks.  • Wrote Python Spark application to join two disparate datasets and utilized Spark API's to perform transformations and actions on the subset data. Used Unit Testing on python code.  • Spark RDD's, DataFrames were used for processing the data from Data Lake. Data transformed from python collections, textfiles and converted to Key-Value pairs for Spark API processing.  • Utilized Apache Solr for tabular and text search on Files and Data stored in Hadoop Distributed File System.  • Used Flume and Kafka for streaming analytics processing of web server logs and store the data collected into HDFS for analysis. Application Programmer Analyst Intern Best Docs Live Inc - Plano, TX December 2015 to May 2017 Worked as a Python/Django Developer. Built a back-end API with Django Rest Framework to handle user accounts and registrations. Collaborated with Senior Developer to handle complicated issues related with deployment of Django based  applications. Resolved ongoing problems and documented progress of Python project.  • Developed pages for cross browser and cross platform compatibility. Utilized Browser Stack to test for compatibility.  • Wrote Python program to parse and upload csv files into PostgreSQL Database. HTTP Request Library was used for Web API call.  Maintained both Dev and Production Databases in PostgreSQL environment. PostgreSQL DB was setup in Amazon Web Services.  Data was Stored in HIPPA complaint servers.  • Deployed the application in Amazon Web Services. Have experience in Amazon EC2, RDS, S3, Lambda, Elastic Beanstalk and  Route 53. AWS Cloudfront was used as CDN to transfer data with low latency and high transfer speeds. SQL Developer Mahindra and Mahindra Financial Services - Delhi, Delhi August 2011 to May 2014 • Designed Database using different forms of relationships. Documented and maintained database system specifications, diagram and connectivity charts. Work with application developers to identify business needs and discuss solution options.  • Designed and configured database and back-end applications and programs. Build and maintain SQL scripts, indexes and complex  queries for data analysis and extraction. Ran SQL Queries to back up the data from Hand-held devices and perform maintenance.  • Worked closely and effectively with vendors to replace/repair defective hardware and software. Education Master of Science in Computer Information Science THE UNIVERSITY OF TEXAS AT DALLAS - Dallas, TX May 2017 Bachelor of Engineering in Electronics and Communications ANNA UNIVERSITY May 2011 Skills PYTHON (2 years), WEB SERVICES (2 years), AWS (1 year), DATABASES (1 year), DJANGO (1 year) Links https://github.com/rjshekar90 https://www.linkedin.com/in/rajashekar90 Additional Information Technical Skills  • Languages: Python, Scala, Java, Restful Web Services  • Frameworks: Spark, Hadoop, Django, Flask, ElasticSearch, AWS Elastic Map Reduce  • Databases: MySQL, PostgreSQL, Oracle, MongoDB, Hive, AWS Redshift  • Tools: PyCharm, IntelliJ IDEA, DataGrip, Apache Sqoop & NiFi, GIT, JIRA