{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    DPRContextEncoder,\n",
    "    DPRQuestionEncoder,\n",
    "    DPRContextEncoderTokenizer,\n",
    "    DPRQuestionEncoderTokenizer,\n",
    ")\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import faiss  # make faiss available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\n",
    "    \"facebook/dpr-question_encoder-single-nq-base\"\n",
    ")\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\n",
    "    \"facebook/dpr-ctx_encoder-single-nq-base\"\n",
    ")\n",
    "\n",
    "\n",
    "def encode(tokenizer, encoder, text):\n",
    "    with torch.no_grad():\n",
    "        tokenized_output = tokenizer(\n",
    "            text, return_tensors=\"pt\", padding=\"max_length\", max_length=512, truncation=True\n",
    "        )\n",
    "        input_ids = tokenized_output[\"input_ids\"]\n",
    "        attention_mask = tokenized_output[\"attention_mask\"]\n",
    "\n",
    "        return F.normalize(encoder(input_ids.to(device), attention_mask.to(device)).pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"resume\": [], \"categories\": []}\n",
    "df = pd.DataFrame(data)\n",
    "START_INDEX = 10000\n",
    "\n",
    "# Iterate through a folder of text files and extract the text\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "# Define the directory\n",
    "dir_path = \"./data/resumes_corpus\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(dir_path)[START_INDEX:]\n",
    "\n",
    "# Iterate over each file\n",
    "for file in files:\n",
    "    if file.endswith(\".txt\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        file_path_label = file_path.replace(\".txt\", \".lab\")\n",
    "        data = {\"resume\": [], \"categories\": []}\n",
    "\n",
    "        # Open the file\n",
    "        with codecs.open(file_path, \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "            # Read the file's contents\n",
    "            resume = f.read()\n",
    "            data[\"resume\"].append(resume)\n",
    "\n",
    "        with codecs.open(file_path_label, \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "            # Read the file's contents\n",
    "            content = f.read()\n",
    "            content = content.split(\"\\n\")\n",
    "            if \"\" in content and len(content) == 1:\n",
    "                continue\n",
    "            elif \"\" in content:\n",
    "                content.remove(\"\")\n",
    "            data[\"categories\"].append(content)\n",
    "\n",
    "        new_row_df = pd.DataFrame(data)\n",
    "        # Add the new row to the DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_memory_usage(tensor):\n",
    "    print(tensor.element_size() * tensor.nelement() / 1024 / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_stats():\n",
    "    print(torch.cuda.memory_allocated() / 1024**2)\n",
    "    print(torch.cuda.memory_cached() / 1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(label, result):\n",
    "    return sum([label in x for x in result[\"categories\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Security_Analyst', 'Systems_Administrator', 'Project_manager',\n",
       "       'Database_Administrator', 'Software_Developer',\n",
       "       'Front_End_Developer', 'Web_Developer', 'Java_Developer',\n",
       "       'Network_Administrator', 'Python_Developer'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = df[\"categories\"].explode().unique()\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_subset(index, xq, subset):\n",
    "    n, _ = xq.shape\n",
    "    _, k = subset.shape\n",
    "    distances = np.empty((n, k), dtype=np.float32)\n",
    "    index.compute_distance_subset(\n",
    "        n, faiss.swig_ptr(xq), k, faiss.swig_ptr(distances), faiss.swig_ptr(subset)\n",
    "    )\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DPR + BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_descriptions = {\n",
    "    \"Security_Analyst\": \"Security Analyst: As a Security Analyst, you will play a critical role in safeguarding our organization's digital assets and ensuring the integrity of our systems. Your primary responsibilities will include continuously monitoring and analyzing security alerts and events to detect and respond to potential threats. By conducting thorough investigations, you will identify the root causes of security incidents and develop strategies to prevent their recurrence. Collaborating closely with cross-functional teams, including IT, network operations, and software development, you will assess and enhance our security infrastructure. This involves evaluating existing security measures, such as firewalls, intrusion detection systems, and endpoint protection solutions, and recommending improvements to strengthen our defenses against cyber threats. Your role will also involve staying abreast of emerging security trends, vulnerabilities, and attack techniques. By keeping our security policies and procedures up to date, you will ensure that our organization remains compliant with industry regulations and standards. Additionally, you will participate in security awareness training programs to educate employees about best practices for maintaining information security. Through your expertise and diligence, you will contribute to creating a secure environment where our stakeholders can trust that their data is protected from unauthorized access, disclosure, and manipulation.\",\n",
    "    \"Systems_Administrator\": \"A Systems Administrator is a vital IT professional responsible for the maintenance, configuration, and reliable operation of computer systems, particularly multi-user computers, such as servers. They ensure that the infrastructure of an organization runs smoothly by managing, upgrading, and setting up hardware and software, installing patches, and ensuring the security of data from internal and external threats. This role includes developing and maintaining networks, backups, and system security strategies. Systems Administrators must quickly diagnose and resolve problems in IT systems, making them essential for minimizing downtime and enhancing performance in business operations. They also provide technical support and guidance to users, which may include training non-technical staff on how to use business systems. Applicants should possess strong problem-solving skills, experience with various operating systems including Windows and Linux, and understanding of network management and security. Certifications such as Microsoft Certified Systems Administrator (MCSA), CompTIA A+, and Cisco Certified Network Associate (CCNA) are highly regarded. Effective communication and the ability to work in a team are crucial for collaborating with IT staff and other departments to facilitate seamless IT operations.\",\n",
    "    \"Project_manager\": \"A Project Manager is a critical role responsible for planning, executing, and finalizing projects within set deadlines and budgets. This position involves coordinating efforts of team members, consultants, and contractors to deliver projects according to plan. The Project Manager must define project objectives, create schedules, and oversee quality control throughout the project life cycle. Key responsibilities include managing project resources, leading team meetings, and ensuring clear communication among project stakeholders. The role demands strong leadership to motivate and direct diverse teams, and an ability to anticipate and mitigate risks that could impact project timelines or outcomes. Applicants should have proven experience in project management methodologies, such as Agile or Waterfall, and be adept at using project management software like Microsoft Project or Atlassian JIRA. Strong organizational skills, attention to detail, and the capacity to handle multiple projects simultaneously are essential. Ideal candidates will possess a Bachelor’s degree in a related field and certifications such as PMP (Project Management Professional) or PRINCE2. Excellent interpersonal and communication skills are crucial for negotiating with clients and vendors, as well as for fostering a collaborative team environment. This role suits someone with a proactive approach and a knack for problem-solving in dynamic project environments.\",\n",
    "    \"Database_Administrator\": \"A Database Administrator (DBA) is responsible for the performance, integrity, and security of databases in an organization. They ensure that data remains consistent across the database, is clearly defined, and efficiently accessed by users. DBAs are also involved in planning and development of the database, as well as in troubleshooting any issues on behalf of the users. Key responsibilities include installing, configuring, upgrading, and maintaining database servers. A DBA will set and enforce policies for the access and use of the database, and ensure compliance with data security and privacy mandates. They perform regular backups to prevent data loss in case of power failure or other issues. Additionally, DBAs optimize database performance through monitoring, tuning, and managing database parameters. Candidates should have a strong understanding of database languages like SQL, experience with database management systems like Oracle, SQL Server, or MySQL, and familiarity with operating systems such as Linux and Windows. Relevant certifications, such as Oracle Certified Professional or Microsoft Certified Database Administrator, are advantageous. This role requires excellent problem-solving skills and attention to detail. Effective communication skills are also important, as DBAs need to collaborate with IT staff and management to align database plans with organizational goals.\",\n",
    "    \"Software_Developer\": \"A Software Developer is responsible for designing, coding, testing, and maintaining software applications that meet user needs and business requirements. They collaborate with other developers, project managers, UX designers, and sometimes clients to create complex software systems. This role involves writing scalable and efficient code, often in various programming languages such as Java, Python, C#, or JavaScript. Key responsibilities include analyzing user needs and developing software solutions, often modifying existing software to improve performance or adapt to new hardware. A developer must also monitor the performance of software applications to ensure they are error-free and efficient. Documenting the development process, code changes, and other technical information is essential for ongoing maintenance and updates. Candidates should possess a bachelor's degree in computer science, software engineering, or a related field, along with a strong foundation in computer science principles, data structures, and algorithms. Experience with development environments, version control systems like Git, and methodologies such as Agile or Scrum is beneficial. Effective problem-solving skills, attention to detail, and the ability to work in a team environment are crucial. Good communication skills are also important for interacting with non-technical team members and stakeholders to gather requirements and explain technical details.\",\n",
    "    \"Front_End_Developer\": \"A Front End Developer is responsible for implementing visual elements that users see and interact with in a web application. They are tasked with combining the art of design with the science of programming, translating UI/UX design wireframes into actual code that will produce visual elements of the application. Key responsibilities include developing new user-facing features and optimizing applications for maximum speed and scalability. Front End Developers ensure the technical feasibility of UI/UX designs and maintain the consistency of visual design language across a digital ecosystem. They are also expected to manage responsive design, ensuring websites function across different devices and platforms. Candidates should be proficient in web markup, including HTML5, CSS3, and client-side scripting languages like JavaScript. Knowledge of JavaScript frameworks such as React, Angular, or Vue.js is highly advantageous. Experience with version control tools like Git, and familiarity with SEO principles are also desirable. A bachelor’s degree in computer science, information technology, or a related field is typically required. Strong problem-solving skills, attention to detail, and the ability to work collaboratively in cross-functional teams are essential. Effective communication skills are necessary to explain complex concepts to team members who may not have a technical background.\",\n",
    "    \"Web_Developer\": \"A Web Developer is responsible for the coding, design, and layout of websites according to a company’s specifications. As the role takes into consideration user experience and function, a certain level of both graphic design and computer programming is necessary. They work closely with project managers and designers to ensure the final product adheres to the predetermined budget, scope, and design. Web developers typically build the framework of a website using coding languages such as HTML, CSS, JavaScript, and frameworks like React or Angular. They must also test and document software for web sites, work with graphics and other designers to determine the website’s layout, and integrate graphics, audio, and video into the website. Additionally, they are responsible for monitoring website performance and ensuring that the site is user-friendly and up-to-date. Candidates should have strong analytical skills and be detail-oriented with the ability to solve problems effectively. Knowledge of search engine optimization (SEO) practices is a plus, helping to ensure that websites meet optimal architecture, content, linking, and other factors to rank well in search engines. A bachelor’s degree in computer science or a related field is often required, along with experience in web development or a similar role. Strong communication and teamwork skills are essential to collaborate effectively with various departments.\",\n",
    "    \"Java_Developer\": \"A Java Developer is responsible for the design, development, and management of Java-based applications. Because Java is widely used in large systems, the role requires a deep understanding of the language as well as the underlying frameworks and libraries such as Spring and Hibernate. Key responsibilities include writing well-designed, efficient code that fits in with the rest of the project’s architecture. A Java Developer must also conduct software analysis, programming, testing, and debugging, ensuring that standards and project requirements are met. Further, they engage in maintaining, expanding, and scaling existing software systems and may assist in the design of new applications. Candidates should have a strong grasp of Java development and object-oriented design patterns, as well as experience with concepts like full-stack development, microservices, and cloud services. Familiarity with web technologies like HTML, CSS, JavaScript, and popular frameworks like Angular or React is beneficial. A bachelor’s degree in computer science, engineering, or a related field is typically required. Java Developers must have strong analytical skills and the ability to work independently or as part of a team. They should also possess good communication skills to effectively collaborate with team members and stakeholders to define user requirements and provide business solutions.\",\n",
    "    \"Network_Administrator\": \"A Network Administrator is responsible for maintaining an organization's computer networks, ensuring that they run efficiently and securely. This role involves setting up, administering, and troubleshooting network hardware and software systems to ensure optimal operations and connectivity. Key duties include installing and configuring network equipment such as routers, switches, firewalls, and load balancers. Network Administrators also manage IP addresses, monitor network performance to identify and resolve bottlenecks, and perform security measures to protect data and systems from external and internal threats. They are tasked with regularly updating network infrastructure, conducting routine maintenance, and providing support for network issues to users across the organization. Candidates should possess a solid understanding of network infrastructure and network hardware. They must be capable of quickly learning new technologies and procedures, and able to implement and maintain emergency backup and restore systems for mission-critical network servers. Certifications such as CompTIA Network+, Cisco Certified Network Associate (CCNA), or Certified Information Systems Security Professional (CISSP) can be advantageous. A bachelor’s degree in computer science, network administration, or a related field is typically required. Strong problem-solving skills, attention to detail, and effective communication capabilities are essential for diagnosing network issues, explaining complex information to non-technical colleagues, and ensuring reliable network infrastructure.\",\n",
    "    \"Python_Developer\": \"A Python Developer is responsible for writing server-side web application logic, developing backend components, connecting applications with third-party web services, and supporting frontend developers by integrating their work with the Python application. Often, Python developers are involved in system development projects, requiring them to handle data interchange between servers and users. Key responsibilities include writing and testing scalable code, developing back-end components to improve responsiveness and overall performance, and integrating user-facing elements into applications. A Python Developer also often handles the integration of data storage solutions and may assist in designing and implementing low-latency, high-availability applications. Candidates should have a strong understanding of the Python programming language and familiarity with some ORM (Object Relational Mapper) libraries. They should be proficient in understanding of threading limitations of Python, and multi-process architecture. Experience with server-side templating languages and basic understanding of front-end technologies, such as JavaScript, HTML5, and CSS3, is highly beneficial. A bachelor’s degree in computer science, engineering, or a relevant field is typically required. Strong problem-solving skills and the ability to work in a team or independently are crucial. Good communication skills are also important for collaborating with other team members and stakeholders to deliver effective software solutions.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumes = df[\"resume\"].values.tolist()[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DPRContextEncoder were not initialized from the model checkpoint at ./models/finetune_question_encoder and are newly initialized: ['bert_model.embeddings.LayerNorm.bias', 'bert_model.embeddings.LayerNorm.weight', 'bert_model.embeddings.position_embeddings.weight', 'bert_model.embeddings.token_type_embeddings.weight', 'bert_model.embeddings.word_embeddings.weight', 'bert_model.encoder.layer.0.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.0.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.0.attention.output.dense.bias', 'bert_model.encoder.layer.0.attention.output.dense.weight', 'bert_model.encoder.layer.0.attention.self.key.bias', 'bert_model.encoder.layer.0.attention.self.key.weight', 'bert_model.encoder.layer.0.attention.self.query.bias', 'bert_model.encoder.layer.0.attention.self.query.weight', 'bert_model.encoder.layer.0.attention.self.value.bias', 'bert_model.encoder.layer.0.attention.self.value.weight', 'bert_model.encoder.layer.0.intermediate.dense.bias', 'bert_model.encoder.layer.0.intermediate.dense.weight', 'bert_model.encoder.layer.0.output.LayerNorm.bias', 'bert_model.encoder.layer.0.output.LayerNorm.weight', 'bert_model.encoder.layer.0.output.dense.bias', 'bert_model.encoder.layer.0.output.dense.weight', 'bert_model.encoder.layer.1.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.1.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.1.attention.output.dense.bias', 'bert_model.encoder.layer.1.attention.output.dense.weight', 'bert_model.encoder.layer.1.attention.self.key.bias', 'bert_model.encoder.layer.1.attention.self.key.weight', 'bert_model.encoder.layer.1.attention.self.query.bias', 'bert_model.encoder.layer.1.attention.self.query.weight', 'bert_model.encoder.layer.1.attention.self.value.bias', 'bert_model.encoder.layer.1.attention.self.value.weight', 'bert_model.encoder.layer.1.intermediate.dense.bias', 'bert_model.encoder.layer.1.intermediate.dense.weight', 'bert_model.encoder.layer.1.output.LayerNorm.bias', 'bert_model.encoder.layer.1.output.LayerNorm.weight', 'bert_model.encoder.layer.1.output.dense.bias', 'bert_model.encoder.layer.1.output.dense.weight', 'bert_model.encoder.layer.10.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.10.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.10.attention.output.dense.bias', 'bert_model.encoder.layer.10.attention.output.dense.weight', 'bert_model.encoder.layer.10.attention.self.key.bias', 'bert_model.encoder.layer.10.attention.self.key.weight', 'bert_model.encoder.layer.10.attention.self.query.bias', 'bert_model.encoder.layer.10.attention.self.query.weight', 'bert_model.encoder.layer.10.attention.self.value.bias', 'bert_model.encoder.layer.10.attention.self.value.weight', 'bert_model.encoder.layer.10.intermediate.dense.bias', 'bert_model.encoder.layer.10.intermediate.dense.weight', 'bert_model.encoder.layer.10.output.LayerNorm.bias', 'bert_model.encoder.layer.10.output.LayerNorm.weight', 'bert_model.encoder.layer.10.output.dense.bias', 'bert_model.encoder.layer.10.output.dense.weight', 'bert_model.encoder.layer.11.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.11.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.11.attention.output.dense.bias', 'bert_model.encoder.layer.11.attention.output.dense.weight', 'bert_model.encoder.layer.11.attention.self.key.bias', 'bert_model.encoder.layer.11.attention.self.key.weight', 'bert_model.encoder.layer.11.attention.self.query.bias', 'bert_model.encoder.layer.11.attention.self.query.weight', 'bert_model.encoder.layer.11.attention.self.value.bias', 'bert_model.encoder.layer.11.attention.self.value.weight', 'bert_model.encoder.layer.11.intermediate.dense.bias', 'bert_model.encoder.layer.11.intermediate.dense.weight', 'bert_model.encoder.layer.11.output.LayerNorm.bias', 'bert_model.encoder.layer.11.output.LayerNorm.weight', 'bert_model.encoder.layer.11.output.dense.bias', 'bert_model.encoder.layer.11.output.dense.weight', 'bert_model.encoder.layer.2.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.2.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.2.attention.output.dense.bias', 'bert_model.encoder.layer.2.attention.output.dense.weight', 'bert_model.encoder.layer.2.attention.self.key.bias', 'bert_model.encoder.layer.2.attention.self.key.weight', 'bert_model.encoder.layer.2.attention.self.query.bias', 'bert_model.encoder.layer.2.attention.self.query.weight', 'bert_model.encoder.layer.2.attention.self.value.bias', 'bert_model.encoder.layer.2.attention.self.value.weight', 'bert_model.encoder.layer.2.intermediate.dense.bias', 'bert_model.encoder.layer.2.intermediate.dense.weight', 'bert_model.encoder.layer.2.output.LayerNorm.bias', 'bert_model.encoder.layer.2.output.LayerNorm.weight', 'bert_model.encoder.layer.2.output.dense.bias', 'bert_model.encoder.layer.2.output.dense.weight', 'bert_model.encoder.layer.3.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.3.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.3.attention.output.dense.bias', 'bert_model.encoder.layer.3.attention.output.dense.weight', 'bert_model.encoder.layer.3.attention.self.key.bias', 'bert_model.encoder.layer.3.attention.self.key.weight', 'bert_model.encoder.layer.3.attention.self.query.bias', 'bert_model.encoder.layer.3.attention.self.query.weight', 'bert_model.encoder.layer.3.attention.self.value.bias', 'bert_model.encoder.layer.3.attention.self.value.weight', 'bert_model.encoder.layer.3.intermediate.dense.bias', 'bert_model.encoder.layer.3.intermediate.dense.weight', 'bert_model.encoder.layer.3.output.LayerNorm.bias', 'bert_model.encoder.layer.3.output.LayerNorm.weight', 'bert_model.encoder.layer.3.output.dense.bias', 'bert_model.encoder.layer.3.output.dense.weight', 'bert_model.encoder.layer.4.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.4.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.4.attention.output.dense.bias', 'bert_model.encoder.layer.4.attention.output.dense.weight', 'bert_model.encoder.layer.4.attention.self.key.bias', 'bert_model.encoder.layer.4.attention.self.key.weight', 'bert_model.encoder.layer.4.attention.self.query.bias', 'bert_model.encoder.layer.4.attention.self.query.weight', 'bert_model.encoder.layer.4.attention.self.value.bias', 'bert_model.encoder.layer.4.attention.self.value.weight', 'bert_model.encoder.layer.4.intermediate.dense.bias', 'bert_model.encoder.layer.4.intermediate.dense.weight', 'bert_model.encoder.layer.4.output.LayerNorm.bias', 'bert_model.encoder.layer.4.output.LayerNorm.weight', 'bert_model.encoder.layer.4.output.dense.bias', 'bert_model.encoder.layer.4.output.dense.weight', 'bert_model.encoder.layer.5.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.5.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.5.attention.output.dense.bias', 'bert_model.encoder.layer.5.attention.output.dense.weight', 'bert_model.encoder.layer.5.attention.self.key.bias', 'bert_model.encoder.layer.5.attention.self.key.weight', 'bert_model.encoder.layer.5.attention.self.query.bias', 'bert_model.encoder.layer.5.attention.self.query.weight', 'bert_model.encoder.layer.5.attention.self.value.bias', 'bert_model.encoder.layer.5.attention.self.value.weight', 'bert_model.encoder.layer.5.intermediate.dense.bias', 'bert_model.encoder.layer.5.intermediate.dense.weight', 'bert_model.encoder.layer.5.output.LayerNorm.bias', 'bert_model.encoder.layer.5.output.LayerNorm.weight', 'bert_model.encoder.layer.5.output.dense.bias', 'bert_model.encoder.layer.5.output.dense.weight', 'bert_model.encoder.layer.6.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.6.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.6.attention.output.dense.bias', 'bert_model.encoder.layer.6.attention.output.dense.weight', 'bert_model.encoder.layer.6.attention.self.key.bias', 'bert_model.encoder.layer.6.attention.self.key.weight', 'bert_model.encoder.layer.6.attention.self.query.bias', 'bert_model.encoder.layer.6.attention.self.query.weight', 'bert_model.encoder.layer.6.attention.self.value.bias', 'bert_model.encoder.layer.6.attention.self.value.weight', 'bert_model.encoder.layer.6.intermediate.dense.bias', 'bert_model.encoder.layer.6.intermediate.dense.weight', 'bert_model.encoder.layer.6.output.LayerNorm.bias', 'bert_model.encoder.layer.6.output.LayerNorm.weight', 'bert_model.encoder.layer.6.output.dense.bias', 'bert_model.encoder.layer.6.output.dense.weight', 'bert_model.encoder.layer.7.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.7.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.7.attention.output.dense.bias', 'bert_model.encoder.layer.7.attention.output.dense.weight', 'bert_model.encoder.layer.7.attention.self.key.bias', 'bert_model.encoder.layer.7.attention.self.key.weight', 'bert_model.encoder.layer.7.attention.self.query.bias', 'bert_model.encoder.layer.7.attention.self.query.weight', 'bert_model.encoder.layer.7.attention.self.value.bias', 'bert_model.encoder.layer.7.attention.self.value.weight', 'bert_model.encoder.layer.7.intermediate.dense.bias', 'bert_model.encoder.layer.7.intermediate.dense.weight', 'bert_model.encoder.layer.7.output.LayerNorm.bias', 'bert_model.encoder.layer.7.output.LayerNorm.weight', 'bert_model.encoder.layer.7.output.dense.bias', 'bert_model.encoder.layer.7.output.dense.weight', 'bert_model.encoder.layer.8.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.8.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.8.attention.output.dense.bias', 'bert_model.encoder.layer.8.attention.output.dense.weight', 'bert_model.encoder.layer.8.attention.self.key.bias', 'bert_model.encoder.layer.8.attention.self.key.weight', 'bert_model.encoder.layer.8.attention.self.query.bias', 'bert_model.encoder.layer.8.attention.self.query.weight', 'bert_model.encoder.layer.8.attention.self.value.bias', 'bert_model.encoder.layer.8.attention.self.value.weight', 'bert_model.encoder.layer.8.intermediate.dense.bias', 'bert_model.encoder.layer.8.intermediate.dense.weight', 'bert_model.encoder.layer.8.output.LayerNorm.bias', 'bert_model.encoder.layer.8.output.LayerNorm.weight', 'bert_model.encoder.layer.8.output.dense.bias', 'bert_model.encoder.layer.8.output.dense.weight', 'bert_model.encoder.layer.9.attention.output.LayerNorm.bias', 'bert_model.encoder.layer.9.attention.output.LayerNorm.weight', 'bert_model.encoder.layer.9.attention.output.dense.bias', 'bert_model.encoder.layer.9.attention.output.dense.weight', 'bert_model.encoder.layer.9.attention.self.key.bias', 'bert_model.encoder.layer.9.attention.self.key.weight', 'bert_model.encoder.layer.9.attention.self.query.bias', 'bert_model.encoder.layer.9.attention.self.query.weight', 'bert_model.encoder.layer.9.attention.self.value.bias', 'bert_model.encoder.layer.9.attention.self.value.weight', 'bert_model.encoder.layer.9.intermediate.dense.bias', 'bert_model.encoder.layer.9.intermediate.dense.weight', 'bert_model.encoder.layer.9.output.LayerNorm.bias', 'bert_model.encoder.layer.9.output.LayerNorm.weight', 'bert_model.encoder.layer.9.output.dense.bias', 'bert_model.encoder.layer.9.output.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Security_Analyst: 51/100\n",
      "Systems_Administrator: 48/100\n",
      "Project_manager: 88/100\n",
      "Database_Administrator: 70/100\n",
      "Software_Developer: 85/100\n",
      "Front_End_Developer: 93/100\n",
      "Web_Developer: 55/100\n",
      "Java_Developer: 25/100\n",
      "Network_Administrator: 67/100\n",
      "Python_Developer: 99/100\n",
      "Total: 681/1000\n"
     ]
    }
   ],
   "source": [
    "question_encoder = DPRContextEncoder.from_pretrained(\n",
    "    \"./models/finetune_question_encoder\"\n",
    ").to(device)\n",
    "\n",
    "index = faiss.read_index(\"./models/faiss_index_finetuning.index\")\n",
    "indices = np.arange(0, 10000).reshape(1, 10000)\n",
    "\n",
    "total_correct = 0\n",
    "total = 0\n",
    "top_k = 100\n",
    "lambda_val = 0.1\n",
    "\n",
    "for role, description in job_descriptions.items():\n",
    "    # BM 25\n",
    "    tokenized_all = [doc.split(\" \") for doc in resumes]\n",
    "    bm25 = BM25Okapi(tokenized_all)\n",
    "    tokenized_query = description.split(\" \")\n",
    "    scores_bm25 = bm25.get_scores(tokenized_query)\n",
    "    scores_bm25 = scores_bm25 / np.max(scores_bm25)\n",
    "\n",
    "    # FAISS\n",
    "    indices = np.arange(0, 10000).reshape(1, 10000)\n",
    "    encoded_description = (\n",
    "        encode(question_tokenizer, question_encoder, description).detach().cpu().numpy()\n",
    "    )\n",
    "    scores = compute_distance_subset(index, encoded_description, indices)[0]\n",
    "    scores = scores / np.max(scores)\n",
    "\n",
    "    consolidated_scores = torch.from_numpy(lambda_val * scores + scores_bm25)\n",
    "\n",
    "    _, indices = torch.topk(consolidated_scores, top_k)\n",
    "    result = df.iloc[indices]\n",
    "    count = count_labels(role, result)\n",
    "    total_correct += count\n",
    "    total += top_k\n",
    "    print(f\"{role}: {count}/{top_k}\")\n",
    "print(f\"Total: {total_correct}/{total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_encoder = DPRContextEncoder.from_pretrained(\n",
    "    \"./models/finetune_context_encoder\"\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5468b07ace6743de8e3fce3813ecaa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(start_index, end_index, \u001b[38;5;241m500\u001b[39m)):\n\u001b[1;32m      7\u001b[0m     data \u001b[38;5;241m=\u001b[39m resumes[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m500\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m     encoded_resumes \u001b[38;5;241m=\u001b[39m \u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_encoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     index\u001b[38;5;241m.\u001b[39madd(encoded_resumes\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     11\u001b[0m faiss\u001b[38;5;241m.\u001b[39mwrite_index(index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/faiss_index_finetuning.index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[37], line 11\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(tokenizer, encoder, text)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(tokenizer, encoder, text):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 11\u001b[0m         tokenized_output \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m tokenized_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m tokenized_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2872\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2872\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2874\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2958\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2954\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2955\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2956\u001b[0m         )\n\u001b[1;32m   2957\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 2958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2960\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2964\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   2979\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   2980\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2996\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2997\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3149\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3139\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3140\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3141\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3142\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3147\u001b[0m )\n\u001b[0;32m-> 3149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/tokenization_utils.py:803\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    801\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[0;32m--> 803\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    805\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/tokenization_utils.py:770\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 770\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/tokenization_utils.py:617\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 617\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:245\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[0;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[1;32m    243\u001b[0m split_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_basic_tokenize:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnever_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;66;03m# If the token is part of the never_split set\u001b[39;00m\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_tokenizer\u001b[38;5;241m.\u001b[39mnever_split:\n\u001b[1;32m    250\u001b[0m             split_tokens\u001b[38;5;241m.\u001b[39mappend(token)\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:432\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[0;34m(self, text, never_split)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# This was added on November 1st, 2018 for the multilingual and Chinese\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;66;03m# models. This is also applied to the English models now, but it doesn't\u001b[39;00m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# matter since the English models were not trained on any Chinese data\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# and generally don't have any Chinese data in them (there are Chinese\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;66;03m# characters in the vocabulary because Wikipedia does have some Chinese\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# words in the English Wikipedia.).\u001b[39;00m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize_chinese_chars:\n\u001b[0;32m--> 432\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize_chinese_chars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# prevents treating the same character with different unicode codepoints as different characters\u001b[39;00m\n\u001b[1;32m    434\u001b[0m unicode_normalized_text \u001b[38;5;241m=\u001b[39m unicodedata\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNFC\u001b[39m\u001b[38;5;124m\"\u001b[39m, text)\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:488\u001b[0m, in \u001b[0;36mBasicTokenizer._tokenize_chinese_chars\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m char \u001b[38;5;129;01min\u001b[39;00m text:\n\u001b[1;32m    487\u001b[0m     cp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mord\u001b[39m(char)\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_chinese_char\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcp\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    489\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    490\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend(char)\n",
      "File \u001b[0;32m~/miniconda3/envs/544-final-project/lib/python3.10/site-packages/transformers/models/bert/tokenization_bert.py:512\u001b[0m, in \u001b[0;36mBasicTokenizer._is_chinese_char\u001b[0;34m(self, cp)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# This defines a \"chinese character\" as anything in the CJK Unicode block:\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# space-separated words, so they are not treated specially and handled\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;66;03m# like the all of the other languages.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    507\u001b[0m     (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x4E00\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x9FFF\u001b[39m)\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x3400\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x4DBF\u001b[39m)  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x20000\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2A6DF\u001b[39m)  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2A700\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2B73F\u001b[39m)  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2B740\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2B81F\u001b[39m)  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 512\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2B820\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2CEAF\u001b[39m)  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0xF900\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0xFAFF\u001b[39m)\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2F800\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0x2FA1F\u001b[39m)  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    515\u001b[0m ):  \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_index = 0\n",
    "end_index = 10000\n",
    "\n",
    "index = faiss.IndexFlatIP(768)  # build the index\n",
    "\n",
    "for i in tqdm(range(start_index, end_index, 500)):\n",
    "    data = resumes[i : i + 500]\n",
    "    encoded_resumes = encode(context_tokenizer, context_encoder, data)\n",
    "    index.add(encoded_resumes.detach().cpu().numpy())\n",
    "\n",
    "faiss.write_index(index, \"./models/faiss_index_finetuning.index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
