{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def get_prompt(resume):\n",
    "    return f'generate a 200 word job description for the following resumes without proper nouns \"{resume}\"'\n",
    "\n",
    "def get_job_description(resume):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": get_prompt(resume)}],\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"resume\": [], \"categories\": []}\n",
    "df = pd.DataFrame(data)\n",
    "START_INDEX = 10000\n",
    "\n",
    "# Iterate through a folder of text files and extract the text\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "# Define the directory\n",
    "dir_path = \"./data/resumes_corpus\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "files = os.listdir(dir_path)[START_INDEX:]\n",
    "\n",
    "# Iterate over each file\n",
    "for file in files:\n",
    "    if file.endswith(\".txt\"):\n",
    "        # Construct full file path\n",
    "        file_path = os.path.join(dir_path, file)\n",
    "        file_path_label = file_path.replace(\".txt\", \".lab\")\n",
    "        data = {\"resume\": [], \"categories\": []}\n",
    "\n",
    "        # Open the file\n",
    "        with codecs.open(file_path, \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "            # Read the file's contents\n",
    "            resume = f.read()\n",
    "            data[\"resume\"].append(resume)\n",
    "\n",
    "        with codecs.open(file_path_label, \"r\", encoding=\"utf8\", errors=\"ignore\") as f:\n",
    "            # Read the file's contents\n",
    "            content = f.read()\n",
    "            content = content.split(\"\\n\")\n",
    "            if \"\" in content and len(content) == 1:\n",
    "                continue\n",
    "            elif \"\" in content:\n",
    "                content.remove(\"\")\n",
    "            data[\"categories\"].append(content)\n",
    "\n",
    "        new_row_df = pd.DataFrame(data)\n",
    "        # Add the new row to the DataFrame\n",
    "        df = pd.concat([df, new_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = df[\"categories\"].explode().unique()\n",
    "df_generator = df.iterrows()\n",
    "valid_data = []\n",
    "indices = []\n",
    "for i in range(10):\n",
    "    for u_label in unique_labels:\n",
    "        data = {\"label\": u_label, \"pos\": [], \"neg\": []}\n",
    "        i = 0\n",
    "        while i < 5:\n",
    "            index, row = next(df_generator)\n",
    "            if u_label in row[\"categories\"]:\n",
    "                data[\"pos\"].append(row[\"resume\"])\n",
    "                indices.append(index)\n",
    "                i += 1\n",
    "        i = 0\n",
    "        while i < 15:\n",
    "            index, row = next(df_generator)\n",
    "            if u_label not in row[\"categories\"]:\n",
    "                indices.append(index)\n",
    "                data[\"neg\"].append(row[\"resume\"])\n",
    "                i += 1\n",
    "        valid_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for i in range(10):\n",
    "    for u_label in unique_labels:\n",
    "        data = {\"label\": u_label, \"pos\": [], \"neg\": []}\n",
    "        i = 0\n",
    "        while i < 5:\n",
    "            index, row = next(df_generator)\n",
    "            if u_label in row[\"categories\"]:\n",
    "                data[\"pos\"].append(row[\"resume\"])\n",
    "                indices.append(index)\n",
    "                i += 1\n",
    "        i = 0\n",
    "        while i < 15:\n",
    "            index, row = next(df_generator)\n",
    "            if u_label not in row[\"categories\"]:\n",
    "                indices.append(index)\n",
    "                data[\"neg\"].append(row[\"resume\"])\n",
    "                i += 1\n",
    "        test_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:33<00:00,  5.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Add job descriptions\n",
    "for data in tqdm(valid_data):\n",
    "    resumes = \"---------------------------------\\n\".join(data[\"pos\"][0:3])\n",
    "    data[\"description\"] = get_job_description(resumes)\n",
    "\n",
    "for data in tqdm(test_data):\n",
    "    resumes = \"---------------------------------\\n\".join(data[\"pos\"][0:3])\n",
    "    data[\"description\"] = get_job_description(resumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/valid_data.json\", \"w\") as f:\n",
    "    json.dump(valid_data, f, indent=4)\n",
    "with open(\"./data/test_data.json\", \"w\") as f:\n",
    "    json.dump(test_data, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "544-final-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
