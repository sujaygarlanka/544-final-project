Machine Learning Engineer Machine Learning Engineer Machine Learning Engineer Boston, MA ? Around 5 years IT experience as a software engineer and web application developer using Python as the primary language.  ? Worked on several standard python libraries such as Numpy, Pandas, Matplotlib, Pickle, Scipy, Pytables, Pytest, Pyside etc.  ? Co-ordinated with SMEs, other architects and senior technical staff to identify client needs, document assumptions and work in an agile project based environment.  ? Good working knowledge of object oriented design principles and techniques.  ? Familiar with JSON based REST Web services and Amazon Web Services (AWS)  ? Expertise in working with different databases like Microsoft SQL Server, Oracle, MySQL, PostgreSQL and Good knowledge in using NoSQL databases MongoDB  ? Experience in working with Splunk and good knowledge on Wireshark and Ettercap  ? Well versed with design and development of presentation layer for web applications using HTML, CSS and JavaScript.  ? Experience with VMWare Server, Desktop virtualization, AWS EC2, EBS and RDS  ? Troubleshot problems with PHP and other web technologies Utilized Git and Gitlab for version control.  ? Strong knowledge in writing Automation test scripts using QTP 10.0 and selenium webdriver integrated with python  ? Hands on experience working with multiple databases to query and manage data, using SQL. Worked with multiple databases including MYSQL, Postgres, Oracle, MongoDB. Worked mostly in UNIX based environments, with some exposure to windows based environments.  ? Experience with test driven development and worked in both waterfall and agile project management methodologies.  ? Hands on experience building RESTful end points using Django Rest Framework and building web services to be consumed by different front end clients.  ? Working knowledge of continuous integration and deployment tools such as Travis CI, Circle CI and Docker.  ? Hands on experience with cloud computing platforms such as Amazon Web Services, using services such as S3, EC2 and RDS. Used both AWS command line tools and the Python SDK Boto.  ? Familiar with version control systems such as Git, Subversion and CVS.  ? Excellent communication, interpersonal and analytical skills and a highly motivated team player with the ability to work independently. Work Experience Machine Learning Engineer Boston Medical Center HealthNet Plan, MA December 2016 to September 2017 BMCHP is a HealthCare service provider company that provides services to the states of Massachusetts and New Hampshire. BMCHP's Mission is to serve Boston Medical Center and to assist and support Boston Medical Center's mission in providing and enhancing access to effective, efficient medical care among low income, undeserved, disabled and elderly and other vulnerable populations.    Responsibilities:  • Designed and developed machine learning/ deep learning algorithms to classify the behavioral patterns of the insurance claimers using random forests and decision trees.  • Developed machine learning strategies for risk analysis using Multiple Regression.  • Identify and assess available machine learning and statistical analysis libraries (including regressions, classifiers, statistical tests, and clustering algorithms).  • Creating and support a data management workflow from data collection, storage, analysis to training and validation.  • Understanding requirements, significance of weld point data, energy efficiency using large datasets  • Involved in the entire life cycle of the projects including design, development, implementation and post production support.  • Created the necessary tests for views and then built the models, views and templates as per the requirement specification.  • Implemented the guidelines of the user interface and standards throughout the development and maintenance of the application using HTML, CSS and Javascript.  • Performed statistical analytics using respective plots and tools using the linear algebraic concepts.  • Parsing various formats of files like XML, JSON, CSV and HTML and load into the Oracle Database with Python XML and JSON modules using pandas.  • Used python libraries like Numpy, Scipy and Pandas to create visualization for the data frames.  • Collaborated with QA teams during integration and system testing to ensure code coverage and resolved outstanding defects arising from the process.  • Created Plots such as bar plots, line charts, scatter plots and also histograms for visualizing the data and the frequency of occurrences of certain entities using Matlpotlib.  • Worked on MatplotLib to visualize the statistical data.  • Pig scripts used to apply the business logic and the results were stored in a flat file  • Jupyter notebook used to write Python script to train / test data sets & prediction  • NLP using NLTK library to analyze consumer feedback classification by NaïveByes  Environment: Python 3.x, Shell Scripting, Numpy, Pandas, PyQuery, Wire shark, Flash, JSON, HTML, Apache Web Server, MYSQL, GitHub, LINUX, Anaconda navigator, Jupyter ipython notebook, Ipython Console Python developer Optum - Atlanta, GA August 2015 to October 2016 Optum companies are licensed, independent of the association offering insurance and technology solution. Optum/UHG also act as administrators of Medicare in many states or regions of the USA and provide coverage to state government employees as well as to the federal government employees under a nationwide option of the Federal Employees Health Benefit Plan.    Responsibilities:  • Participated in all stages of the software development life-cycle including design, development, implementation and testing  • Experience in developing views and templates with Python and Django's view controller and templating language to create a user-friendly website interface  • Using the built APIs and modules along with Python text parsing modules to cleanse and load data files from partners into the application/database.  • Parsing various formats of files like XML, JSON and load into the Oracle Database with Python XML and JSON modules.  • Modify the existing Python/Django modules to deliver certain format of data.  • Collaborated with QA teams during integration and system testing to ensure code coverage and resolved outstanding defects arising from the process.  • Created RESTful web services to sending and receiving data from multiple systems.  • Developed automation scripts to create test data and test environment. Reduced set up time for new developers by 3X and increased productivity with consistent set up.  • Actively worked as part of team with managers and other staff to meet delivery timelines and improve the agile process for more predictable delivery.  • Worked as fall back release manager and scum master for 3 different releases of the product.  • Used Cognos BI tool and its packages for visualizing the data patterns and to create ad hoc reports.    Environment: Python 3, Django, SQL, MySQL, Sqlite3, git, Jira, Virtual Machine, Ajax, jQuery, JavaScript, LINUX. System Analyst/ Python Developer Microport - Memphis, TN December 2014 to June 2015 Microport is on orthodontics firm specializing in healthcare Surgeries. There are multiple home-grown systems for CRM and Claims management. I worked as a system analyst on multiple projects, initially focused on automation and then on web development.    Responsibilities:  • Developed Merge jobs in Python to extract and load data into MySQL database.  • Created the necessary tests for views and then built the models, views and templates as per the requirement specification.  • Worked on Django for web application development.  • Experienced in developing a portal to manage and entities in a content management system using Python and Django.  • Implemented user interface guidelines and standards throughout the development and maintenance of the application using HTML, CSS, JavaScript and JQuery.  • Used Test driven approach for developing the application and Implemented the unit tests using Python Unit test framework.  • Worked with a team of developers to automate loading data feeds into the current application. Initial bulk load was converted into loads using application API calls for consistent data management.  • Created forms for different stages of the claim management pipeline including user workflow, approval workflow and supervisor workflow.  • Created HTML grid based reports and graphs/dashboards using HighCharts (JS library) to show data related to current state of the claims pipeline.  • Generated feeds for external partners by using the API and connecting to the DB. Data generated was in JSON format.  • Handled day to day issues as part of production support and fine-tuned the application for enhanced performance.  • Did proof of concept work for deploying the in-house application to the AWS cloud using AWS services, in particular EC2 and RDS.  • Did design reviews and code reviews as part of the development process.    Environment: Python, JavaScript, Django Framework, CSS, SQL, MySQL, LAMP, JQuery, Apache web server. SQL Analyst Cybertek Solutions - Hyderabad, Telangana December 2012 to June 2014 Worked in the offshore division serving multiple clients in the U.S and U.K. Most of my work involved writing SQL Queries for ad-hoc reports and supporting production database and reporting applications.    Responsibilities:  • Prepare MDR documents and Database Design documents and review it with the Architecture team.  • Work with business users and development leads to analyze, understand and document existing systems and Data.  • Develop and modified PL/SQL objects such as Packages, Procedures, functions, triggers to retrieve data from the new centralized ODS.  • Create external tables based on flat files and use them to load data into the final target tables.  • Create and modify UNIX shell scripts (and SQL Loader control files) that load data from other systems into Chase schemas, for operational reporting.  • Performance tuning procedures/Queries (taking more than expected times) using Oracle DBMS_PROFILER, SQL Trace and DBMS_XPLAN.  • Develop UNIX shell scripts (ksh) to implement event wait-like functionality to wait on load status table entries instead of an event wait file. (for Informatica - based workflows)  • Made use of PL/SQL functions such as Bulk Collect and SQL constructs such as append hints, parallel loads to implement faster loads to meet data load SLAs in place.  • Troubleshoot and fix any production support issues.  • Tune long running jobs using job run logs and historical times.    Environment:MS SQL Server 2013, MySQL, Java script, Eclipse, Shell Scripting, Citrix, Team Foundation Server. Education Bachelor of technology in Hyderabad Wilmington University Skills Javascript. (2 years), MYSQL (3 years), Oracle (3 years), Python (2 years), SQL (3 years) Additional Information Technical Skills:    Programming Languages Python,JAVA, SQL, HTML, CSS, Javascript  Frameworks/Libraries Django, Angular JS, Bootstrap, JQuery, Numpy, Scipy, Pandas  Databases Oracle, SQL Server, MySQL, MongoDB    Operating Systems UNIX, Sun Solaris, Linux, HPUX, Windows  Web Servers Apache, WebSphere, WebLogic  Version Control Git, CVS, Subversion, TFS  Tools Sublime Text, PyCharm, VIM, IntelliJ, Netbeans, Eclipse