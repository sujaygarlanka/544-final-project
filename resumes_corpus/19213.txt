NBIS/NASUP General Leader NBIS/NASUP General Leader NBIS/NASUP General Leader - US NAVY, NAVAL SUPPORT Work Experience NBIS/NASUP General Leader US NAVY, NAVAL SUPPORT - Mechanicsburg, PA September 2017 to Present Senior ETL Principal Consultant  • Analysis of business requirements for end-to-end ETL process.  • Worked closely with business analysts to understand the business needs for decision support data.  • Analyzed and Created Facts and Dimension Tables for star schema.  • Participated in system analysis and data modeling, which included creating tables, views, indexes, Synonyms, triggers, functions, procedures, cursors and packages.  • Designed, developed, implemented and maintain programs to load, aggregate, and extract data to meet a wide range of business and system requirements using Informatica.  • Performed data mappings and design of system ETL workflow solutions.  • Worked with functional team of US Navy users to establish and clarify requirements.  • Investigated and corrected application defects and analyzed to maintain data quality.  • Prepared comprehensive documentation.  • Designed Audit Control Mechanism using Python.  • Designed a ETL framework to execute Python ETL scripts.  • Created error handling mechanism in Python using try & except method.  • Created logging mechanism in Python to create log files.    Environment: Python 3.7 , Informatica 9.5, IBM Cloud, Cognos 10.1, Framework Manager, Transformer, Sql Server, TOAD, SQL Navigator, Window 7, Unix. Senior ETL Consultant / Python Developer FANNIMAE - Washington, DC January 2016 to August 2017 Capital Markets  • Associated with team in offsite/onsite and assigned tasks to different team members.  • Coordinated with upstream/downstream consumers/users, analyzed the business systems gathered requirements and coordinated accordingly.  • Monitored Day to day activities and conducted meeting for reviewing codes and updated management accordingly.  • Created User stories in Rally for requirements and assigned accordingly to individual.  • Conducted daily stand up calls for status updates and made sure work assigned is completed in given spirit.  • Designed and developed ETL Mappings to extract data from flat files, MS Excel and Oracle to load the data into the target database.  • Involved and develop several complex mappings in Informatica a variety of PowerCenter transformations, Mapping Parameters, Mapping Variables, Mapplets & Parameter files in Mapping Designer using Informatica PowerCenter.  • Created complex mappings to load the data mart and monitored them.  • Worked extensively with the QA team for designing Test Plan and Test Cases.  • Created Python scripts to load from flat files to staging tables.  • Designed a ETL framework to execute Python ETL scripts.  • Converted the existing ETL mappings into Python scripts.  • Created Email Notification mechanism in Python to send Failure job email alerts.    Environment: Python 2.7 Informatica 9.6, Business Objects 11x, Oracle 11g, TOAD, SQL Navigator, Rally SVN, Window8, UNIX. Sr ETL Consultant BANK OF AMERICA January 2014 to December 2015 GWIM AND CSBB COMPLIANCE  • Analyzed the business systems, gathered requirements from the users and documented business needs for decision support data.  • Interpreted logical and physical data models for Business users to determine common data definitions and establish referential integrity of the system.  • Created the (ER) Entity Relationship diagrams & maintained corresponding documentation for corporate data dictionary with all attributes, table names and constraints.  • Extensively used Erwin for data modeling and Dimensional Data Modeling.  • Prepared technical documentation to map source to target.  • Designed, Developed, Deployed and implemented ETL mappings using Informatica.  • Migrated Workflows, Mappings, and other repository objects from Development to QA and then to production.  • Responsible for performance tuning at all levels of the Data warehouse.  • Created Informatica sessions in workflow manager to load the data from staging to Target database.  • Prepared technical design/specifications for data Extraction, Transformation and Loading.  • Created different target schemas for Staging and Data Mart.  • Designed the Mapping Design documents and the Deployment Documents.  • Designed and Developed several mappings to Load the Dimensions and the fact tables.  • Created Informatica mappings to extract data from sources and staged in SQL Server and populated the warehouse.  • Involved in integrating the change in the workflow to both test and allow error handling using Informatica IDQ 9.5 and developed solutions based on the data governance.  • Responsible for performance tuning at all levels of the Data warehouse.  • Created Informatica sessions in workflow manager to load the data from staging to Target.  • Used Address validator transformation in IDQ and passed the partial address and populated the full address in the target table.  • Worked in Scorecards & Profiles in IDQ.  • Created Business Glossaries using Informatica Metadata Manager  • Created sessions and workflows for processing and to populate the dimensions and facts in the star schema.  • Extensively used various transformations like XML, Union, Expression, Filter, Aggregator, Lookup and Router Transformations.  • Generated XML files as target to load into the vendor customized application to generate the reports.  • Implemented Slowly Changing Dimensions Type1, Type 2.  • Worked in rules, Logical Data Objects, Physical Data Objects in IDQ.  • Worked with connected and unconnected look-up for implementing complex logic  • Created Data Analysis graphs using Python third Party libraries.  • Created Email Notification and Data Visualization scripts using Python    Environment: Python 2.7, Informatica 9.5/10.1, Informatica Data Quality (IDQ), Informatica Metadata Manager, Framework Manager, Transformer, Sql Server, TOAD, SQL Navigator, Window 7, Unix. Lead ETL Developer CIGNA - Hartford, CT December 2013 to August 2014 Enterprise Quality Architecture  • Gathered user Requirements and designed Source to Target data load specifications based on business rules.  • Used Informatica Power Center 9.0.1.for extraction, loading and transformation (ETL) of data in the DataMart.  • Designed and developed ETL Mappings to extract data from HP Flat files and Oracle to load the data into the target database.  • Developed several complex mappings in Informatica a variety of PowerCenter transformations, Mapping Parameters, Mapping Variables, Mapplets & Parameter files in Mapping Designer using Informatica PowerCenter.  • Built complex reports using SQL scripts.  • Created complex calculations, various prompts, conditional formatting and conditional blocking etc., accordingly.  • Created complex mappings to load the data mart and monitored them. The mappings involved extensive use of Aggregator, Filter, Router, Expression, Joiner, Union, Normaliser and Sequence generator transformations.  • Using Aggregator transformation calculated SUM, AVG of monthly sales for different products.  Environment: Informatica 9.0.1, Cognos 10.1, Framework Manager, Transformer, Oracle 11g, TOAD, SQL Navigator, Window 7, Unix. Lead ETL Developer J.KNIPPER / MEDIMEDIA, PA March 2013 to November 2013 • Participated in all phases of system development life cycle from requirements gathering to deployment of the finished system into production followed by maintenance and knowledge transfer tasks.  • Gathered requirements by analyzing source systems and identification of business rules through regular requirements gathering sessions with business users and other support teams for various OLTP and OLAP systems.  • Extensively used STAR and SNOWFLAKE schema models in design.  • Involved in code review sessions to bring the team's attention to best practices and to identify areas of improvement.  • Developed PERL scripts used to cleanse the data, recreate indexes and run batch jobs.  • Used PMCMD to run workflows and CRON tab to automate their schedules.  • Participated in deployment planning and in deployment of the system to production.  • Facilitated business user smoke testing of the production system by setting up test data.  • Involved in production support duties including monitoring of nightly batches.  Environment: Informatica Power Center 9.1. Erwin 4.0, Oracle9i, SQL*PLUS, MS SQL Management studio, TOAD, DB2, UNIX, Windows ETL Developer BANK OF AMERICA March 2012 to February 2013 • Analysis of business requirements for end-to-end ETL process.  • Worked closely with business analysts to understand the business needs for decision support data.  • Analyzed and Created Facts and Dimension Tables for star schema.  • Extraction, Transformation and Load was performed using Informatica Power Center to build the data Mart.  • Designed the ETL processes using Informatica to extract data from Oracle, Flat Files, and XML files to load into target tables.  • Developed various Sessions, Batches for all Mappings to load from Source flat files tables to Target tables  • Extensively managed the data skew all the database tables.  • Created of Transformations like Sequence generator, Lookup, joiner and Update Strategy transformations in Informatica Designer.  • Wrote shell scripts for data validation and reconciliation.  • Extensively worked on the tuning of mappings and sessions.  • Wrote stored procedures for dropping and re-created indexes for efficient Data Load.  Environment: Informatica Power Center 7.3, MS SQL Server 2000, Oracle9i, Windows NT, HP-Unix. Informatica /Database developer RELYCOM, NJ February 2008 to February 2012 Clients: Wells Fargo, Medco, 1stconstitution Bank, NJ, Price water coppers, State Farm Insurance  • Gathered user Requirements and designed Source to Target data load specifications based on business rules.  • Used Informatica Power Center 8.6.1.for extraction, loading and transformation (ETL) of data in the DataMart.  • Designed and developed ETL Mappings to extract data from flat files, MS Excel and Oracle to load the data into the target database.  • Developing several complex mappings in Informatica a variety of PowerCenter transformations, Mapping Parameters, Mapping Variables, Mapplets & Parameter files in Mapping Designer using Informatica PowerCenter.  • Created complex mappings to load the data mart and monitored them. The mappings involved extensive use of Aggregator, Filter, Router, Expression, Joiner, Union, Normaliser and Sequence generator transformations.  • Ran the workflows on a daily and weekly basis using workflow monitor.  • Examined the workflow log files and assigning the ticket to the Informatica support based on the error.  • Performed operational support and maintenance of ETL bug fixes and defects.  • Maintained the target database in the production and testing environments.  • Supported migration of ETL code from development to QA and QA to production environments.  • Developed and tested all the mappings, sessions and workflows.  • Designed and developed Unix Shell Scripts, FTP, sending files to source directory & managing session files  • Done extensive testing and wrote queries in SQL to ensure the loading of the data.  • Used Informatica Power Center Workflow manager to create sessions, batches to run with the logic embedded in the mappings.  • Involved in created of Folders, Users, Repositories, Deployment Group using Repository Manager.  • Developed SQL code at the database level for the new objects.  • Designed and Developed Oracle SQL and UNIX Shell Scripts, Data Import/Export.  • Developed mappings for policy, claims dimension tables.  • Worked with database connections, SQL joins, cardinalities, loops, aliases, views, aggregate conditions, parsing of objects and hierarchies.  • Developed shell scripts for running batch jobs and scheduling them.  Environment: Informatica PowerCenter 7.x, 8.6.1, Oracle 10g/9i, Flat files, XML, MS Access, Web services, UNIX, Toad, and Business Objects. Education Physical Modelling Power Center 2000