HADOOP DEVELOPER HADOOP <span class="hl">DEVELOPER</span> HADOOP DEVELOPER - American Express Work Experience HADOOP DEVELOPER American Express - Phoenix, AZ March 2018 to Present • Design, develop and implement enterprise data warehouse and create DataMart models, Physical and logical data models.  • Build the Hive Query Language code, Build Spark Query Language code and unit testing the code. Also, create partitions, dynamic partitions.  • Develop Magellan maps and assist in deployment and provide technical and operational support during the install.  • Involved in hive coding by using Magellan tool transform the data from SOR's to ODL tables.  • Review the Hive QL code, Spark code, UNIX scripts, Magellan code and other deliverables with ODL technical panel. Work closely with team and close all issues identified during the technical panel review.  • Prepare installation manual and implement the project and provide post installation support. Update the project documentations with the installed project changes.  • Perform all the activities related to release such as preparing the metadata, Jenkin job configurations and RFC creations. All follow-ups related to the RFC and managing service now tickets and Jira tickets.  • Worked on scheduling maps/nodes in event engine and implement different proactive steps for monitoring scheduled jobs on regular basis.  • Provide production support for the existing ODL variables in production. This includes any defects fixing and implementing changes with respect to any existing ODL variables in production.  • Creating activity reports with risks, issues, causes, resolutions and provide status reports to American Express end users on daily or weekly basis.  • Conduct knowledge sharing and best practice sessions to educate the team for better quality deliverables for future.    Environment: Hive, HDFS, MapReduce, Flume, Spark -SQL, Oozie, Oracle, Jenkins, Yarn, Netezza, GitHub, Junit, Linux, Hbase , sqoop, HDFS, Event Engine, Maven and Splunk, Eclipse. Big Data Developer Citi Bank - Irving, TX March 2016 to February 2018 • Updating details in Rally for all assigned user stories and reported the status in daily stand-up meetings and also involved in sprint planning , Grooming , show &tell and retrospective calls  • Analyze the reported issues during UAT and coordinate with the business users for the resolutions.  • Implemented multiple Map Reduce Jobs in java for data cleaning and pre-processing.  • Created the external tables in Hive to store information from different sources for testing needs.  • Configured the Sqoop jobs to load the data from Netezza database and other sources into Hive Tables.  • Extensively Used Sqoop to import/export data from Netezza and Hive tables, incremental imports and created Sqoop jobs for last saved value.  • Collected logs data from webservers and integrated into HDFS using Flume.  • Created Hive tables to store the processed results in a tabular format.  • Used Maven extensively for building jar files of MapReduce programs and deployed to Cluster.  • Good experience in importing other enterprise data from different data sources into HDFS using Sqoop and Flume, and also performing transformations using Hive and PIG and then loading into HBase tables.  • Configured Oozie workflow engine to run multiple Map Reduce, HiveQL and Pig jobs  • Loaded the customer profiles data, customer spending data, credit from legacy warehouse onto HDFS using Sqoop.  • Used Oozie to orchestrate the map reduce jobs that extract the data on a timely manner.  • Involved in loading data from one Environment to other environment in Hadoop Platform.  • Developed multiple Map Reduce jobs in java for data cleaning.  • Involved in creating Hive tables, loading with data and writing hive queries that will run internally in Map Reduce way.  • Design and develop oozie workflows for timely data loading into Hadoop ecosystems from other data sources.    Environment: Hive, HDFS, MapReduce, Flume, Pig, Spark Core, Spark -SQL, Oozie, Oracle, Yarn, Netezza, GitHub, Junit, Linux, Hbase , sqoop, HDFS, Java, Scala, Maven and Splunk, Eclipse. JAVA DEVELOPER Hibu - Cedar Rapids, IA August 2014 to February 2016 • Involved in all phases of Software Development Life Cycle and in Analysis, designed applications using agile methodology.  • Created dynamic HTML pages using JavaScript, jQuery, RESTful Web Services and AJAX to create interactive Front-End GUI.  • Used synchronous and asynchronous Multi-Threading and Lambdas Expressions.  • Implemented J2EE design patterns such as Session Facade, Factory, DAO, DTO and Proxy.  • Involved in Coding based on the spring framework.  • Implemented several components using Spring IOC/Dependency Injection.  • Consumed RESTful Web services provided by different vendor to use for Address verification and validation.  • Used REST services along with UI built on Angular2.0 to perform CRUD operations on the database server over HTTP with GET, POST, PUT, DELETE to the Web service.  • Used JIRA ticketing system to keep track of issues and tasks on individuals.  • Created new tables, Stored Procedures, functions, views, indexes and constraints, triggers and required SQL tuning to reduce the response time in the application.  • Used NoSQL DB like Mongo DB for the proof of concept.  • Migrating existing legacy java services into Micro Services Architecture with Spring Boot.  • Optimized the full text search function by connecting to MongoDB.  • Created data model and generated Hibernate mappings and domain objects using Hibernate tools.  • Interfaced with the MySQL back-end database by integrating Spring with Hibernate.  • Maintaining production critical servers running Unix, Linux supporting database and Web services. Providing 24x7 supports.  • Used Spring Core annotations for Spring Dependency Injection, Spring MVC for Rest API's and Spring Boot for microservices.  • Installed the WebSphere MQ and involved in configuring MDB listeners, JMS resources, and queues and integrating with the WebSphere Application Server.  • Used log4j to print the logging, debugging, warning, info statements.  • Used Maven for build, cruise control is used continuous building; Used SVN as version control system for source code and project documents.    Environment: Java8, Spring Frameworks, Spring Boot, Micro services, JPA, Hibernate, AWS, , RESTful/SOAP Web Services, HTML, CSS, JavaScript, jQuery, Angular 2, Maven, WebSphere Application Server, Mongo DB, Log4j, Jenkins, JIRA, GIT. JAVA DEVELOPER Walmart Inc - Bentonville, AR November 2013 to July 2014 • Involved in Analyzing, preparing technical design specification documents as per the Requirements, Architecture, Development and Maintenance of high traffic application built in Java/J2EE.  • Designed application modules, base classes and utility classes using core java.  • Used SAX for XML parsing specifically for JAXB marshaling and un-marshaling.  • Involved in development, performance testing & defects fixing.  • Developed SOAP Web Services (Contract First) for pricing of the claims.  • Organized daily agile meetings to interact with the development team.  • Expertise in understanding and preparation of WSDL, XSLT and XML schemas definitions.  • Designed the project using Business Delegate, Singleton, Service Locator and DAO Patterns.  • Involved in making the necessary changes for the entire work flow from Action classes to the back-end database in Placement & Quote Creation module.  • Implemented Hibernate (ORM Mapping tool) framework to interact with the database to update, retrieve, insert and delete values effectively. JSF was used as the data interchange format between the browser and server.  • In the Front end of the application designed and implemented a publishing framework and reusable UI component library based on Angular JS and jQuery.  • Developed web-layer using Spring MVC Framework with JSP, CSS3, AJAX, and JavaScript.  • Worked within SOA based enterprise framework to build web services.  • The RESTful web services have been used to retrieve and update the data, which is populated in view using Angular JS model.  • Developed Messaging framework for Asynchronous messaging service using JMS and MQ-series.  • Extensively used JSON object data in the model as from RESTful web services.  • Developed Restful web services using JERSEY to send/receive data to/from various systems.  • Performed Test Driven Development (TDD) using JUnit.  • Used Jenkins for Continuous Integration and Continuous Delivery.    Environment: Java, J2EE, HTML5, CSS3, AJAX, JavaScript, jQuery, Spring 4.0, Tiles, SOA, Hibernate 4.0, JMS 2.0, JNDI, JTA, XML, JSON, JAXB, JAX-WS, REST WS, SOAP, WSDL, JUnit, Log4J, Maven,  JSP, JSF, Oracle, Servlets, Jenkins, Eclipse, SVN, Design Patterns, Agile, WebSphere Skills HDFS, OOZIE, SQOOP, HBASE, KAFKA, FLUME, JMS, MAP REDUCE, CODING, Git, HBase, Hive, HTML, JENKINS, Pig, SVN, XML, ZooKeeper, ECLIPSE, EJB Additional Information Technical Skills    Big Data Technologies HDFS, Map Reduce, Hive, Pig, Hbase, Sqoop, Zookeeper, Oozie, Flume, Kafka  Databases Oracle 9i, 10g, 11g, MySQL, SQL Server, Hbase  Java/J2EE Technologies JDBC, Servlets, JSP, OAuth2, JMS, EJB, JNDI, Selenium, OWB, LDAP, Log4j, ANT, Maven, RDS, SNS, Chef, JIRA, Confluence, JMeter  Programming Languages Java JDK 1.7/1.8, SQL, PL/SQL  IDEs Eclipse, NetBeans, IntelliJ, IBM RAD, Oracle WebLogic Studio 8.x/7.x, Sublime text, Brackets , Hive Connecter  Frameworks Struts 2.x/1.x, Spring 2.x, Hibernate 3.x, Mockito, PowerMockito.  Coding Languages Java 6/7/8, PL/SQL, XML, HTML, CSS, Java Script, UML  Bug Tracking or other Tools Jira, Bugzilla, Junit, Putty , WinScp& FileZilla  Operating Systems Windows and Linux Environments  Web Services SOAP, JAX-B, JAX-WS, RESTful Web services, UDDI, Micro services  Sub Version Control Tool SVN, CVS, Git, Bit Bucket, Jenkins, JIRA