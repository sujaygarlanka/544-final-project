Power BI Developer Power BI <span class="hl">Developer</span> Enterprise Data Specialist - ZURICH INSURANCE COMPANY Schaumburg, IL ? Overall 10 years of IT Experience in Enterprise Data management and currently working in DXC at onsite Location (DXC US, Schaumburg, IL)  ? Possess strong analytical thinking, troubleshooting capabilities, proactive listener & team player, commitment to co-operative teamwork and excellent interpersonal communication skills  ? Served as a point of contact for Team in offshore Location and on site for all assignments relating to the development of the Project  ? Mentoring new joiners in the Application team and getting them to a comfortable pace with the work and system.  ? Perform Coding, Unit Testing and supporting UAT  ? Conduct technical sessions to enforce knowledge sharing and knowledge gaining in the Application Team  ? Coordinate Project Activities between various Teams both over offshore and onshore  ? Ensured an excellent quality of deliverables, high team productivity and efficiency in meeting deadlines for all assignments Sponsorship required to work in the US Work Experience Power BI Developer ZURICH INSURANCE COMPANY - Schaumburg, IL August 2017 to Present Zurich Dashboards - Power BI Migration    Description: Zurich Senior Management came up with an approach to migrate all the Dashboards from Business Objects to Power BI and the backend to be moved from a regular Relational Database to Microsoft Azure Cloud Environment. This decision is taken to enhance the existing functionality and provide rich look for Users without compromising on the performance  Duration: August 2017 to till Date  Location: CSC US, Schaumburg IL  Client: ZURICH INSURANCE COMPANY  Role: Power BI Developer  Environment: Microsoft Azure, ADLS, ADLA, ADF Storage Account & Power BI    Responsibilities  ? Expertise in writing complex DAX functions in Power BI and Power Pivot  ? Design Data Models for various Dashboards that need to be transitioned from Business Objects to Power BI  ? Review the Models with Power BI Team and make them understand how all the Tables connect to each other  ? Obtain Inputs from Power BI Team regarding changes to the delivered Model which would enhance the Dashboard performance  ? Create an exhaustive list of Tables that need to be migrated from On-Premise Server to Azure Data Lake Store  ? Create Input and Output Datasets in Azure Data Factory and use them in Copy Activities within a specified pipeline  ? Ensure proper dependency is setup between different activities present in a pipeline by making use of Input / Output Datasets  ? Prepare U-SQL for existing Informatica Source Qualifier Transformation and test it under Azure Data Lake Analytics Account  ? Create workspaces and Update Apps in order to provide access to Business Users  ? Prepare Deployment Plans for Base Support Team to migrate pipelines from QA to PROD Environment with appropriate permissions granted  ? Schedule calls with ETL, Power BI & QA Team to consolidate the status on progress of the Project and share the same with the Client  ? Prepare Runbook for Productionm Support Team making it easier for them to execute the ADF Pipelines without losing track of the dependency between different pipelines. Broker Performance Management Dashboard ZURICH INSURANCE COMPANY - Schaumburg, IL January 2015 to Present Description: Provides Internal and External Views to Business Development Leader (BDL) for his reviews with Brokers. Detailed level view of number of Submissions, Quotes and Bounds and their respective Conversion, Quote and Hit Ratios and also Profitability analysis for internal reviews are also presented in this Dashboard making it much easier for BDL's presentations  Duration: Jan 2015 to till Date  Location: CSC US, Schaumburg IL  Client: ZURICH INSURANCE COMPANY  Role: Power BI / Data Specialist  Environment: Microsoft Azure, Azure SQL DB, SQL Server, Netezza, Informatica, Xcelsius, Business Objects, Unix, Autosys, JavaScript Library - D3.js, Power BI    Responsibilities  ? Design prototypes and sample Data for review with Executives to show an overall view of the Dashboard Design  ? Build a DataMart for BPM Dashboard that would increase the performance by querying appropriate Summary Tables available  ? Develop, Review HLD and LLD Documents for extracting the Data from ZEA to a Staging Layer and from Staging Layer to DataMart  ? Coordinate with Business Analyst and review the Business Logic for BPM Dashboard Views such as Retention, Lost Accounts  ? Formulated a process that would run on a monthly basis based on the dependencies of Source Data from disparate Systems and ensured that it is completed on time through Autosys Tool  ? Developed and documented Business process in order to load Files coming from various Systems so that the DataMart, Dashboard get the latest update  ? Analyzed Production Job Failures and coordinated with Business Analysts to communicate the Issue to Business Users  ? Optimizing the Queries and also improving Query / Stored Procedure Execution Time by creating Indexes with SQL Server Management Studio  ? Work with Dashboard Developer to obtain the Desired Output from Stored Procedure without compromising on its Execution Time  ? Ensure that all Code Files and other Project Related Documents were properly updated throughout all phases and checked into the Repository    CIT - PATH (Combined Input Templates for PATH)  Description: Combined Input Templates is a set of Documents that need to be filled with Pricing and Rate Change Information from disparate Source Systems. With help of ZURICH LEAN Program, the whole process is streamlined and automated using Informatica and back-end integration with SQL-Server & Netezza Power BI / Data Specialist ZURICH INSURANCE COMPANY - Schaumburg, IL October 2013 to Present Environment: Power BI, ADF, ADLA, ADLS, Netezza 7, Informatica 9.5.x, Unix, Autosys    Responsibilities  ? Responsible for developing and running Informatica mappings that would Load Data from different Pricing, Rate Change Source Systems  ? Coordinate with Actuarial Team to process the CSV Files and apply appropriate Business Logic to get the desired Result set and also export Intermediate Results from SSMS IDE  ? Made use of Java Transformation to process multiple policies present in a single Column to load them as different multiple Policies into the Target System  ? Automated process to generate Files and intimate Actuarial Team about any Duplicate Records in the Pricing Data Set  ? Participated in ZURICH LEAN Process to streamline CIT Process and deliver the Reports back in a day  ? Successfully implemented Informatica as ETL Tool for CIT and processed the Files by applying Business Logic gained from Actuarial Team there by reducing the Effort to few hours from 2-3 days  ? Create Standard Calendars using Autosys to schedule the Jobs as per Business needs  ? Analyze the Requirements and create proper Subject Area Folders in Informatica Repository so that all related Mappings / Sessions / Workflows reside in the same place  ? Validated all the Mappings / Sessions / Workflows and ensured that they are no warnings reported at any level  ? Detailed Level Comments were provided in the Description Field of each of the Transformation being used in the Mapping, mainly what functionality is being achieved by using it in a given Mapping  ? Created Breakpoints in Informatica Designer and ran the Debugger Tool to identify incorrect measures reported for a given Set of records  ? Made use of Parameter Files(.prm) and created Pre-processing Script that generated the Parameter File based on the Step Key provided as an argument to it  ? Maintained a metadata of the Informatica workflows so that the automation of creating Parameter Files, Scheduling of the workflows is easier through Autosys  ? Analyzed Session Log Files to resolve Production Issues and developed one-time Fix mappings to Production Support Team so that they can re-run the Workflows and complete the Job run successfully.    SCV (Single Customer View Dashboard)  Description: Provides insights into Customers owned, renewed, lost and acquired over a period of time by Zurich Power BI Developer / Data Specialist ZURICH INSURANCE COMPANY - Schaumburg, IL October 2013 to Present Environment: Netezza, Informatica, Xcelsius, Business Objects, Unix, Autosys    Responsibilities  ? Created calculated columns, Measures in Power BI desktop  ? Published the Power BI Desktop File to different Workspaces (DEV, QA & PROD)  ? Used various sources to pull data into Power BI such as Sql Server, Sales Force, HD Insight Cluster, SQL Azure etc.,  ? Responsible for providing worked examples during Analysis and Design Phase enabling the Business Users to see what would be the end result  ? Holding discussions with Business Analysts, Users and helping them to understand the UI Design and its connectivity to Data  ? Model and Develop required Tables for Dashboard keeping in view the performance of the Dashboard  ? Design, Develop and Test the Informatica mappings based on the Database Model for the Dashboard  ? Optimize (PDO - Push Down Optimization) for Informatica mappings whose Source and Target reside in same Server / Database  ? Schedule Informatica Jobs in Autosys Server using JIL Scripts  ? Responsible for identifying the root cause upon failure of an Autosys Job or Informatica Workflow  ? Coordinate with Netezza, Informatica and Unix Administrators to make sure QA / Production Deployments were done successfully Power BI / Data Specialist ZURICH INSURANCE COMPANY - Schaumburg, IL October 2010 to Present PATH (Pricing Activity Tracking Hub Dashboard)  Description: A Pricing Activity tool that provides essential Metrics across various Dimensions for Senior Executives to take appropriate decisions  Duration: October 2010 - till Date  Location: CSC US, Schaumburg, IL  Client: ZURICH INSURANCE COMPANY  Role: Power BI / Data Specialist  Environment: SQL Server 2005 / 2008, Informatica, Xcelsius, Business Objects    Responsibilities  ? Coordinate with Business Analysts and assisting them in writing the Requirements for the Application  ? Responsible for migrating all the Dependent Objects from one Environment to another (Development, Quality Assurance and Production)  ? Supporting / Fixing Production Issues within a specified period of time without any Business Impact  ? Ensure that all Code Files and other Project Related Documents were properly updated throughout all phases and checked into the Repository  ? Building Stored Procedures for various business Scenarios in Azure SQL Database  ? Resolving Issues in the Stored Procedures so that they can be consumed by Business upper Layer of the Stream  ? Writing up SQL Code to generate manual Business Reports  ? Work with Offshore Team to develop ETL Code for given Requirements  ? Design strategies that would enhance the performance of Dashboard from Backend perspective  ? Optimizing the Queries and also improving Query / Stored Procedure Execution Time by creating Indexes  ? Work with Dashboard Developer to obtain the Desired Output from Stored Procedure without compromising on its Execution Time  ? Automating Tasks through Informatica for Loading Text Files into SQL Tables so that the Business can do more analysis  ? Assisting Users in Testing the Dashboards which rely on Stored Procedures for displaying Data in Charts and other Dashboard Components  ? Conducted a POC on migrating the Stored Procedures from SQL Server to Netezza TwinFin Warehouse and successfully pointing the Dashboard to Netezza    Canada Claims Project  Description: Canada Claim Centre captures the Claims Information in a centralized System. The scope of this project is to provide Users with a view of Claim Information through Crystal Reports Python Scripts Developer Metadata Management - IBM InfoSphere Information Governance Catalog - Schaumburg, IL January 2010 to Present Metadata Management - IBM InfoSphere Information Governance Catalog    Description: IBM IGC Tool is being used to manage Metadata Information for all Sources that were ingested into Hadoop as part of Predictive Analytics Program initiated by Zurich. IGC provides a User interface to browse through various Physical Assets for various Internal and External Sources. IGC also manages Glossary Assets in Category Hierarchy and would be linked to Physical Assets  Duration: Jan2010 to till Date  Location: CSC US, Schaumburg IL  Client: ZURICH INSURANCE COMPANY  Role: Python Scripts Developer  Environment: MySQL Database, Python Scripting, Unix, Autosys    Responsibilities  ? Automated Scripts to generate Physical Assets Files in order to easily upload the Physical Assets to Information Governance Catalog  ? Maintain existing Python Scripts that are being used to generate Glossary Assets and linkage Files that provide a relation between Physical & Glossary Assets  ? Generate Statistics out of IGC for various measures that would help to gauge how efficiently Metadata is being maintained  ? Developed Scripts to extract the differences associated between different Data Lakes present in IGC both at a Table and Column Level  ? Process Table Level Metadata Files that were reviewed by Business System Analysts to assign appropriated Glossary Assets to their corresponding Physical Assets  ? Created methods to generate Glossary Assets as and when required from the Master Catalogue Hierarchy and push it through various stages of Workflow Process in IGC  ? Coordinate with Business System Analysts to ensure proper maintenance of Metadata in Information Governance Catalog  ? Automated Scripts to refresh Custom Properties on a Table Level (Last Load Date) as and when Data gets ingested for various Source Tables  ? Prepare Deployment Plans for Base Support Team to migrate Scripts from QA to PROD Environment with appropriate permissions granted  ? Developed & Tested Python Scripts against IGC QA Environment to ensure that the necessary changes were done successfully before proceeding to IGC PROD which helped in maintenance of Information Governance Catalog  ? Coordinated with BSA's to discuss various Issues that occurred during update of IGC through various Scripts Crystal Reports Developer CSC India, Hyderabad January 2010 to October 2010 Environment: SQL Server 2005, Crystal Reports 2008, Business Objects    Responsibilities  ? Analyzing the Requirements and providing constructive feedback on Technical Limitations of the tool to Business  ? Developing Stored Procedures / Views on Claims Database for Crystal Reports  ? Preparing Standard / Cross Tab Reports based on User Requirements  ? Changing the Data Source of Crystal Reports when Backend Environment Changes  ? Optimized the Crystal Reports performance by pushing most of the Calculations to database side wherever possible  ? Deploying the Reports in Business Objects Environment (InfoView)  ? Building URL's for displaying the Crystal Reports in various formats such as Word, Excel and PDF (OPENDOC URL)  ? Ensuring that the Crystal Reports CUID were same during migration from one BO Environment to another Java Developer CSC India, Hyderabad November 2008 to February 2010 Environment: Rational Application Developer, IBM WebSphere Server, DB2    Responsibilities  ? Changing Business Logic in specific Java Files based on the Requirements Document provided by User  ? Developing new Web Screens using JSP and Servlets Technology  ? Creating / Enhancing the Web Services which were already present in the Application  ? Packaging the entire Application as an EAR and deploying it in IBM WebSphere Server  ? Preparation of Detailed Analysis Document with explanation of the Business Logic written in Application ETL Developer CSC India, Hyderabad May 2009 to December 2009 FIG BIW Migration Project  Description: Migration of the existing SQL Server 2000 DTS Packages to SQL Server 2005 SSIS Packages  Duration: May 2009 - Dec 2009  Location: CSC India, Hyderabad  Role: ETL Developer  Environment: SQL Server 2000 / 2005, Integration Service    Responsibilities  ? Analyzing the existing DTS Packages and preparing Document for any Design Changes required during Migration  ? Designing Configuration Database for smooth migration of SSIS Packages through different SQL Environments  ? Ensuring proper Error Handling in all Data / Control Flow Tasks of SSIS Packages  ? Check-in of the Package / Code Files to TFS Environment  ? Deploying the packages to SQL Server Integration MSDB Database and then scheduling them on SQL Server Agent  ? Fixing Production Issues and resolving them within SLA  ? Enhance the deployed existing SSIS Packages with new requirements as provided by the Business  ? Preparing Standard Documents for all the Packages that have been migrated from DTS (SQL Server 2000) by indicating the Transformations used within the Package along with Source and Target Systems.  ? Maintaining a separate Job Dependency List between for the Scheduled Jobs making Production support much easier in case of Issues    CMS Application  Description: CMS is the central repository for Customer Information. It stores the Individual/Organization/Entity Names and Addresses that do business with ZURICH. CMS System also has the capability to Screen the Customer Information against the Suspect List and indicates whether ZURICH can go ahead and do Business with that particular Party or not. Education Bachelor's Degree in Information Technology in Information Technology Gayatri Vidya Parishad College of Engineering, JNTU 2004 to 2008 Additional Information Technical Skills  Programming Languages: Java, C  J2E Technologies: Servlets, JSP  Databases: Azure SQL DB , SQL Server 2008 / 2012, DB2 9, Netezza  ETL Tools: SSIS 2008 / 2012, Informatica 9.5.x, BODS, Azure Data Factory  Version Control Tools: TFS, SharePoint, VSS  Reporting Tools: Power BI, SSRS, Crystal Reports, Xcelsius  Scripting Language: Korn Shell, Javascript, Python  Governance Tool: IBM Infosphere IGC (Information Governance Catalog)